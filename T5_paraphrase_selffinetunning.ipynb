{"cells":[{"cell_type":"markdown","metadata":{"id":"cFApwu25OA0Y"},"source":["#**t5-base-korean-paraphrase model Fine-tunning: 일상대화 성능 upgrade**\n","Chang W Lee가 만듦.\n","huggingface: https://huggingface.co/lcw99/t5-base-korean-paraphrase"]},{"cell_type":"markdown","metadata":{"id":"DRXbzZ9I4r3r"},"source":["# **Install and Import libraries**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoU86m_opJij","executionInfo":{"status":"ok","timestamp":1688012211596,"user_tz":-540,"elapsed":19465,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"outputId":"85a0e722-3f74-435b-c234-828efe0865ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJdcVbOR4j0_","executionInfo":{"status":"ok","timestamp":1688012227564,"user_tz":-540,"elapsed":15974,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8869788-efa3-4f31-adf7-29f3cf744c2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}],"source":["!pip install sentencepiece\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwGMHc7z6UI9"},"outputs":[],"source":["#importing libraries\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, BatchSampler\n","from torch.nn.functional import pad\n","from torch.nn.utils.rnn import pad_sequence\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW, get_linear_schedule_with_warmup, AutoModelForCausalLM\n","from sklearn.metrics import accuracy_score\n","import pandas as pd"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/NLP프로젝트/데이터/train_data/train_data.csv\")\n","df.head()"],"metadata":{"id":"2oI5LoYcnQEm","executionInfo":{"status":"ok","timestamp":1685365414626,"user_tz":-540,"elapsed":3400,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/","height":250},"outputId":"3535f9ff-f14e-4857-94b6-22ec000bbb30"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                    texts                       pairs\n","0           0            비행기가 이륙하고 있다.               비행기가 이륙하고 있다.\n","1           9     사람이 고양이를 천장에 던지고 있다.           사람이 고양이를 천장에 던진다.\n","2          11  한 여성이 아기를 안아서 캥거루를 안는다.  한 여성이 아기를 안아서 팔에 캥거루를 안는다.\n","3          13       사람이 종이 한 장을 접고 있다.             누군가가 종이를 접고 있다.\n","4          16     북극곰이 눈 위에서 미끄러지고 있다.       북극곰이 눈 위로 미끄러져 가고 있다."],"text/html":["\n","  <div id=\"df-83eb137f-2f51-4b4f-a950-04f3d3997cea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>texts</th>\n","      <th>pairs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>비행기가 이륙하고 있다.</td>\n","      <td>비행기가 이륙하고 있다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>사람이 고양이를 천장에 던지고 있다.</td>\n","      <td>사람이 고양이를 천장에 던진다.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>한 여성이 아기를 안아서 캥거루를 안는다.</td>\n","      <td>한 여성이 아기를 안아서 팔에 캥거루를 안는다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13</td>\n","      <td>사람이 종이 한 장을 접고 있다.</td>\n","      <td>누군가가 종이를 접고 있다.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16</td>\n","      <td>북극곰이 눈 위에서 미끄러지고 있다.</td>\n","      <td>북극곰이 눈 위로 미끄러져 가고 있다.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83eb137f-2f51-4b4f-a950-04f3d3997cea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-83eb137f-2f51-4b4f-a950-04f3d3997cea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-83eb137f-2f51-4b4f-a950-04f3d3997cea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJUxdxde9mcD"},"outputs":[],"source":["from tqdm import tqdm\n","\n","class StsDataset(Dataset):\n","    def __init__(self, tokenizer, df):\n","        self.input_ids = []\n","        self.target_ids = []\n","        self.attention_masks = []\n","        for _, row in tqdm(df.iterrows()):\n","            inputencoding = tokenizer(\"Paraphrase: \"+row.values[1]+\"</s>\", padding=True,truncation = True, return_tensors = 'pt')\n","            input = inputencoding.input_ids\n","            input = torch.squeeze(input)\n","            attention_mask = inputencoding.attention_mask\n","            attention_mask = torch.squeeze(attention_mask)\n","            target = tokenizer(row.values[2]+\"</s>\", padding=True,truncation = True, return_tensors = 'pt').input_ids\n","            target = torch.squeeze(target)\n","            max_len = max(input.size()[-1], attention_mask.size()[-1], target.size()[-1])\n","            if max_len - input.size()[-1] > 0:\n","                input = torch.cat((input, torch.zeros(1)*(max_len - input.size()[-1])), dim = -1)\n","                attention_mask = torch.cat((attention_mask, torch.zeros(1)*(max_len - input.size()[-1])), dim = -1)\n","            target = torch.cat((target, torch.zeros(1)*(max_len - target.size()[-1])), dim = -1) if max_len - target.size()[-1] > 0 else target\n","            self.input_ids.append(input)\n","            self.target_ids.append(target)\n","            self.attention_masks.append(attention_mask)\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        self.input_ids[idx] = self.input_ids[idx].type(torch.LongTensor)\n","        self.attention_masks[idx] = self.attention_masks[idx].type(torch.LongTensor)\n","        self.target_ids[idx] = self.target_ids[idx].type(torch.LongTensor)\n","        return {\"input_ids\": self.input_ids[idx], \"attention_masks\": self.attention_masks[idx], \"target_ids\": self.target_ids[idx]}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCsH5-OV0Hwn","executionInfo":{"status":"ok","timestamp":1685365428522,"user_tz":-540,"elapsed":13903,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/","height":317,"referenced_widgets":["435e0f8d1220415a86e1d9769f6da653","72b35df8644a43838aea9b2d10e8eec4","0fa2c4c58a3847bda7c18ece1b364bdd","285afea32cb4411e848bdfc48b914285","9dd8547294884c3a904b6b06b9825b28","4615a56f3add47b0b29d96b21612f2bf","b377338964e4456b93734b0a36d83d86","4bc58d2c4aa24f3eb59e3acaf5091914","18e42b920d2d4527a8bd83a1c1189c37","2ccb46c3633e490ba8575aca475c0534","f795354defae41fcb02ca073863cf6ed","050e04f847b1440f8ad708a77ce86cb2","ce8afbf770874ab2a099db443fb36a33","2ebabf666fb64eee9a383d46115d513d","1bc71665ce754a1f9f2bca20755e7179","9c5faf0be4bf4b60afb12dc571861f37","fd49743843274e10aac4a3426559ab16","5edbff18355f4410943a36b1bda462b3","ad1ca0f5217949668683e16cfee5544f","c5ccb81de2344819a8c4b98d58847413","000980d82635463a9070d46b89226337","e0b763ad3a064531ad2150e4747059f1","9e772f4cc9074e80b8a8163c5b77fcb4","2f79f6cc82f5443688e75b858d8969ef","ed8ddbeb04f345d593d2290f1e645945","1c491ad22e6d473eb717dc9bd991a6ab","905afbe8184641778c6e94409a6b6e23","011bc38e1e094d87a7703401ad4a0f64","9152307d90694799853824ee3ff647c4","e4489727369e4f52a0c9f1e35e3dfe20","99f64c5897a542b28b40a79425729203","0589921a4b534cc2b0f154ff901230cf","ebcf6046e53341a5934ca138f2c34d7d","8779d228f13642ad91e3950666731737","fe74fec9198543f48adedb8119a6af26","0e183db0f08c4554bc8992bd8ec3101b","71666fc31b804c408fd9dc506f93967b","8535458e206241b1a3c2b36426168c71","ec7e8512f48848409ca5bd5b9c0707c4","1c372e8bb2714e9a8f645086083fab74","793e15f7269249aa96f55cf43ee3907f","2ebc9bc301834a98988dc088b7318f00","59eee7a4aabc4d7e927bc99c2319ab75","8da4593649a6474aa8d5d461fd641316","9300aef687a3411da2c7a7a6e6e819d3","74614b411ac44c3cbb4603936452a5a7","f555967191ca4361a3c2bde2de98a13a","e5ba67456b5a4570bcc22bb5b511c330","78f620a3fef14e3aa670accd1ac627bf","f4cc2cd4f0d345da817f497b6d3e114c","0142023ec86244cea6ad6b5a08f6eec3","f12def0a08534fbeb2da210d13c4b89b","948fc7ab4dcd49b2a8b00b11ebee83f3","4276af31427f45b8aa448800a82318df","55e5313d12c64bb697b02d78a4c1fc43"]},"outputId":"64d1af40-3bc0-4f39-8812-486cf3bbc966"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"435e0f8d1220415a86e1d9769f6da653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"050e04f847b1440f8ad708a77ce86cb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e772f4cc9074e80b8a8163c5b77fcb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/790 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8779d228f13642ad91e3950666731737"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9300aef687a3411da2c7a7a6e6e819d3"}},"metadata":{}}],"source":["model_path = \"lcw99/t5-base-korean-paraphrase\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"]},{"cell_type":"code","source":["def collate_fn(batchDummy):\n","  x = [torch.LongTensor(batch[\"input_ids\"]) for batch in batchDummy], [torch.LongTensor(batch[\"attention_masks\"]) for batch in batchDummy], [torch.LongTensor(batch[\"target_ids\"]) for batch in batchDummy]\n","  # batch단위로 데이터가 넘어올 때 아래 pad_sequence를 통해 알아서 padding을 해준다\n","  input = torch.nn.utils.rnn.pad_sequence(x[0], batch_first = True)\n","  attention_masks = torch.nn.utils.rnn.pad_sequence(x[1], batch_first = True)\n","  target_ids = torch.nn.utils.rnn.pad_sequence(x[2], batch_first = True)\n","  return {\"input_ids\": input, \"attention_masks\": attention_masks, \"target_ids\": target_ids}\n","\n","#배치사이즈, 사용할 데이터프레임\n","Batch_Size = 8\n","pairs = df\n","\n","# 추가 학습을 위한 모델 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.train()\n","5\n","\n","\n","num_epochs = 2  # 추가 학습할 에폭 수\n","dataset = StsDataset(tokenizer, pairs)\n","\n","test_val_split_idx = int(pairs.values.shape[0]*0.2)\n","\n","train_point_sampler = RandomSampler([i for i in range(test_val_split_idx, pairs.values.shape[0])])\n","train_sampler = BatchSampler(train_point_sampler, Batch_Size, False)\n","trainDataLoader = DataLoader(dataset, collate_fn = collate_fn, batch_sampler = train_sampler)\n","\n","# 학습 설정\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps= ((pairs.values.shape[0]-test_val_split_idx)//Batch_Size + 1) * num_epochs)"],"metadata":{"id":"rIAZsRUZCbnA","executionInfo":{"status":"ok","timestamp":1685365601616,"user_tz":-540,"elapsed":173107,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3cc64f7-9658-4d12-9ca9-892ff0db046b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","225376it [02:44, 1369.42it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVuGYDBbS0hC","executionInfo":{"status":"ok","timestamp":1685383393982,"user_tz":-540,"elapsed":4000236,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b7046df6-8dd0-4303-fc7c-23797477021b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Epoch [2/2] | Step [17540/22538] | Loss: 0.3341 | Accuracy: 0.9014\n","Epoch [2/2] | Step [17541/22538] | Loss: 0.2909 | Accuracy: 0.9313\n","Epoch [2/2] | Step [17542/22538] | Loss: 0.3684 | Accuracy: 0.8963\n","Epoch [2/2] | Step [17543/22538] | Loss: 0.3372 | Accuracy: 0.8934\n","Epoch [2/2] | Step [17544/22538] | Loss: 0.2563 | Accuracy: 0.9256\n","Epoch [2/2] | Step [17545/22538] | Loss: 0.2787 | Accuracy: 0.9206\n","Epoch [2/2] | Step [17546/22538] | Loss: 0.1939 | Accuracy: 0.9435\n","Epoch [2/2] | Step [17547/22538] | Loss: 0.2652 | Accuracy: 0.9250\n","Epoch [2/2] | Step [17548/22538] | Loss: 0.3706 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17549/22538] | Loss: 0.3915 | Accuracy: 0.8883\n","Epoch [2/2] | Step [17550/22538] | Loss: 0.1843 | Accuracy: 0.9367\n","Epoch [2/2] | Step [17551/22538] | Loss: 0.2153 | Accuracy: 0.9304\n","Epoch [2/2] | Step [17552/22538] | Loss: 0.2703 | Accuracy: 0.9180\n","Epoch [2/2] | Step [17553/22538] | Loss: 0.3863 | Accuracy: 0.9047\n","Epoch [2/2] | Step [17554/22538] | Loss: 0.3368 | Accuracy: 0.9232\n","Epoch [2/2] | Step [17555/22538] | Loss: 0.5659 | Accuracy: 0.8576\n","Epoch [2/2] | Step [17556/22538] | Loss: 0.3325 | Accuracy: 0.9069\n","Epoch [2/2] | Step [17557/22538] | Loss: 0.3610 | Accuracy: 0.8935\n","Epoch [2/2] | Step [17558/22538] | Loss: 0.2184 | Accuracy: 0.9375\n","Epoch [2/2] | Step [17559/22538] | Loss: 0.3416 | Accuracy: 0.9096\n","Epoch [2/2] | Step [17560/22538] | Loss: 0.4083 | Accuracy: 0.8875\n","Epoch [2/2] | Step [17561/22538] | Loss: 0.4644 | Accuracy: 0.9104\n","Epoch [2/2] | Step [17562/22538] | Loss: 0.2615 | Accuracy: 0.9363\n","Epoch [2/2] | Step [17563/22538] | Loss: 0.3711 | Accuracy: 0.8898\n","Epoch [2/2] | Step [17564/22538] | Loss: 0.2600 | Accuracy: 0.9266\n","Epoch [2/2] | Step [17565/22538] | Loss: 0.3934 | Accuracy: 0.8862\n","Epoch [2/2] | Step [17566/22538] | Loss: 0.5360 | Accuracy: 0.8671\n","Epoch [2/2] | Step [17567/22538] | Loss: 0.4371 | Accuracy: 0.9062\n","Epoch [2/2] | Step [17568/22538] | Loss: 0.4673 | Accuracy: 0.8953\n","Epoch [2/2] | Step [17569/22538] | Loss: 0.3365 | Accuracy: 0.9062\n","Epoch [2/2] | Step [17570/22538] | Loss: 0.2890 | Accuracy: 0.9308\n","Epoch [2/2] | Step [17571/22538] | Loss: 0.2306 | Accuracy: 0.9345\n","Epoch [2/2] | Step [17572/22538] | Loss: 0.2451 | Accuracy: 0.9180\n","Epoch [2/2] | Step [17573/22538] | Loss: 0.2571 | Accuracy: 0.9307\n","Epoch [2/2] | Step [17574/22538] | Loss: 0.2694 | Accuracy: 0.9307\n","Epoch [2/2] | Step [17575/22538] | Loss: 0.3325 | Accuracy: 0.9057\n","Epoch [2/2] | Step [17576/22538] | Loss: 0.2250 | Accuracy: 0.9313\n","Epoch [2/2] | Step [17577/22538] | Loss: 0.1913 | Accuracy: 0.9462\n","Epoch [2/2] | Step [17578/22538] | Loss: 0.2246 | Accuracy: 0.9348\n","Epoch [2/2] | Step [17579/22538] | Loss: 0.3319 | Accuracy: 0.9091\n","Epoch [2/2] | Step [17580/22538] | Loss: 0.1159 | Accuracy: 0.9628\n","Epoch [2/2] | Step [17581/22538] | Loss: 0.3420 | Accuracy: 0.9159\n","Epoch [2/2] | Step [17582/22538] | Loss: 0.3148 | Accuracy: 0.9040\n","Epoch [2/2] | Step [17583/22538] | Loss: 0.2923 | Accuracy: 0.9288\n","Epoch [2/2] | Step [17584/22538] | Loss: 0.3694 | Accuracy: 0.8962\n","Epoch [2/2] | Step [17585/22538] | Loss: 0.4913 | Accuracy: 0.8700\n","Epoch [2/2] | Step [17586/22538] | Loss: 0.2327 | Accuracy: 0.9444\n","Epoch [2/2] | Step [17587/22538] | Loss: 0.2620 | Accuracy: 0.9155\n","Epoch [2/2] | Step [17588/22538] | Loss: 0.3971 | Accuracy: 0.8844\n","Epoch [2/2] | Step [17589/22538] | Loss: 0.3858 | Accuracy: 0.8986\n","Epoch [2/2] | Step [17590/22538] | Loss: 0.3359 | Accuracy: 0.9052\n","Epoch [2/2] | Step [17591/22538] | Loss: 0.1984 | Accuracy: 0.9385\n","Epoch [2/2] | Step [17592/22538] | Loss: 0.3841 | Accuracy: 0.8985\n","Epoch [2/2] | Step [17593/22538] | Loss: 0.4175 | Accuracy: 0.8896\n","Epoch [2/2] | Step [17594/22538] | Loss: 0.3198 | Accuracy: 0.9107\n","Epoch [2/2] | Step [17595/22538] | Loss: 0.3628 | Accuracy: 0.9114\n","Epoch [2/2] | Step [17596/22538] | Loss: 0.2461 | Accuracy: 0.9271\n","Epoch [2/2] | Step [17597/22538] | Loss: 0.2850 | Accuracy: 0.9130\n","Epoch [2/2] | Step [17598/22538] | Loss: 0.3954 | Accuracy: 0.8877\n","Epoch [2/2] | Step [17599/22538] | Loss: 0.5009 | Accuracy: 0.8711\n","Epoch [2/2] | Step [17600/22538] | Loss: 0.2793 | Accuracy: 0.9097\n","Epoch [2/2] | Step [17601/22538] | Loss: 0.3566 | Accuracy: 0.9005\n","Epoch [2/2] | Step [17602/22538] | Loss: 0.2930 | Accuracy: 0.9289\n","Epoch [2/2] | Step [17603/22538] | Loss: 0.3193 | Accuracy: 0.9123\n","Epoch [2/2] | Step [17604/22538] | Loss: 0.3397 | Accuracy: 0.9125\n","Epoch [2/2] | Step [17605/22538] | Loss: 0.3592 | Accuracy: 0.9028\n","Epoch [2/2] | Step [17606/22538] | Loss: 0.4605 | Accuracy: 0.8828\n","Epoch [2/2] | Step [17607/22538] | Loss: 0.3518 | Accuracy: 0.9076\n","Epoch [2/2] | Step [17608/22538] | Loss: 0.2157 | Accuracy: 0.9346\n","Epoch [2/2] | Step [17609/22538] | Loss: 0.4302 | Accuracy: 0.8925\n","Epoch [2/2] | Step [17610/22538] | Loss: 0.3670 | Accuracy: 0.9091\n","Epoch [2/2] | Step [17611/22538] | Loss: 0.2816 | Accuracy: 0.9014\n","Epoch [2/2] | Step [17612/22538] | Loss: 0.3744 | Accuracy: 0.8785\n","Epoch [2/2] | Step [17613/22538] | Loss: 0.4708 | Accuracy: 0.8728\n","Epoch [2/2] | Step [17614/22538] | Loss: 0.2424 | Accuracy: 0.9383\n","Epoch [2/2] | Step [17615/22538] | Loss: 0.3359 | Accuracy: 0.9150\n","Epoch [2/2] | Step [17616/22538] | Loss: 0.4499 | Accuracy: 0.8859\n","Epoch [2/2] | Step [17617/22538] | Loss: 0.3140 | Accuracy: 0.9185\n","Epoch [2/2] | Step [17618/22538] | Loss: 0.4046 | Accuracy: 0.8929\n","Epoch [2/2] | Step [17619/22538] | Loss: 0.3751 | Accuracy: 0.9044\n","Epoch [2/2] | Step [17620/22538] | Loss: 0.2862 | Accuracy: 0.9129\n","Epoch [2/2] | Step [17621/22538] | Loss: 0.4436 | Accuracy: 0.8806\n","Epoch [2/2] | Step [17622/22538] | Loss: 0.3920 | Accuracy: 0.8984\n","Epoch [2/2] | Step [17623/22538] | Loss: 0.4037 | Accuracy: 0.8849\n","Epoch [2/2] | Step [17624/22538] | Loss: 0.3229 | Accuracy: 0.8958\n","Epoch [2/2] | Step [17625/22538] | Loss: 0.4573 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17626/22538] | Loss: 0.2241 | Accuracy: 0.9281\n","Epoch [2/2] | Step [17627/22538] | Loss: 0.4083 | Accuracy: 0.8830\n","Epoch [2/2] | Step [17628/22538] | Loss: 0.2942 | Accuracy: 0.9014\n","Epoch [2/2] | Step [17629/22538] | Loss: 0.3409 | Accuracy: 0.9267\n","Epoch [2/2] | Step [17630/22538] | Loss: 0.5034 | Accuracy: 0.8697\n","Epoch [2/2] | Step [17631/22538] | Loss: 0.2660 | Accuracy: 0.9246\n","Epoch [2/2] | Step [17632/22538] | Loss: 0.2743 | Accuracy: 0.9246\n","Epoch [2/2] | Step [17633/22538] | Loss: 0.4277 | Accuracy: 0.8827\n","Epoch [2/2] | Step [17634/22538] | Loss: 0.3667 | Accuracy: 0.9081\n","Epoch [2/2] | Step [17635/22538] | Loss: 0.2404 | Accuracy: 0.9336\n","Epoch [2/2] | Step [17636/22538] | Loss: 0.3849 | Accuracy: 0.8947\n","Epoch [2/2] | Step [17637/22538] | Loss: 0.2306 | Accuracy: 0.9348\n","Epoch [2/2] | Step [17638/22538] | Loss: 0.3422 | Accuracy: 0.8821\n","Epoch [2/2] | Step [17639/22538] | Loss: 0.3786 | Accuracy: 0.9023\n","Epoch [2/2] | Step [17640/22538] | Loss: 0.3562 | Accuracy: 0.8929\n","Epoch [2/2] | Step [17641/22538] | Loss: 0.2784 | Accuracy: 0.9303\n","Epoch [2/2] | Step [17642/22538] | Loss: 0.3944 | Accuracy: 0.9179\n","Epoch [2/2] | Step [17643/22538] | Loss: 0.4257 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17644/22538] | Loss: 0.3533 | Accuracy: 0.8990\n","Epoch [2/2] | Step [17645/22538] | Loss: 0.3300 | Accuracy: 0.9062\n","Epoch [2/2] | Step [17646/22538] | Loss: 0.2474 | Accuracy: 0.9256\n","Epoch [2/2] | Step [17647/22538] | Loss: 0.2995 | Accuracy: 0.9254\n","Epoch [2/2] | Step [17648/22538] | Loss: 0.2884 | Accuracy: 0.9048\n","Epoch [2/2] | Step [17649/22538] | Loss: 0.4411 | Accuracy: 0.8925\n","Epoch [2/2] | Step [17650/22538] | Loss: 0.2688 | Accuracy: 0.9127\n","Epoch [2/2] | Step [17651/22538] | Loss: 0.3251 | Accuracy: 0.9242\n","Epoch [2/2] | Step [17652/22538] | Loss: 0.3099 | Accuracy: 0.9077\n","Epoch [2/2] | Step [17653/22538] | Loss: 0.3130 | Accuracy: 0.9018\n","Epoch [2/2] | Step [17654/22538] | Loss: 0.2788 | Accuracy: 0.9147\n","Epoch [2/2] | Step [17655/22538] | Loss: 0.2461 | Accuracy: 0.9385\n","Epoch [2/2] | Step [17656/22538] | Loss: 0.3275 | Accuracy: 0.9179\n","Epoch [2/2] | Step [17657/22538] | Loss: 0.1739 | Accuracy: 0.9543\n","Epoch [2/2] | Step [17658/22538] | Loss: 0.2666 | Accuracy: 0.9277\n","Epoch [2/2] | Step [17659/22538] | Loss: 0.4065 | Accuracy: 0.8906\n","Epoch [2/2] | Step [17660/22538] | Loss: 0.5049 | Accuracy: 0.8663\n","Epoch [2/2] | Step [17661/22538] | Loss: 0.3620 | Accuracy: 0.8996\n","Epoch [2/2] | Step [17662/22538] | Loss: 0.2592 | Accuracy: 0.9294\n","Epoch [2/2] | Step [17663/22538] | Loss: 0.3557 | Accuracy: 0.9012\n","Epoch [2/2] | Step [17664/22538] | Loss: 0.3164 | Accuracy: 0.9093\n","Epoch [2/2] | Step [17665/22538] | Loss: 0.5596 | Accuracy: 0.8646\n","Epoch [2/2] | Step [17666/22538] | Loss: 0.2257 | Accuracy: 0.9257\n","Epoch [2/2] | Step [17667/22538] | Loss: 0.3981 | Accuracy: 0.8915\n","Epoch [2/2] | Step [17668/22538] | Loss: 0.2649 | Accuracy: 0.9365\n","Epoch [2/2] | Step [17669/22538] | Loss: 0.3403 | Accuracy: 0.9127\n","Epoch [2/2] | Step [17670/22538] | Loss: 0.3241 | Accuracy: 0.9016\n","Epoch [2/2] | Step [17671/22538] | Loss: 0.3191 | Accuracy: 0.9245\n","Epoch [2/2] | Step [17672/22538] | Loss: 0.2377 | Accuracy: 0.9216\n","Epoch [2/2] | Step [17673/22538] | Loss: 0.3139 | Accuracy: 0.8955\n","Epoch [2/2] | Step [17674/22538] | Loss: 0.3435 | Accuracy: 0.9033\n","Epoch [2/2] | Step [17675/22538] | Loss: 0.3838 | Accuracy: 0.8989\n","Epoch [2/2] | Step [17676/22538] | Loss: 0.3538 | Accuracy: 0.9116\n","Epoch [2/2] | Step [17677/22538] | Loss: 0.3335 | Accuracy: 0.9057\n","Epoch [2/2] | Step [17678/22538] | Loss: 0.2999 | Accuracy: 0.9224\n","Epoch [2/2] | Step [17679/22538] | Loss: 0.3057 | Accuracy: 0.9098\n","Epoch [2/2] | Step [17680/22538] | Loss: 0.4444 | Accuracy: 0.8727\n","Epoch [2/2] | Step [17681/22538] | Loss: 0.5486 | Accuracy: 0.8631\n","Epoch [2/2] | Step [17682/22538] | Loss: 0.3093 | Accuracy: 0.9227\n","Epoch [2/2] | Step [17683/22538] | Loss: 0.2706 | Accuracy: 0.9188\n","Epoch [2/2] | Step [17684/22538] | Loss: 0.2671 | Accuracy: 0.9224\n","Epoch [2/2] | Step [17685/22538] | Loss: 0.2717 | Accuracy: 0.9161\n","Epoch [2/2] | Step [17686/22538] | Loss: 0.4149 | Accuracy: 0.9025\n","Epoch [2/2] | Step [17687/22538] | Loss: 0.3524 | Accuracy: 0.9014\n","Epoch [2/2] | Step [17688/22538] | Loss: 0.3288 | Accuracy: 0.9137\n","Epoch [2/2] | Step [17689/22538] | Loss: 0.4278 | Accuracy: 0.8848\n","Epoch [2/2] | Step [17690/22538] | Loss: 0.3687 | Accuracy: 0.8955\n","Epoch [2/2] | Step [17691/22538] | Loss: 0.4676 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17692/22538] | Loss: 0.3717 | Accuracy: 0.8950\n","Epoch [2/2] | Step [17693/22538] | Loss: 0.3067 | Accuracy: 0.9093\n","Epoch [2/2] | Step [17694/22538] | Loss: 0.4075 | Accuracy: 0.8846\n","Epoch [2/2] | Step [17695/22538] | Loss: 0.3112 | Accuracy: 0.9009\n","Epoch [2/2] | Step [17696/22538] | Loss: 0.4041 | Accuracy: 0.9026\n","Epoch [2/2] | Step [17697/22538] | Loss: 0.4590 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17698/22538] | Loss: 0.2696 | Accuracy: 0.9203\n","Epoch [2/2] | Step [17699/22538] | Loss: 0.3989 | Accuracy: 0.9050\n","Epoch [2/2] | Step [17700/22538] | Loss: 0.2327 | Accuracy: 0.9337\n","Epoch [2/2] | Step [17701/22538] | Loss: 0.3800 | Accuracy: 0.9018\n","Epoch [2/2] | Step [17702/22538] | Loss: 0.3536 | Accuracy: 0.9122\n","Epoch [2/2] | Step [17703/22538] | Loss: 0.2882 | Accuracy: 0.9136\n","Epoch [2/2] | Step [17704/22538] | Loss: 0.3115 | Accuracy: 0.9096\n","Epoch [2/2] | Step [17705/22538] | Loss: 0.4949 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17706/22538] | Loss: 0.4113 | Accuracy: 0.9051\n","Epoch [2/2] | Step [17707/22538] | Loss: 0.2887 | Accuracy: 0.9299\n","Epoch [2/2] | Step [17708/22538] | Loss: 0.5804 | Accuracy: 0.8659\n","Epoch [2/2] | Step [17709/22538] | Loss: 0.2459 | Accuracy: 0.9225\n","Epoch [2/2] | Step [17710/22538] | Loss: 0.2442 | Accuracy: 0.9207\n","Epoch [2/2] | Step [17711/22538] | Loss: 0.2544 | Accuracy: 0.9212\n","Epoch [2/2] | Step [17712/22538] | Loss: 0.3806 | Accuracy: 0.8972\n","Epoch [2/2] | Step [17713/22538] | Loss: 0.3833 | Accuracy: 0.9005\n","Epoch [2/2] | Step [17714/22538] | Loss: 0.2159 | Accuracy: 0.9425\n","Epoch [2/2] | Step [17715/22538] | Loss: 0.2879 | Accuracy: 0.9051\n","Epoch [2/2] | Step [17716/22538] | Loss: 0.2582 | Accuracy: 0.9223\n","Epoch [2/2] | Step [17717/22538] | Loss: 0.2139 | Accuracy: 0.9329\n","Epoch [2/2] | Step [17718/22538] | Loss: 0.3250 | Accuracy: 0.9151\n","Epoch [2/2] | Step [17719/22538] | Loss: 0.3645 | Accuracy: 0.8859\n","Epoch [2/2] | Step [17720/22538] | Loss: 0.2140 | Accuracy: 0.9413\n","Epoch [2/2] | Step [17721/22538] | Loss: 0.3568 | Accuracy: 0.9128\n","Epoch [2/2] | Step [17722/22538] | Loss: 0.4363 | Accuracy: 0.8996\n","Epoch [2/2] | Step [17723/22538] | Loss: 0.2778 | Accuracy: 0.9357\n","Epoch [2/2] | Step [17724/22538] | Loss: 0.3300 | Accuracy: 0.9191\n","Epoch [2/2] | Step [17725/22538] | Loss: 0.5555 | Accuracy: 0.8438\n","Epoch [2/2] | Step [17726/22538] | Loss: 0.2695 | Accuracy: 0.9167\n","Epoch [2/2] | Step [17727/22538] | Loss: 0.3122 | Accuracy: 0.9219\n","Epoch [2/2] | Step [17728/22538] | Loss: 0.3429 | Accuracy: 0.9246\n","Epoch [2/2] | Step [17729/22538] | Loss: 0.3176 | Accuracy: 0.9089\n","Epoch [2/2] | Step [17730/22538] | Loss: 0.3163 | Accuracy: 0.9123\n","Epoch [2/2] | Step [17731/22538] | Loss: 0.3844 | Accuracy: 0.9035\n","Epoch [2/2] | Step [17732/22538] | Loss: 0.4278 | Accuracy: 0.8949\n","Epoch [2/2] | Step [17733/22538] | Loss: 0.2608 | Accuracy: 0.9341\n","Epoch [2/2] | Step [17734/22538] | Loss: 0.3798 | Accuracy: 0.9091\n","Epoch [2/2] | Step [17735/22538] | Loss: 0.3077 | Accuracy: 0.9205\n","Epoch [2/2] | Step [17736/22538] | Loss: 0.3574 | Accuracy: 0.8972\n","Epoch [2/2] | Step [17737/22538] | Loss: 0.3534 | Accuracy: 0.9022\n","Epoch [2/2] | Step [17738/22538] | Loss: 0.2507 | Accuracy: 0.9331\n","Epoch [2/2] | Step [17739/22538] | Loss: 0.5595 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17740/22538] | Loss: 0.3717 | Accuracy: 0.8901\n","Epoch [2/2] | Step [17741/22538] | Loss: 0.4946 | Accuracy: 0.8721\n","Epoch [2/2] | Step [17742/22538] | Loss: 0.1973 | Accuracy: 0.9409\n","Epoch [2/2] | Step [17743/22538] | Loss: 0.3002 | Accuracy: 0.9187\n","Epoch [2/2] | Step [17744/22538] | Loss: 0.2695 | Accuracy: 0.9198\n","Epoch [2/2] | Step [17745/22538] | Loss: 0.2570 | Accuracy: 0.9258\n","Epoch [2/2] | Step [17746/22538] | Loss: 0.3400 | Accuracy: 0.9078\n","Epoch [2/2] | Step [17747/22538] | Loss: 0.2785 | Accuracy: 0.9142\n","Epoch [2/2] | Step [17748/22538] | Loss: 0.3429 | Accuracy: 0.8981\n","Epoch [2/2] | Step [17749/22538] | Loss: 0.4809 | Accuracy: 0.8864\n","Epoch [2/2] | Step [17750/22538] | Loss: 0.2654 | Accuracy: 0.9232\n","Epoch [2/2] | Step [17751/22538] | Loss: 0.4630 | Accuracy: 0.8560\n","Epoch [2/2] | Step [17752/22538] | Loss: 0.5481 | Accuracy: 0.8567\n","Epoch [2/2] | Step [17753/22538] | Loss: 0.2680 | Accuracy: 0.9277\n","Epoch [2/2] | Step [17754/22538] | Loss: 0.4271 | Accuracy: 0.8777\n","Epoch [2/2] | Step [17755/22538] | Loss: 0.3462 | Accuracy: 0.9028\n","Epoch [2/2] | Step [17756/22538] | Loss: 0.2886 | Accuracy: 0.9104\n","Epoch [2/2] | Step [17757/22538] | Loss: 0.3884 | Accuracy: 0.8987\n","Epoch [2/2] | Step [17758/22538] | Loss: 0.2432 | Accuracy: 0.9375\n","Epoch [2/2] | Step [17759/22538] | Loss: 0.3925 | Accuracy: 0.8989\n","Epoch [2/2] | Step [17760/22538] | Loss: 0.3790 | Accuracy: 0.9138\n","Epoch [2/2] | Step [17761/22538] | Loss: 0.3934 | Accuracy: 0.8955\n","Epoch [2/2] | Step [17762/22538] | Loss: 0.1341 | Accuracy: 0.9631\n","Epoch [2/2] | Step [17763/22538] | Loss: 0.3016 | Accuracy: 0.9178\n","Epoch [2/2] | Step [17764/22538] | Loss: 0.3708 | Accuracy: 0.9139\n","Epoch [2/2] | Step [17765/22538] | Loss: 0.2956 | Accuracy: 0.9312\n","Epoch [2/2] | Step [17766/22538] | Loss: 0.2544 | Accuracy: 0.9306\n","Epoch [2/2] | Step [17767/22538] | Loss: 0.2955 | Accuracy: 0.9196\n","Epoch [2/2] | Step [17768/22538] | Loss: 0.3711 | Accuracy: 0.9119\n","Epoch [2/2] | Step [17769/22538] | Loss: 0.3657 | Accuracy: 0.8983\n","Epoch [2/2] | Step [17770/22538] | Loss: 0.4397 | Accuracy: 0.8873\n","Epoch [2/2] | Step [17771/22538] | Loss: 0.2800 | Accuracy: 0.9245\n","Epoch [2/2] | Step [17772/22538] | Loss: 0.3088 | Accuracy: 0.8992\n","Epoch [2/2] | Step [17773/22538] | Loss: 0.3574 | Accuracy: 0.9075\n","Epoch [2/2] | Step [17774/22538] | Loss: 0.3761 | Accuracy: 0.8918\n","Epoch [2/2] | Step [17775/22538] | Loss: 0.2299 | Accuracy: 0.9358\n","Epoch [2/2] | Step [17776/22538] | Loss: 0.2749 | Accuracy: 0.9301\n","Epoch [2/2] | Step [17777/22538] | Loss: 0.4376 | Accuracy: 0.8879\n","Epoch [2/2] | Step [17778/22538] | Loss: 0.3548 | Accuracy: 0.9023\n","Epoch [2/2] | Step [17779/22538] | Loss: 0.3492 | Accuracy: 0.8880\n","Epoch [2/2] | Step [17780/22538] | Loss: 0.3797 | Accuracy: 0.8929\n","Epoch [2/2] | Step [17781/22538] | Loss: 0.3016 | Accuracy: 0.9033\n","Epoch [2/2] | Step [17782/22538] | Loss: 0.3615 | Accuracy: 0.9123\n","Epoch [2/2] | Step [17783/22538] | Loss: 0.3841 | Accuracy: 0.8977\n","Epoch [2/2] | Step [17784/22538] | Loss: 0.2916 | Accuracy: 0.9062\n","Epoch [2/2] | Step [17785/22538] | Loss: 0.3466 | Accuracy: 0.8993\n","Epoch [2/2] | Step [17786/22538] | Loss: 0.3061 | Accuracy: 0.9055\n","Epoch [2/2] | Step [17787/22538] | Loss: 0.3156 | Accuracy: 0.9082\n","Epoch [2/2] | Step [17788/22538] | Loss: 0.2890 | Accuracy: 0.9192\n","Epoch [2/2] | Step [17789/22538] | Loss: 0.3154 | Accuracy: 0.9079\n","Epoch [2/2] | Step [17790/22538] | Loss: 0.3225 | Accuracy: 0.9245\n","Epoch [2/2] | Step [17791/22538] | Loss: 0.3031 | Accuracy: 0.9294\n","Epoch [2/2] | Step [17792/22538] | Loss: 0.3568 | Accuracy: 0.8947\n","Epoch [2/2] | Step [17793/22538] | Loss: 0.3294 | Accuracy: 0.9032\n","Epoch [2/2] | Step [17794/22538] | Loss: 0.2858 | Accuracy: 0.9299\n","Epoch [2/2] | Step [17795/22538] | Loss: 0.3616 | Accuracy: 0.9146\n","Epoch [2/2] | Step [17796/22538] | Loss: 0.3782 | Accuracy: 0.9032\n","Epoch [2/2] | Step [17797/22538] | Loss: 0.3794 | Accuracy: 0.9000\n","Epoch [2/2] | Step [17798/22538] | Loss: 0.4263 | Accuracy: 0.8839\n","Epoch [2/2] | Step [17799/22538] | Loss: 0.4412 | Accuracy: 0.8925\n","Epoch [2/2] | Step [17800/22538] | Loss: 0.4643 | Accuracy: 0.8799\n","Epoch [2/2] | Step [17801/22538] | Loss: 0.3297 | Accuracy: 0.9087\n","Epoch [2/2] | Step [17802/22538] | Loss: 0.5263 | Accuracy: 0.8675\n","Epoch [2/2] | Step [17803/22538] | Loss: 0.2931 | Accuracy: 0.9200\n","Epoch [2/2] | Step [17804/22538] | Loss: 0.4305 | Accuracy: 0.8769\n","Epoch [2/2] | Step [17805/22538] | Loss: 0.4497 | Accuracy: 0.8887\n","Epoch [2/2] | Step [17806/22538] | Loss: 0.3091 | Accuracy: 0.9232\n","Epoch [2/2] | Step [17807/22538] | Loss: 0.3149 | Accuracy: 0.9174\n","Epoch [2/2] | Step [17808/22538] | Loss: 0.4608 | Accuracy: 0.8893\n","Epoch [2/2] | Step [17809/22538] | Loss: 0.3080 | Accuracy: 0.9054\n","Epoch [2/2] | Step [17810/22538] | Loss: 0.3720 | Accuracy: 0.9033\n","Epoch [2/2] | Step [17811/22538] | Loss: 0.4677 | Accuracy: 0.8716\n","Epoch [2/2] | Step [17812/22538] | Loss: 0.2422 | Accuracy: 0.9422\n","Epoch [2/2] | Step [17813/22538] | Loss: 0.3159 | Accuracy: 0.9154\n","Epoch [2/2] | Step [17814/22538] | Loss: 0.4540 | Accuracy: 0.8636\n","Epoch [2/2] | Step [17815/22538] | Loss: 0.4298 | Accuracy: 0.8776\n","Epoch [2/2] | Step [17816/22538] | Loss: 0.3760 | Accuracy: 0.8903\n","Epoch [2/2] | Step [17817/22538] | Loss: 0.3294 | Accuracy: 0.9278\n","Epoch [2/2] | Step [17818/22538] | Loss: 0.3118 | Accuracy: 0.9229\n","Epoch [2/2] | Step [17819/22538] | Loss: 0.2990 | Accuracy: 0.9173\n","Epoch [2/2] | Step [17820/22538] | Loss: 0.2019 | Accuracy: 0.9469\n","Epoch [2/2] | Step [17821/22538] | Loss: 0.2566 | Accuracy: 0.9306\n","Epoch [2/2] | Step [17822/22538] | Loss: 0.3793 | Accuracy: 0.8996\n","Epoch [2/2] | Step [17823/22538] | Loss: 0.3867 | Accuracy: 0.9049\n","Epoch [2/2] | Step [17824/22538] | Loss: 0.4027 | Accuracy: 0.8974\n","Epoch [2/2] | Step [17825/22538] | Loss: 0.2487 | Accuracy: 0.9314\n","Epoch [2/2] | Step [17826/22538] | Loss: 0.2884 | Accuracy: 0.9175\n","Epoch [2/2] | Step [17827/22538] | Loss: 0.3279 | Accuracy: 0.9318\n","Epoch [2/2] | Step [17828/22538] | Loss: 0.2887 | Accuracy: 0.9288\n","Epoch [2/2] | Step [17829/22538] | Loss: 0.4706 | Accuracy: 0.8859\n","Epoch [2/2] | Step [17830/22538] | Loss: 0.2992 | Accuracy: 0.9198\n","Epoch [2/2] | Step [17831/22538] | Loss: 0.4110 | Accuracy: 0.9058\n","Epoch [2/2] | Step [17832/22538] | Loss: 0.2550 | Accuracy: 0.9238\n","Epoch [2/2] | Step [17833/22538] | Loss: 0.2911 | Accuracy: 0.9091\n","Epoch [2/2] | Step [17834/22538] | Loss: 0.4147 | Accuracy: 0.8873\n","Epoch [2/2] | Step [17835/22538] | Loss: 0.4143 | Accuracy: 0.9034\n","Epoch [2/2] | Step [17836/22538] | Loss: 0.6197 | Accuracy: 0.8774\n","Epoch [2/2] | Step [17837/22538] | Loss: 0.1845 | Accuracy: 0.9345\n","Epoch [2/2] | Step [17838/22538] | Loss: 0.2139 | Accuracy: 0.9292\n","Epoch [2/2] | Step [17839/22538] | Loss: 0.2088 | Accuracy: 0.9430\n","Epoch [2/2] | Step [17840/22538] | Loss: 0.3370 | Accuracy: 0.9191\n","Epoch [2/2] | Step [17841/22538] | Loss: 0.3149 | Accuracy: 0.9130\n","Epoch [2/2] | Step [17842/22538] | Loss: 0.3378 | Accuracy: 0.9018\n","Epoch [2/2] | Step [17843/22538] | Loss: 0.2880 | Accuracy: 0.9208\n","Epoch [2/2] | Step [17844/22538] | Loss: 0.4628 | Accuracy: 0.8816\n","Epoch [2/2] | Step [17845/22538] | Loss: 0.4542 | Accuracy: 0.8854\n","Epoch [2/2] | Step [17846/22538] | Loss: 0.3076 | Accuracy: 0.8986\n","Epoch [2/2] | Step [17847/22538] | Loss: 0.2664 | Accuracy: 0.9194\n","Epoch [2/2] | Step [17848/22538] | Loss: 0.3414 | Accuracy: 0.8866\n","Epoch [2/2] | Step [17849/22538] | Loss: 0.4173 | Accuracy: 0.8929\n","Epoch [2/2] | Step [17850/22538] | Loss: 0.3306 | Accuracy: 0.9213\n","Epoch [2/2] | Step [17851/22538] | Loss: 0.4241 | Accuracy: 0.8922\n","Epoch [2/2] | Step [17852/22538] | Loss: 0.2697 | Accuracy: 0.9186\n","Epoch [2/2] | Step [17853/22538] | Loss: 0.2017 | Accuracy: 0.9471\n","Epoch [2/2] | Step [17854/22538] | Loss: 0.2381 | Accuracy: 0.9327\n","Epoch [2/2] | Step [17855/22538] | Loss: 0.2642 | Accuracy: 0.9278\n","Epoch [2/2] | Step [17856/22538] | Loss: 0.4162 | Accuracy: 0.8932\n","Epoch [2/2] | Step [17857/22538] | Loss: 0.3360 | Accuracy: 0.9022\n","Epoch [2/2] | Step [17858/22538] | Loss: 0.3946 | Accuracy: 0.8944\n","Epoch [2/2] | Step [17859/22538] | Loss: 0.2951 | Accuracy: 0.9210\n","Epoch [2/2] | Step [17860/22538] | Loss: 0.1987 | Accuracy: 0.9425\n","Epoch [2/2] | Step [17861/22538] | Loss: 0.3434 | Accuracy: 0.9053\n","Epoch [2/2] | Step [17862/22538] | Loss: 0.4351 | Accuracy: 0.9018\n","Epoch [2/2] | Step [17863/22538] | Loss: 0.2819 | Accuracy: 0.9093\n","Epoch [2/2] | Step [17864/22538] | Loss: 0.5090 | Accuracy: 0.8807\n","Epoch [2/2] | Step [17865/22538] | Loss: 0.3048 | Accuracy: 0.9177\n","Epoch [2/2] | Step [17866/22538] | Loss: 0.2396 | Accuracy: 0.9245\n","Epoch [2/2] | Step [17867/22538] | Loss: 0.2913 | Accuracy: 0.9219\n","Epoch [2/2] | Step [17868/22538] | Loss: 0.4410 | Accuracy: 0.8936\n","Epoch [2/2] | Step [17869/22538] | Loss: 0.2876 | Accuracy: 0.9123\n","Epoch [2/2] | Step [17870/22538] | Loss: 0.3074 | Accuracy: 0.9146\n","Epoch [2/2] | Step [17871/22538] | Loss: 0.2791 | Accuracy: 0.9228\n","Epoch [2/2] | Step [17872/22538] | Loss: 0.4297 | Accuracy: 0.8970\n","Epoch [2/2] | Step [17873/22538] | Loss: 0.3458 | Accuracy: 0.9116\n","Epoch [2/2] | Step [17874/22538] | Loss: 0.3957 | Accuracy: 0.8778\n","Epoch [2/2] | Step [17875/22538] | Loss: 0.4552 | Accuracy: 0.8693\n","Epoch [2/2] | Step [17876/22538] | Loss: 0.4632 | Accuracy: 0.8902\n","Epoch [2/2] | Step [17877/22538] | Loss: 0.2295 | Accuracy: 0.9318\n","Epoch [2/2] | Step [17878/22538] | Loss: 0.4668 | Accuracy: 0.8707\n","Epoch [2/2] | Step [17879/22538] | Loss: 0.4091 | Accuracy: 0.8899\n","Epoch [2/2] | Step [17880/22538] | Loss: 0.2623 | Accuracy: 0.9339\n","Epoch [2/2] | Step [17881/22538] | Loss: 0.2629 | Accuracy: 0.9188\n","Epoch [2/2] | Step [17882/22538] | Loss: 0.3539 | Accuracy: 0.8841\n","Epoch [2/2] | Step [17883/22538] | Loss: 0.3993 | Accuracy: 0.8919\n","Epoch [2/2] | Step [17884/22538] | Loss: 0.3760 | Accuracy: 0.8925\n","Epoch [2/2] | Step [17885/22538] | Loss: 0.4570 | Accuracy: 0.8875\n","Epoch [2/2] | Step [17886/22538] | Loss: 0.1884 | Accuracy: 0.9438\n","Epoch [2/2] | Step [17887/22538] | Loss: 0.4356 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17888/22538] | Loss: 0.3612 | Accuracy: 0.8824\n","Epoch [2/2] | Step [17889/22538] | Loss: 0.2800 | Accuracy: 0.9199\n","Epoch [2/2] | Step [17890/22538] | Loss: 0.2066 | Accuracy: 0.9443\n","Epoch [2/2] | Step [17891/22538] | Loss: 0.2739 | Accuracy: 0.9276\n","Epoch [2/2] | Step [17892/22538] | Loss: 0.4103 | Accuracy: 0.8904\n","Epoch [2/2] | Step [17893/22538] | Loss: 0.4259 | Accuracy: 0.9000\n","Epoch [2/2] | Step [17894/22538] | Loss: 0.3969 | Accuracy: 0.8892\n","Epoch [2/2] | Step [17895/22538] | Loss: 0.3416 | Accuracy: 0.9071\n","Epoch [2/2] | Step [17896/22538] | Loss: 0.4548 | Accuracy: 0.8792\n","Epoch [2/2] | Step [17897/22538] | Loss: 0.3546 | Accuracy: 0.9089\n","Epoch [2/2] | Step [17898/22538] | Loss: 0.2689 | Accuracy: 0.9301\n","Epoch [2/2] | Step [17899/22538] | Loss: 0.3773 | Accuracy: 0.9158\n","Epoch [2/2] | Step [17900/22538] | Loss: 0.3702 | Accuracy: 0.8951\n","Epoch [2/2] | Step [17901/22538] | Loss: 0.3060 | Accuracy: 0.9057\n","Epoch [2/2] | Step [17902/22538] | Loss: 0.4946 | Accuracy: 0.8488\n","Epoch [2/2] | Step [17903/22538] | Loss: 0.3433 | Accuracy: 0.9104\n","Epoch [2/2] | Step [17904/22538] | Loss: 0.2570 | Accuracy: 0.9247\n","Epoch [2/2] | Step [17905/22538] | Loss: 0.2900 | Accuracy: 0.9139\n","Epoch [2/2] | Step [17906/22538] | Loss: 0.4026 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17907/22538] | Loss: 0.2666 | Accuracy: 0.9335\n","Epoch [2/2] | Step [17908/22538] | Loss: 0.3933 | Accuracy: 0.8929\n","Epoch [2/2] | Step [17909/22538] | Loss: 0.3342 | Accuracy: 0.9000\n","Epoch [2/2] | Step [17910/22538] | Loss: 0.3493 | Accuracy: 0.9014\n","Epoch [2/2] | Step [17911/22538] | Loss: 0.4592 | Accuracy: 0.8947\n","Epoch [2/2] | Step [17912/22538] | Loss: 0.3462 | Accuracy: 0.9005\n","Epoch [2/2] | Step [17913/22538] | Loss: 0.2940 | Accuracy: 0.9268\n","Epoch [2/2] | Step [17914/22538] | Loss: 0.3665 | Accuracy: 0.8912\n","Epoch [2/2] | Step [17915/22538] | Loss: 0.3845 | Accuracy: 0.8966\n","Epoch [2/2] | Step [17916/22538] | Loss: 0.3323 | Accuracy: 0.9100\n","Epoch [2/2] | Step [17917/22538] | Loss: 0.3538 | Accuracy: 0.8878\n","Epoch [2/2] | Step [17918/22538] | Loss: 0.1793 | Accuracy: 0.9386\n","Epoch [2/2] | Step [17919/22538] | Loss: 0.3953 | Accuracy: 0.8897\n","Epoch [2/2] | Step [17920/22538] | Loss: 0.2539 | Accuracy: 0.9208\n","Epoch [2/2] | Step [17921/22538] | Loss: 0.4414 | Accuracy: 0.8883\n","Epoch [2/2] | Step [17922/22538] | Loss: 0.2411 | Accuracy: 0.9306\n","Epoch [2/2] | Step [17923/22538] | Loss: 0.3838 | Accuracy: 0.8929\n","Epoch [2/2] | Step [17924/22538] | Loss: 0.3231 | Accuracy: 0.9038\n","Epoch [2/2] | Step [17925/22538] | Loss: 0.3043 | Accuracy: 0.9154\n","Epoch [2/2] | Step [17926/22538] | Loss: 0.2622 | Accuracy: 0.9344\n","Epoch [2/2] | Step [17927/22538] | Loss: 0.1745 | Accuracy: 0.9488\n","Epoch [2/2] | Step [17928/22538] | Loss: 0.2973 | Accuracy: 0.9167\n","Epoch [2/2] | Step [17929/22538] | Loss: 0.4003 | Accuracy: 0.8922\n","Epoch [2/2] | Step [17930/22538] | Loss: 0.2383 | Accuracy: 0.9320\n","Epoch [2/2] | Step [17931/22538] | Loss: 0.3501 | Accuracy: 0.9136\n","Epoch [2/2] | Step [17932/22538] | Loss: 0.2883 | Accuracy: 0.9180\n","Epoch [2/2] | Step [17933/22538] | Loss: 0.2445 | Accuracy: 0.9346\n","Epoch [2/2] | Step [17934/22538] | Loss: 0.2575 | Accuracy: 0.9259\n","Epoch [2/2] | Step [17935/22538] | Loss: 0.4232 | Accuracy: 0.8918\n","Epoch [2/2] | Step [17936/22538] | Loss: 0.3541 | Accuracy: 0.9133\n","Epoch [2/2] | Step [17937/22538] | Loss: 0.3407 | Accuracy: 0.8950\n","Epoch [2/2] | Step [17938/22538] | Loss: 0.4209 | Accuracy: 0.9031\n","Epoch [2/2] | Step [17939/22538] | Loss: 0.4977 | Accuracy: 0.8750\n","Epoch [2/2] | Step [17940/22538] | Loss: 0.2585 | Accuracy: 0.9245\n","Epoch [2/2] | Step [17941/22538] | Loss: 0.3394 | Accuracy: 0.9006\n","Epoch [2/2] | Step [17942/22538] | Loss: 0.3286 | Accuracy: 0.9167\n","Epoch [2/2] | Step [17943/22538] | Loss: 0.3478 | Accuracy: 0.8990\n","Epoch [2/2] | Step [17944/22538] | Loss: 0.4366 | Accuracy: 0.8926\n","Epoch [2/2] | Step [17945/22538] | Loss: 0.3318 | Accuracy: 0.9135\n","Epoch [2/2] | Step [17946/22538] | Loss: 0.3150 | Accuracy: 0.9018\n","Epoch [2/2] | Step [17947/22538] | Loss: 0.3095 | Accuracy: 0.9037\n","Epoch [2/2] | Step [17948/22538] | Loss: 0.3692 | Accuracy: 0.9038\n","Epoch [2/2] | Step [17949/22538] | Loss: 0.2030 | Accuracy: 0.9286\n","Epoch [2/2] | Step [17950/22538] | Loss: 0.3236 | Accuracy: 0.9125\n","Epoch [2/2] | Step [17951/22538] | Loss: 0.1771 | Accuracy: 0.9479\n","Epoch [2/2] | Step [17952/22538] | Loss: 0.4021 | Accuracy: 0.8812\n","Epoch [2/2] | Step [17953/22538] | Loss: 0.2791 | Accuracy: 0.9237\n","Epoch [2/2] | Step [17954/22538] | Loss: 0.2573 | Accuracy: 0.9192\n","Epoch [2/2] | Step [17955/22538] | Loss: 0.4432 | Accuracy: 0.8940\n","Epoch [2/2] | Step [17956/22538] | Loss: 0.3175 | Accuracy: 0.9018\n","Epoch [2/2] | Step [17957/22538] | Loss: 0.2386 | Accuracy: 0.9353\n","Epoch [2/2] | Step [17958/22538] | Loss: 0.4419 | Accuracy: 0.8804\n","Epoch [2/2] | Step [17959/22538] | Loss: 0.3682 | Accuracy: 0.9115\n","Epoch [2/2] | Step [17960/22538] | Loss: 0.3681 | Accuracy: 0.9073\n","Epoch [2/2] | Step [17961/22538] | Loss: 0.2908 | Accuracy: 0.9147\n","Epoch [2/2] | Step [17962/22538] | Loss: 0.4451 | Accuracy: 0.8848\n","Epoch [2/2] | Step [17963/22538] | Loss: 0.3487 | Accuracy: 0.8910\n","Epoch [2/2] | Step [17964/22538] | Loss: 0.3202 | Accuracy: 0.9056\n","Epoch [2/2] | Step [17965/22538] | Loss: 0.2943 | Accuracy: 0.9167\n","Epoch [2/2] | Step [17966/22538] | Loss: 0.3455 | Accuracy: 0.9004\n","Epoch [2/2] | Step [17967/22538] | Loss: 0.2677 | Accuracy: 0.9385\n","Epoch [2/2] | Step [17968/22538] | Loss: 0.4579 | Accuracy: 0.8851\n","Epoch [2/2] | Step [17969/22538] | Loss: 0.2507 | Accuracy: 0.9259\n","Epoch [2/2] | Step [17970/22538] | Loss: 0.2898 | Accuracy: 0.9235\n","Epoch [2/2] | Step [17971/22538] | Loss: 0.5088 | Accuracy: 0.8722\n","Epoch [2/2] | Step [17972/22538] | Loss: 0.2814 | Accuracy: 0.9301\n","Epoch [2/2] | Step [17973/22538] | Loss: 0.3333 | Accuracy: 0.9127\n","Epoch [2/2] | Step [17974/22538] | Loss: 0.3556 | Accuracy: 0.8966\n","Epoch [2/2] | Step [17975/22538] | Loss: 0.3346 | Accuracy: 0.9184\n","Epoch [2/2] | Step [17976/22538] | Loss: 0.4215 | Accuracy: 0.8958\n","Epoch [2/2] | Step [17977/22538] | Loss: 0.2988 | Accuracy: 0.9345\n","Epoch [2/2] | Step [17978/22538] | Loss: 0.2457 | Accuracy: 0.9403\n","Epoch [2/2] | Step [17979/22538] | Loss: 0.2826 | Accuracy: 0.9269\n","Epoch [2/2] | Step [17980/22538] | Loss: 0.3354 | Accuracy: 0.9080\n","Epoch [2/2] | Step [17981/22538] | Loss: 0.2929 | Accuracy: 0.9278\n","Epoch [2/2] | Step [17982/22538] | Loss: 0.3765 | Accuracy: 0.9045\n","Epoch [2/2] | Step [17983/22538] | Loss: 0.3333 | Accuracy: 0.9097\n","Epoch [2/2] | Step [17984/22538] | Loss: 0.2401 | Accuracy: 0.9190\n","Epoch [2/2] | Step [17985/22538] | Loss: 0.3475 | Accuracy: 0.9069\n","Epoch [2/2] | Step [17986/22538] | Loss: 0.3325 | Accuracy: 0.9173\n","Epoch [2/2] | Step [17987/22538] | Loss: 0.3110 | Accuracy: 0.9146\n","Epoch [2/2] | Step [17988/22538] | Loss: 0.3652 | Accuracy: 0.8939\n","Epoch [2/2] | Step [17989/22538] | Loss: 0.4115 | Accuracy: 0.8801\n","Epoch [2/2] | Step [17990/22538] | Loss: 0.2212 | Accuracy: 0.9329\n","Epoch [2/2] | Step [17991/22538] | Loss: 0.3951 | Accuracy: 0.9019\n","Epoch [2/2] | Step [17992/22538] | Loss: 0.5397 | Accuracy: 0.8684\n","Epoch [2/2] | Step [17993/22538] | Loss: 0.3144 | Accuracy: 0.9202\n","Epoch [2/2] | Step [17994/22538] | Loss: 0.2414 | Accuracy: 0.9364\n","Epoch [2/2] | Step [17995/22538] | Loss: 0.2874 | Accuracy: 0.9054\n","Epoch [2/2] | Step [17996/22538] | Loss: 0.3591 | Accuracy: 0.8909\n","Epoch [2/2] | Step [17997/22538] | Loss: 0.3465 | Accuracy: 0.8886\n","Epoch [2/2] | Step [17998/22538] | Loss: 0.4142 | Accuracy: 0.8810\n","Epoch [2/2] | Step [17999/22538] | Loss: 0.2999 | Accuracy: 0.9192\n","Epoch [2/2] | Step [18000/22538] | Loss: 0.4116 | Accuracy: 0.8987\n","Epoch [2/2] | Step [18001/22538] | Loss: 0.4576 | Accuracy: 0.8895\n","Epoch [2/2] | Step [18002/22538] | Loss: 0.1582 | Accuracy: 0.9573\n","Epoch [2/2] | Step [18003/22538] | Loss: 0.2963 | Accuracy: 0.9141\n","Epoch [2/2] | Step [18004/22538] | Loss: 0.1862 | Accuracy: 0.9477\n","Epoch [2/2] | Step [18005/22538] | Loss: 0.3634 | Accuracy: 0.9037\n","Epoch [2/2] | Step [18006/22538] | Loss: 0.3323 | Accuracy: 0.9057\n","Epoch [2/2] | Step [18007/22538] | Loss: 0.2879 | Accuracy: 0.9188\n","Epoch [2/2] | Step [18008/22538] | Loss: 0.2826 | Accuracy: 0.9254\n","Epoch [2/2] | Step [18009/22538] | Loss: 0.3733 | Accuracy: 0.8909\n","Epoch [2/2] | Step [18010/22538] | Loss: 0.3713 | Accuracy: 0.9030\n","Epoch [2/2] | Step [18011/22538] | Loss: 0.5812 | Accuracy: 0.8713\n","Epoch [2/2] | Step [18012/22538] | Loss: 0.3284 | Accuracy: 0.9068\n","Epoch [2/2] | Step [18013/22538] | Loss: 0.2643 | Accuracy: 0.9208\n","Epoch [2/2] | Step [18014/22538] | Loss: 0.3145 | Accuracy: 0.9086\n","Epoch [2/2] | Step [18015/22538] | Loss: 0.2944 | Accuracy: 0.9009\n","Epoch [2/2] | Step [18016/22538] | Loss: 0.4475 | Accuracy: 0.8725\n","Epoch [2/2] | Step [18017/22538] | Loss: 0.2951 | Accuracy: 0.9255\n","Epoch [2/2] | Step [18018/22538] | Loss: 0.4299 | Accuracy: 0.8721\n","Epoch [2/2] | Step [18019/22538] | Loss: 0.4037 | Accuracy: 0.8720\n","Epoch [2/2] | Step [18020/22538] | Loss: 0.2843 | Accuracy: 0.9229\n","Epoch [2/2] | Step [18021/22538] | Loss: 0.4020 | Accuracy: 0.8793\n","Epoch [2/2] | Step [18022/22538] | Loss: 0.3328 | Accuracy: 0.8962\n","Epoch [2/2] | Step [18023/22538] | Loss: 0.3672 | Accuracy: 0.9211\n","Epoch [2/2] | Step [18024/22538] | Loss: 0.4706 | Accuracy: 0.8844\n","Epoch [2/2] | Step [18025/22538] | Loss: 0.3309 | Accuracy: 0.9118\n","Epoch [2/2] | Step [18026/22538] | Loss: 0.4511 | Accuracy: 0.8934\n","Epoch [2/2] | Step [18027/22538] | Loss: 0.3010 | Accuracy: 0.9082\n","Epoch [2/2] | Step [18028/22538] | Loss: 0.3679 | Accuracy: 0.9145\n","Epoch [2/2] | Step [18029/22538] | Loss: 0.2799 | Accuracy: 0.9185\n","Epoch [2/2] | Step [18030/22538] | Loss: 0.4412 | Accuracy: 0.8700\n","Epoch [2/2] | Step [18031/22538] | Loss: 0.2522 | Accuracy: 0.9216\n","Epoch [2/2] | Step [18032/22538] | Loss: 0.1817 | Accuracy: 0.9345\n","Epoch [2/2] | Step [18033/22538] | Loss: 0.3312 | Accuracy: 0.9040\n","Epoch [2/2] | Step [18034/22538] | Loss: 0.3595 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18035/22538] | Loss: 0.3833 | Accuracy: 0.8966\n","Epoch [2/2] | Step [18036/22538] | Loss: 0.2945 | Accuracy: 0.9120\n","Epoch [2/2] | Step [18037/22538] | Loss: 0.2845 | Accuracy: 0.9087\n","Epoch [2/2] | Step [18038/22538] | Loss: 0.3155 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18039/22538] | Loss: 0.3723 | Accuracy: 0.8980\n","Epoch [2/2] | Step [18040/22538] | Loss: 0.3064 | Accuracy: 0.9050\n","Epoch [2/2] | Step [18041/22538] | Loss: 0.3079 | Accuracy: 0.9058\n","Epoch [2/2] | Step [18042/22538] | Loss: 0.4926 | Accuracy: 0.8779\n","Epoch [2/2] | Step [18043/22538] | Loss: 0.2368 | Accuracy: 0.9236\n","Epoch [2/2] | Step [18044/22538] | Loss: 0.3721 | Accuracy: 0.8994\n","Epoch [2/2] | Step [18045/22538] | Loss: 0.4147 | Accuracy: 0.8902\n","Epoch [2/2] | Step [18046/22538] | Loss: 0.4026 | Accuracy: 0.8955\n","Epoch [2/2] | Step [18047/22538] | Loss: 0.3270 | Accuracy: 0.9087\n","Epoch [2/2] | Step [18048/22538] | Loss: 0.2702 | Accuracy: 0.9242\n","Epoch [2/2] | Step [18049/22538] | Loss: 0.3054 | Accuracy: 0.9241\n","Epoch [2/2] | Step [18050/22538] | Loss: 0.2658 | Accuracy: 0.9280\n","Epoch [2/2] | Step [18051/22538] | Loss: 0.2619 | Accuracy: 0.9291\n","Epoch [2/2] | Step [18052/22538] | Loss: 0.1864 | Accuracy: 0.9500\n","Epoch [2/2] | Step [18053/22538] | Loss: 0.3590 | Accuracy: 0.9035\n","Epoch [2/2] | Step [18054/22538] | Loss: 0.3908 | Accuracy: 0.9031\n","Epoch [2/2] | Step [18055/22538] | Loss: 0.3106 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18056/22538] | Loss: 0.2917 | Accuracy: 0.9033\n","Epoch [2/2] | Step [18057/22538] | Loss: 0.4180 | Accuracy: 0.8929\n","Epoch [2/2] | Step [18058/22538] | Loss: 0.3123 | Accuracy: 0.8976\n","Epoch [2/2] | Step [18059/22538] | Loss: 0.2363 | Accuracy: 0.9434\n","Epoch [2/2] | Step [18060/22538] | Loss: 0.3853 | Accuracy: 0.8938\n","Epoch [2/2] | Step [18061/22538] | Loss: 0.4099 | Accuracy: 0.8946\n","Epoch [2/2] | Step [18062/22538] | Loss: 0.5128 | Accuracy: 0.8542\n","Epoch [2/2] | Step [18063/22538] | Loss: 0.2966 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18064/22538] | Loss: 0.3723 | Accuracy: 0.8784\n","Epoch [2/2] | Step [18065/22538] | Loss: 0.3921 | Accuracy: 0.8989\n","Epoch [2/2] | Step [18066/22538] | Loss: 0.2983 | Accuracy: 0.9224\n","Epoch [2/2] | Step [18067/22538] | Loss: 0.3075 | Accuracy: 0.9048\n","Epoch [2/2] | Step [18068/22538] | Loss: 0.2267 | Accuracy: 0.9310\n","Epoch [2/2] | Step [18069/22538] | Loss: 0.3421 | Accuracy: 0.9035\n","Epoch [2/2] | Step [18070/22538] | Loss: 0.3624 | Accuracy: 0.8958\n","Epoch [2/2] | Step [18071/22538] | Loss: 0.3212 | Accuracy: 0.9063\n","Epoch [2/2] | Step [18072/22538] | Loss: 0.1812 | Accuracy: 0.9513\n","Epoch [2/2] | Step [18073/22538] | Loss: 0.3806 | Accuracy: 0.8892\n","Epoch [2/2] | Step [18074/22538] | Loss: 0.3286 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18075/22538] | Loss: 0.3394 | Accuracy: 0.9141\n","Epoch [2/2] | Step [18076/22538] | Loss: 0.3678 | Accuracy: 0.9021\n","Epoch [2/2] | Step [18077/22538] | Loss: 0.3874 | Accuracy: 0.8925\n","Epoch [2/2] | Step [18078/22538] | Loss: 0.3251 | Accuracy: 0.9035\n","Epoch [2/2] | Step [18079/22538] | Loss: 0.4937 | Accuracy: 0.8833\n","Epoch [2/2] | Step [18080/22538] | Loss: 0.3610 | Accuracy: 0.8958\n","Epoch [2/2] | Step [18081/22538] | Loss: 0.2149 | Accuracy: 0.9318\n","Epoch [2/2] | Step [18082/22538] | Loss: 0.3515 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18083/22538] | Loss: 0.2926 | Accuracy: 0.9264\n","Epoch [2/2] | Step [18084/22538] | Loss: 0.2508 | Accuracy: 0.9203\n","Epoch [2/2] | Step [18085/22538] | Loss: 0.1804 | Accuracy: 0.9491\n","Epoch [2/2] | Step [18086/22538] | Loss: 0.2950 | Accuracy: 0.9116\n","Epoch [2/2] | Step [18087/22538] | Loss: 0.2883 | Accuracy: 0.9202\n","Epoch [2/2] | Step [18088/22538] | Loss: 0.2441 | Accuracy: 0.9412\n","Epoch [2/2] | Step [18089/22538] | Loss: 0.3246 | Accuracy: 0.9115\n","Epoch [2/2] | Step [18090/22538] | Loss: 0.3242 | Accuracy: 0.9130\n","Epoch [2/2] | Step [18091/22538] | Loss: 0.2146 | Accuracy: 0.9422\n","Epoch [2/2] | Step [18092/22538] | Loss: 0.2868 | Accuracy: 0.9073\n","Epoch [2/2] | Step [18093/22538] | Loss: 0.3722 | Accuracy: 0.8953\n","Epoch [2/2] | Step [18094/22538] | Loss: 0.4106 | Accuracy: 0.8980\n","Epoch [2/2] | Step [18095/22538] | Loss: 0.2944 | Accuracy: 0.9038\n","Epoch [2/2] | Step [18096/22538] | Loss: 0.3585 | Accuracy: 0.9009\n","Epoch [2/2] | Step [18097/22538] | Loss: 0.2810 | Accuracy: 0.9223\n","Epoch [2/2] | Step [18098/22538] | Loss: 0.4529 | Accuracy: 0.8942\n","Epoch [2/2] | Step [18099/22538] | Loss: 0.3108 | Accuracy: 0.9082\n","Epoch [2/2] | Step [18100/22538] | Loss: 0.2886 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18101/22538] | Loss: 0.3954 | Accuracy: 0.8875\n","Epoch [2/2] | Step [18102/22538] | Loss: 0.2175 | Accuracy: 0.9392\n","Epoch [2/2] | Step [18103/22538] | Loss: 0.2280 | Accuracy: 0.9275\n","Epoch [2/2] | Step [18104/22538] | Loss: 0.2693 | Accuracy: 0.9303\n","Epoch [2/2] | Step [18105/22538] | Loss: 0.2836 | Accuracy: 0.9186\n","Epoch [2/2] | Step [18106/22538] | Loss: 0.5273 | Accuracy: 0.8454\n","Epoch [2/2] | Step [18107/22538] | Loss: 0.3587 | Accuracy: 0.9043\n","Epoch [2/2] | Step [18108/22538] | Loss: 0.2331 | Accuracy: 0.9358\n","Epoch [2/2] | Step [18109/22538] | Loss: 0.2879 | Accuracy: 0.9311\n","Epoch [2/2] | Step [18110/22538] | Loss: 0.2598 | Accuracy: 0.9195\n","Epoch [2/2] | Step [18111/22538] | Loss: 0.3459 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18112/22538] | Loss: 0.3120 | Accuracy: 0.9295\n","Epoch [2/2] | Step [18113/22538] | Loss: 0.3323 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18114/22538] | Loss: 0.2477 | Accuracy: 0.9277\n","Epoch [2/2] | Step [18115/22538] | Loss: 0.1633 | Accuracy: 0.9468\n","Epoch [2/2] | Step [18116/22538] | Loss: 0.2891 | Accuracy: 0.9129\n","Epoch [2/2] | Step [18117/22538] | Loss: 0.4390 | Accuracy: 0.8821\n","Epoch [2/2] | Step [18118/22538] | Loss: 0.4030 | Accuracy: 0.9091\n","Epoch [2/2] | Step [18119/22538] | Loss: 0.2832 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18120/22538] | Loss: 0.2527 | Accuracy: 0.9214\n","Epoch [2/2] | Step [18121/22538] | Loss: 0.2809 | Accuracy: 0.9048\n","Epoch [2/2] | Step [18122/22538] | Loss: 0.3981 | Accuracy: 0.8827\n","Epoch [2/2] | Step [18123/22538] | Loss: 0.3725 | Accuracy: 0.9056\n","Epoch [2/2] | Step [18124/22538] | Loss: 0.2916 | Accuracy: 0.9069\n","Epoch [2/2] | Step [18125/22538] | Loss: 0.4063 | Accuracy: 0.9083\n","Epoch [2/2] | Step [18126/22538] | Loss: 0.5728 | Accuracy: 0.8438\n","Epoch [2/2] | Step [18127/22538] | Loss: 0.3192 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18128/22538] | Loss: 0.3095 | Accuracy: 0.9011\n","Epoch [2/2] | Step [18129/22538] | Loss: 0.2474 | Accuracy: 0.9365\n","Epoch [2/2] | Step [18130/22538] | Loss: 0.3031 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18131/22538] | Loss: 0.3249 | Accuracy: 0.9111\n","Epoch [2/2] | Step [18132/22538] | Loss: 0.1857 | Accuracy: 0.9384\n","Epoch [2/2] | Step [18133/22538] | Loss: 0.4415 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18134/22538] | Loss: 0.2680 | Accuracy: 0.9151\n","Epoch [2/2] | Step [18135/22538] | Loss: 0.1968 | Accuracy: 0.9365\n","Epoch [2/2] | Step [18136/22538] | Loss: 0.3390 | Accuracy: 0.8899\n","Epoch [2/2] | Step [18137/22538] | Loss: 0.3410 | Accuracy: 0.9142\n","Epoch [2/2] | Step [18138/22538] | Loss: 0.3190 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18139/22538] | Loss: 0.3456 | Accuracy: 0.9198\n","Epoch [2/2] | Step [18140/22538] | Loss: 0.3670 | Accuracy: 0.8967\n","Epoch [2/2] | Step [18141/22538] | Loss: 0.4181 | Accuracy: 0.8963\n","Epoch [2/2] | Step [18142/22538] | Loss: 0.4444 | Accuracy: 0.9036\n","Epoch [2/2] | Step [18143/22538] | Loss: 0.3282 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18144/22538] | Loss: 0.4606 | Accuracy: 0.8868\n","Epoch [2/2] | Step [18145/22538] | Loss: 0.4206 | Accuracy: 0.9023\n","Epoch [2/2] | Step [18146/22538] | Loss: 0.3490 | Accuracy: 0.9018\n","Epoch [2/2] | Step [18147/22538] | Loss: 0.3629 | Accuracy: 0.9052\n","Epoch [2/2] | Step [18148/22538] | Loss: 0.2643 | Accuracy: 0.9312\n","Epoch [2/2] | Step [18149/22538] | Loss: 0.4562 | Accuracy: 0.8873\n","Epoch [2/2] | Step [18150/22538] | Loss: 0.3597 | Accuracy: 0.8986\n","Epoch [2/2] | Step [18151/22538] | Loss: 0.3495 | Accuracy: 0.8914\n","Epoch [2/2] | Step [18152/22538] | Loss: 0.3173 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18153/22538] | Loss: 0.3304 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18154/22538] | Loss: 0.2962 | Accuracy: 0.9286\n","Epoch [2/2] | Step [18155/22538] | Loss: 0.3607 | Accuracy: 0.8828\n","Epoch [2/2] | Step [18156/22538] | Loss: 0.2932 | Accuracy: 0.9085\n","Epoch [2/2] | Step [18157/22538] | Loss: 0.4737 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18158/22538] | Loss: 0.3104 | Accuracy: 0.9044\n","Epoch [2/2] | Step [18159/22538] | Loss: 0.2980 | Accuracy: 0.9194\n","Epoch [2/2] | Step [18160/22538] | Loss: 0.3452 | Accuracy: 0.9009\n","Epoch [2/2] | Step [18161/22538] | Loss: 0.2459 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18162/22538] | Loss: 0.2790 | Accuracy: 0.9127\n","Epoch [2/2] | Step [18163/22538] | Loss: 0.5656 | Accuracy: 0.8778\n","Epoch [2/2] | Step [18164/22538] | Loss: 0.1714 | Accuracy: 0.9531\n","Epoch [2/2] | Step [18165/22538] | Loss: 0.2577 | Accuracy: 0.9232\n","Epoch [2/2] | Step [18166/22538] | Loss: 0.2624 | Accuracy: 0.9322\n","Epoch [2/2] | Step [18167/22538] | Loss: 0.3727 | Accuracy: 0.9069\n","Epoch [2/2] | Step [18168/22538] | Loss: 0.3202 | Accuracy: 0.9142\n","Epoch [2/2] | Step [18169/22538] | Loss: 0.2755 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18170/22538] | Loss: 0.3989 | Accuracy: 0.8986\n","Epoch [2/2] | Step [18171/22538] | Loss: 0.3986 | Accuracy: 0.8980\n","Epoch [2/2] | Step [18172/22538] | Loss: 0.2501 | Accuracy: 0.9237\n","Epoch [2/2] | Step [18173/22538] | Loss: 0.2832 | Accuracy: 0.9213\n","Epoch [2/2] | Step [18174/22538] | Loss: 0.2889 | Accuracy: 0.9337\n","Epoch [2/2] | Step [18175/22538] | Loss: 0.2033 | Accuracy: 0.9384\n","Epoch [2/2] | Step [18176/22538] | Loss: 0.2247 | Accuracy: 0.9313\n","Epoch [2/2] | Step [18177/22538] | Loss: 0.4010 | Accuracy: 0.8880\n","Epoch [2/2] | Step [18178/22538] | Loss: 0.2514 | Accuracy: 0.9219\n","Epoch [2/2] | Step [18179/22538] | Loss: 0.3952 | Accuracy: 0.9031\n","Epoch [2/2] | Step [18180/22538] | Loss: 0.2636 | Accuracy: 0.9300\n","Epoch [2/2] | Step [18181/22538] | Loss: 0.2135 | Accuracy: 0.9435\n","Epoch [2/2] | Step [18182/22538] | Loss: 0.3358 | Accuracy: 0.9038\n","Epoch [2/2] | Step [18183/22538] | Loss: 0.3582 | Accuracy: 0.8932\n","Epoch [2/2] | Step [18184/22538] | Loss: 0.3582 | Accuracy: 0.8868\n","Epoch [2/2] | Step [18185/22538] | Loss: 0.3372 | Accuracy: 0.9129\n","Epoch [2/2] | Step [18186/22538] | Loss: 0.3540 | Accuracy: 0.9111\n","Epoch [2/2] | Step [18187/22538] | Loss: 0.4290 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18188/22538] | Loss: 0.2130 | Accuracy: 0.9359\n","Epoch [2/2] | Step [18189/22538] | Loss: 0.2837 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18190/22538] | Loss: 0.5047 | Accuracy: 0.8811\n","Epoch [2/2] | Step [18191/22538] | Loss: 0.2958 | Accuracy: 0.9133\n","Epoch [2/2] | Step [18192/22538] | Loss: 0.4093 | Accuracy: 0.8792\n","Epoch [2/2] | Step [18193/22538] | Loss: 0.3172 | Accuracy: 0.9068\n","Epoch [2/2] | Step [18194/22538] | Loss: 0.2873 | Accuracy: 0.9201\n","Epoch [2/2] | Step [18195/22538] | Loss: 0.3857 | Accuracy: 0.8950\n","Epoch [2/2] | Step [18196/22538] | Loss: 0.3179 | Accuracy: 0.9222\n","Epoch [2/2] | Step [18197/22538] | Loss: 0.3025 | Accuracy: 0.9238\n","Epoch [2/2] | Step [18198/22538] | Loss: 0.2140 | Accuracy: 0.9442\n","Epoch [2/2] | Step [18199/22538] | Loss: 0.5042 | Accuracy: 0.8564\n","Epoch [2/2] | Step [18200/22538] | Loss: 0.3472 | Accuracy: 0.9116\n","Epoch [2/2] | Step [18201/22538] | Loss: 0.2692 | Accuracy: 0.9274\n","Epoch [2/2] | Step [18202/22538] | Loss: 0.3621 | Accuracy: 0.8889\n","Epoch [2/2] | Step [18203/22538] | Loss: 0.3626 | Accuracy: 0.8984\n","Epoch [2/2] | Step [18204/22538] | Loss: 0.2410 | Accuracy: 0.9188\n","Epoch [2/2] | Step [18205/22538] | Loss: 0.2904 | Accuracy: 0.9069\n","Epoch [2/2] | Step [18206/22538] | Loss: 0.2892 | Accuracy: 0.9209\n","Epoch [2/2] | Step [18207/22538] | Loss: 0.3306 | Accuracy: 0.9110\n","Epoch [2/2] | Step [18208/22538] | Loss: 0.2962 | Accuracy: 0.9253\n","Epoch [2/2] | Step [18209/22538] | Loss: 0.2877 | Accuracy: 0.9172\n","Epoch [2/2] | Step [18210/22538] | Loss: 0.3741 | Accuracy: 0.9067\n","Epoch [2/2] | Step [18211/22538] | Loss: 0.3146 | Accuracy: 0.9236\n","Epoch [2/2] | Step [18212/22538] | Loss: 0.3610 | Accuracy: 0.9075\n","Epoch [2/2] | Step [18213/22538] | Loss: 0.3783 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18214/22538] | Loss: 0.2983 | Accuracy: 0.9190\n","Epoch [2/2] | Step [18215/22538] | Loss: 0.2789 | Accuracy: 0.9118\n","Epoch [2/2] | Step [18216/22538] | Loss: 0.2663 | Accuracy: 0.9183\n","Epoch [2/2] | Step [18217/22538] | Loss: 0.3289 | Accuracy: 0.9073\n","Epoch [2/2] | Step [18218/22538] | Loss: 0.3080 | Accuracy: 0.9219\n","Epoch [2/2] | Step [18219/22538] | Loss: 0.4918 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18220/22538] | Loss: 0.2752 | Accuracy: 0.9239\n","Epoch [2/2] | Step [18221/22538] | Loss: 0.3712 | Accuracy: 0.8858\n","Epoch [2/2] | Step [18222/22538] | Loss: 0.1962 | Accuracy: 0.9519\n","Epoch [2/2] | Step [18223/22538] | Loss: 0.3350 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18224/22538] | Loss: 0.3929 | Accuracy: 0.8926\n","Epoch [2/2] | Step [18225/22538] | Loss: 0.3476 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18226/22538] | Loss: 0.3326 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18227/22538] | Loss: 0.1994 | Accuracy: 0.9390\n","Epoch [2/2] | Step [18228/22538] | Loss: 0.4176 | Accuracy: 0.8815\n","Epoch [2/2] | Step [18229/22538] | Loss: 0.2020 | Accuracy: 0.9430\n","Epoch [2/2] | Step [18230/22538] | Loss: 0.3284 | Accuracy: 0.9050\n","Epoch [2/2] | Step [18231/22538] | Loss: 0.2507 | Accuracy: 0.9180\n","Epoch [2/2] | Step [18232/22538] | Loss: 0.2544 | Accuracy: 0.9225\n","Epoch [2/2] | Step [18233/22538] | Loss: 0.2684 | Accuracy: 0.9190\n","Epoch [2/2] | Step [18234/22538] | Loss: 0.2077 | Accuracy: 0.9344\n","Epoch [2/2] | Step [18235/22538] | Loss: 0.2617 | Accuracy: 0.9130\n","Epoch [2/2] | Step [18236/22538] | Loss: 0.4883 | Accuracy: 0.8679\n","Epoch [2/2] | Step [18237/22538] | Loss: 0.5221 | Accuracy: 0.8813\n","Epoch [2/2] | Step [18238/22538] | Loss: 0.3738 | Accuracy: 0.9048\n","Epoch [2/2] | Step [18239/22538] | Loss: 0.1593 | Accuracy: 0.9491\n","Epoch [2/2] | Step [18240/22538] | Loss: 0.3323 | Accuracy: 0.9101\n","Epoch [2/2] | Step [18241/22538] | Loss: 0.3676 | Accuracy: 0.8929\n","Epoch [2/2] | Step [18242/22538] | Loss: 0.3339 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18243/22538] | Loss: 0.3342 | Accuracy: 0.8966\n","Epoch [2/2] | Step [18244/22538] | Loss: 0.3416 | Accuracy: 0.9159\n","Epoch [2/2] | Step [18245/22538] | Loss: 0.2705 | Accuracy: 0.9182\n","Epoch [2/2] | Step [18246/22538] | Loss: 0.4233 | Accuracy: 0.8728\n","Epoch [2/2] | Step [18247/22538] | Loss: 0.3967 | Accuracy: 0.8878\n","Epoch [2/2] | Step [18248/22538] | Loss: 0.3729 | Accuracy: 0.8991\n","Epoch [2/2] | Step [18249/22538] | Loss: 0.3290 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18250/22538] | Loss: 0.3132 | Accuracy: 0.9160\n","Epoch [2/2] | Step [18251/22538] | Loss: 0.3569 | Accuracy: 0.8798\n","Epoch [2/2] | Step [18252/22538] | Loss: 0.4037 | Accuracy: 0.8915\n","Epoch [2/2] | Step [18253/22538] | Loss: 0.4738 | Accuracy: 0.8821\n","Epoch [2/2] | Step [18254/22538] | Loss: 0.3262 | Accuracy: 0.9063\n","Epoch [2/2] | Step [18255/22538] | Loss: 0.2579 | Accuracy: 0.9384\n","Epoch [2/2] | Step [18256/22538] | Loss: 0.2386 | Accuracy: 0.9265\n","Epoch [2/2] | Step [18257/22538] | Loss: 0.2626 | Accuracy: 0.9257\n","Epoch [2/2] | Step [18258/22538] | Loss: 0.2637 | Accuracy: 0.9286\n","Epoch [2/2] | Step [18259/22538] | Loss: 0.2444 | Accuracy: 0.9384\n","Epoch [2/2] | Step [18260/22538] | Loss: 0.3526 | Accuracy: 0.8947\n","Epoch [2/2] | Step [18261/22538] | Loss: 0.3642 | Accuracy: 0.8825\n","Epoch [2/2] | Step [18262/22538] | Loss: 0.3014 | Accuracy: 0.9212\n","Epoch [2/2] | Step [18263/22538] | Loss: 0.3673 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18264/22538] | Loss: 0.5042 | Accuracy: 0.8675\n","Epoch [2/2] | Step [18265/22538] | Loss: 0.4342 | Accuracy: 0.8858\n","Epoch [2/2] | Step [18266/22538] | Loss: 0.3028 | Accuracy: 0.9188\n","Epoch [2/2] | Step [18267/22538] | Loss: 0.2884 | Accuracy: 0.9290\n","Epoch [2/2] | Step [18268/22538] | Loss: 0.3415 | Accuracy: 0.9067\n","Epoch [2/2] | Step [18269/22538] | Loss: 0.3279 | Accuracy: 0.9076\n","Epoch [2/2] | Step [18270/22538] | Loss: 0.3191 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18271/22538] | Loss: 0.4994 | Accuracy: 0.8724\n","Epoch [2/2] | Step [18272/22538] | Loss: 0.2539 | Accuracy: 0.9327\n","Epoch [2/2] | Step [18273/22538] | Loss: 0.3919 | Accuracy: 0.8864\n","Epoch [2/2] | Step [18274/22538] | Loss: 0.2833 | Accuracy: 0.9261\n","Epoch [2/2] | Step [18275/22538] | Loss: 0.3366 | Accuracy: 0.9096\n","Epoch [2/2] | Step [18276/22538] | Loss: 0.3726 | Accuracy: 0.8967\n","Epoch [2/2] | Step [18277/22538] | Loss: 0.2298 | Accuracy: 0.9395\n","Epoch [2/2] | Step [18278/22538] | Loss: 0.4423 | Accuracy: 0.8670\n","Epoch [2/2] | Step [18279/22538] | Loss: 0.1772 | Accuracy: 0.9426\n","Epoch [2/2] | Step [18280/22538] | Loss: 0.2843 | Accuracy: 0.9123\n","Epoch [2/2] | Step [18281/22538] | Loss: 0.4083 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18282/22538] | Loss: 0.3612 | Accuracy: 0.8969\n","Epoch [2/2] | Step [18283/22538] | Loss: 0.3890 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18284/22538] | Loss: 0.3246 | Accuracy: 0.9137\n","Epoch [2/2] | Step [18285/22538] | Loss: 0.4005 | Accuracy: 0.8934\n","Epoch [2/2] | Step [18286/22538] | Loss: 0.4058 | Accuracy: 0.8897\n","Epoch [2/2] | Step [18287/22538] | Loss: 0.3911 | Accuracy: 0.8984\n","Epoch [2/2] | Step [18288/22538] | Loss: 0.3837 | Accuracy: 0.8983\n","Epoch [2/2] | Step [18289/22538] | Loss: 0.3236 | Accuracy: 0.9122\n","Epoch [2/2] | Step [18290/22538] | Loss: 0.2633 | Accuracy: 0.9311\n","Epoch [2/2] | Step [18291/22538] | Loss: 0.4066 | Accuracy: 0.8838\n","Epoch [2/2] | Step [18292/22538] | Loss: 0.2463 | Accuracy: 0.9333\n","Epoch [2/2] | Step [18293/22538] | Loss: 0.2969 | Accuracy: 0.9038\n","Epoch [2/2] | Step [18294/22538] | Loss: 0.2465 | Accuracy: 0.9395\n","Epoch [2/2] | Step [18295/22538] | Loss: 0.2328 | Accuracy: 0.9310\n","Epoch [2/2] | Step [18296/22538] | Loss: 0.2585 | Accuracy: 0.9153\n","Epoch [2/2] | Step [18297/22538] | Loss: 0.3915 | Accuracy: 0.8962\n","Epoch [2/2] | Step [18298/22538] | Loss: 0.4899 | Accuracy: 0.8625\n","Epoch [2/2] | Step [18299/22538] | Loss: 0.3257 | Accuracy: 0.9040\n","Epoch [2/2] | Step [18300/22538] | Loss: 0.4764 | Accuracy: 0.8564\n","Epoch [2/2] | Step [18301/22538] | Loss: 0.2559 | Accuracy: 0.9300\n","Epoch [2/2] | Step [18302/22538] | Loss: 0.3756 | Accuracy: 0.8992\n","Epoch [2/2] | Step [18303/22538] | Loss: 0.3647 | Accuracy: 0.8962\n","Epoch [2/2] | Step [18304/22538] | Loss: 0.2164 | Accuracy: 0.9291\n","Epoch [2/2] | Step [18305/22538] | Loss: 0.4189 | Accuracy: 0.8958\n","Epoch [2/2] | Step [18306/22538] | Loss: 0.3348 | Accuracy: 0.9179\n","Epoch [2/2] | Step [18307/22538] | Loss: 0.3571 | Accuracy: 0.9116\n","Epoch [2/2] | Step [18308/22538] | Loss: 0.2211 | Accuracy: 0.9241\n","Epoch [2/2] | Step [18309/22538] | Loss: 0.3709 | Accuracy: 0.8963\n","Epoch [2/2] | Step [18310/22538] | Loss: 0.3792 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18311/22538] | Loss: 0.3558 | Accuracy: 0.9014\n","Epoch [2/2] | Step [18312/22538] | Loss: 0.3486 | Accuracy: 0.9012\n","Epoch [2/2] | Step [18313/22538] | Loss: 0.3853 | Accuracy: 0.8971\n","Epoch [2/2] | Step [18314/22538] | Loss: 0.3094 | Accuracy: 0.9144\n","Epoch [2/2] | Step [18315/22538] | Loss: 0.3605 | Accuracy: 0.8983\n","Epoch [2/2] | Step [18316/22538] | Loss: 0.3453 | Accuracy: 0.9079\n","Epoch [2/2] | Step [18317/22538] | Loss: 0.2690 | Accuracy: 0.9266\n","Epoch [2/2] | Step [18318/22538] | Loss: 0.2345 | Accuracy: 0.9354\n","Epoch [2/2] | Step [18319/22538] | Loss: 0.4060 | Accuracy: 0.8942\n","Epoch [2/2] | Step [18320/22538] | Loss: 0.2879 | Accuracy: 0.9200\n","Epoch [2/2] | Step [18321/22538] | Loss: 0.3398 | Accuracy: 0.9129\n","Epoch [2/2] | Step [18322/22538] | Loss: 0.3420 | Accuracy: 0.9026\n","Epoch [2/2] | Step [18323/22538] | Loss: 0.4267 | Accuracy: 0.8773\n","Epoch [2/2] | Step [18324/22538] | Loss: 0.5486 | Accuracy: 0.8686\n","Epoch [2/2] | Step [18325/22538] | Loss: 0.5250 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18326/22538] | Loss: 0.2901 | Accuracy: 0.9191\n","Epoch [2/2] | Step [18327/22538] | Loss: 0.2960 | Accuracy: 0.9138\n","Epoch [2/2] | Step [18328/22538] | Loss: 0.2888 | Accuracy: 0.9179\n","Epoch [2/2] | Step [18329/22538] | Loss: 0.3742 | Accuracy: 0.8860\n","Epoch [2/2] | Step [18330/22538] | Loss: 0.2798 | Accuracy: 0.9256\n","Epoch [2/2] | Step [18331/22538] | Loss: 0.3237 | Accuracy: 0.9212\n","Epoch [2/2] | Step [18332/22538] | Loss: 0.3529 | Accuracy: 0.8986\n","Epoch [2/2] | Step [18333/22538] | Loss: 0.3800 | Accuracy: 0.8780\n","Epoch [2/2] | Step [18334/22538] | Loss: 0.3773 | Accuracy: 0.9103\n","Epoch [2/2] | Step [18335/22538] | Loss: 0.4411 | Accuracy: 0.8804\n","Epoch [2/2] | Step [18336/22538] | Loss: 0.3089 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18337/22538] | Loss: 0.3637 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18338/22538] | Loss: 0.2589 | Accuracy: 0.9333\n","Epoch [2/2] | Step [18339/22538] | Loss: 0.2233 | Accuracy: 0.9339\n","Epoch [2/2] | Step [18340/22538] | Loss: 0.2404 | Accuracy: 0.9369\n","Epoch [2/2] | Step [18341/22538] | Loss: 0.3654 | Accuracy: 0.9006\n","Epoch [2/2] | Step [18342/22538] | Loss: 0.2928 | Accuracy: 0.9085\n","Epoch [2/2] | Step [18343/22538] | Loss: 0.3144 | Accuracy: 0.9116\n","Epoch [2/2] | Step [18344/22538] | Loss: 0.3257 | Accuracy: 0.9308\n","Epoch [2/2] | Step [18345/22538] | Loss: 0.2376 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18346/22538] | Loss: 0.3199 | Accuracy: 0.9219\n","Epoch [2/2] | Step [18347/22538] | Loss: 0.2821 | Accuracy: 0.9316\n","Epoch [2/2] | Step [18348/22538] | Loss: 0.3043 | Accuracy: 0.9012\n","Epoch [2/2] | Step [18349/22538] | Loss: 0.4654 | Accuracy: 0.8701\n","Epoch [2/2] | Step [18350/22538] | Loss: 0.4535 | Accuracy: 0.8952\n","Epoch [2/2] | Step [18351/22538] | Loss: 0.4413 | Accuracy: 0.8972\n","Epoch [2/2] | Step [18352/22538] | Loss: 0.3211 | Accuracy: 0.9042\n","Epoch [2/2] | Step [18353/22538] | Loss: 0.3982 | Accuracy: 0.8988\n","Epoch [2/2] | Step [18354/22538] | Loss: 0.2809 | Accuracy: 0.9216\n","Epoch [2/2] | Step [18355/22538] | Loss: 0.3940 | Accuracy: 0.8944\n","Epoch [2/2] | Step [18356/22538] | Loss: 0.2174 | Accuracy: 0.9276\n","Epoch [2/2] | Step [18357/22538] | Loss: 0.2762 | Accuracy: 0.9112\n","Epoch [2/2] | Step [18358/22538] | Loss: 0.2916 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18359/22538] | Loss: 0.3692 | Accuracy: 0.8810\n","Epoch [2/2] | Step [18360/22538] | Loss: 0.4073 | Accuracy: 0.8988\n","Epoch [2/2] | Step [18361/22538] | Loss: 0.3033 | Accuracy: 0.9107\n","Epoch [2/2] | Step [18362/22538] | Loss: 0.4434 | Accuracy: 0.8869\n","Epoch [2/2] | Step [18363/22538] | Loss: 0.3260 | Accuracy: 0.8974\n","Epoch [2/2] | Step [18364/22538] | Loss: 0.3252 | Accuracy: 0.9253\n","Epoch [2/2] | Step [18365/22538] | Loss: 0.3217 | Accuracy: 0.9030\n","Epoch [2/2] | Step [18366/22538] | Loss: 0.4100 | Accuracy: 0.8828\n","Epoch [2/2] | Step [18367/22538] | Loss: 0.2530 | Accuracy: 0.9110\n","Epoch [2/2] | Step [18368/22538] | Loss: 0.3507 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18369/22538] | Loss: 0.4960 | Accuracy: 0.8690\n","Epoch [2/2] | Step [18370/22538] | Loss: 0.2555 | Accuracy: 0.9332\n","Epoch [2/2] | Step [18371/22538] | Loss: 0.2680 | Accuracy: 0.9183\n","Epoch [2/2] | Step [18372/22538] | Loss: 0.1998 | Accuracy: 0.9452\n","Epoch [2/2] | Step [18373/22538] | Loss: 0.3123 | Accuracy: 0.9231\n","Epoch [2/2] | Step [18374/22538] | Loss: 0.2926 | Accuracy: 0.9255\n","Epoch [2/2] | Step [18375/22538] | Loss: 0.2818 | Accuracy: 0.9229\n","Epoch [2/2] | Step [18376/22538] | Loss: 0.3256 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18377/22538] | Loss: 0.3949 | Accuracy: 0.8851\n","Epoch [2/2] | Step [18378/22538] | Loss: 0.2921 | Accuracy: 0.9281\n","Epoch [2/2] | Step [18379/22538] | Loss: 0.1666 | Accuracy: 0.9485\n","Epoch [2/2] | Step [18380/22538] | Loss: 0.2266 | Accuracy: 0.9442\n","Epoch [2/2] | Step [18381/22538] | Loss: 0.2933 | Accuracy: 0.9093\n","Epoch [2/2] | Step [18382/22538] | Loss: 0.1522 | Accuracy: 0.9583\n","Epoch [2/2] | Step [18383/22538] | Loss: 0.3404 | Accuracy: 0.9026\n","Epoch [2/2] | Step [18384/22538] | Loss: 0.3320 | Accuracy: 0.9227\n","Epoch [2/2] | Step [18385/22538] | Loss: 0.2430 | Accuracy: 0.9353\n","Epoch [2/2] | Step [18386/22538] | Loss: 0.3830 | Accuracy: 0.8965\n","Epoch [2/2] | Step [18387/22538] | Loss: 0.3561 | Accuracy: 0.9016\n","Epoch [2/2] | Step [18388/22538] | Loss: 0.3221 | Accuracy: 0.9098\n","Epoch [2/2] | Step [18389/22538] | Loss: 0.4383 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18390/22538] | Loss: 0.2807 | Accuracy: 0.9103\n","Epoch [2/2] | Step [18391/22538] | Loss: 0.2298 | Accuracy: 0.9353\n","Epoch [2/2] | Step [18392/22538] | Loss: 0.3202 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18393/22538] | Loss: 0.4169 | Accuracy: 0.8950\n","Epoch [2/2] | Step [18394/22538] | Loss: 0.1670 | Accuracy: 0.9430\n","Epoch [2/2] | Step [18395/22538] | Loss: 0.2524 | Accuracy: 0.9297\n","Epoch [2/2] | Step [18396/22538] | Loss: 0.2931 | Accuracy: 0.9250\n","Epoch [2/2] | Step [18397/22538] | Loss: 0.2599 | Accuracy: 0.9275\n","Epoch [2/2] | Step [18398/22538] | Loss: 0.2737 | Accuracy: 0.9280\n","Epoch [2/2] | Step [18399/22538] | Loss: 0.2018 | Accuracy: 0.9375\n","Epoch [2/2] | Step [18400/22538] | Loss: 0.2758 | Accuracy: 0.9102\n","Epoch [2/2] | Step [18401/22538] | Loss: 0.5081 | Accuracy: 0.8726\n","Epoch [2/2] | Step [18402/22538] | Loss: 0.2846 | Accuracy: 0.9228\n","Epoch [2/2] | Step [18403/22538] | Loss: 0.3058 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18404/22538] | Loss: 0.3083 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18405/22538] | Loss: 0.3387 | Accuracy: 0.8972\n","Epoch [2/2] | Step [18406/22538] | Loss: 0.3566 | Accuracy: 0.8913\n","Epoch [2/2] | Step [18407/22538] | Loss: 0.4621 | Accuracy: 0.8822\n","Epoch [2/2] | Step [18408/22538] | Loss: 0.5105 | Accuracy: 0.8586\n","Epoch [2/2] | Step [18409/22538] | Loss: 0.3145 | Accuracy: 0.9099\n","Epoch [2/2] | Step [18410/22538] | Loss: 0.2692 | Accuracy: 0.9159\n","Epoch [2/2] | Step [18411/22538] | Loss: 0.2645 | Accuracy: 0.9273\n","Epoch [2/2] | Step [18412/22538] | Loss: 0.3353 | Accuracy: 0.8900\n","Epoch [2/2] | Step [18413/22538] | Loss: 0.3514 | Accuracy: 0.8814\n","Epoch [2/2] | Step [18414/22538] | Loss: 0.2840 | Accuracy: 0.9190\n","Epoch [2/2] | Step [18415/22538] | Loss: 0.3881 | Accuracy: 0.8913\n","Epoch [2/2] | Step [18416/22538] | Loss: 0.1904 | Accuracy: 0.9375\n","Epoch [2/2] | Step [18417/22538] | Loss: 0.5067 | Accuracy: 0.8682\n","Epoch [2/2] | Step [18418/22538] | Loss: 0.3745 | Accuracy: 0.9081\n","Epoch [2/2] | Step [18419/22538] | Loss: 0.2693 | Accuracy: 0.9318\n","Epoch [2/2] | Step [18420/22538] | Loss: 0.2851 | Accuracy: 0.9146\n","Epoch [2/2] | Step [18421/22538] | Loss: 0.3116 | Accuracy: 0.9216\n","Epoch [2/2] | Step [18422/22538] | Loss: 0.4183 | Accuracy: 0.9006\n","Epoch [2/2] | Step [18423/22538] | Loss: 0.2301 | Accuracy: 0.9276\n","Epoch [2/2] | Step [18424/22538] | Loss: 0.2718 | Accuracy: 0.9320\n","Epoch [2/2] | Step [18425/22538] | Loss: 0.3561 | Accuracy: 0.8977\n","Epoch [2/2] | Step [18426/22538] | Loss: 0.2581 | Accuracy: 0.9263\n","Epoch [2/2] | Step [18427/22538] | Loss: 0.3277 | Accuracy: 0.9097\n","Epoch [2/2] | Step [18428/22538] | Loss: 0.2443 | Accuracy: 0.9155\n","Epoch [2/2] | Step [18429/22538] | Loss: 0.3882 | Accuracy: 0.8981\n","Epoch [2/2] | Step [18430/22538] | Loss: 0.1963 | Accuracy: 0.9303\n","Epoch [2/2] | Step [18431/22538] | Loss: 0.2176 | Accuracy: 0.9317\n","Epoch [2/2] | Step [18432/22538] | Loss: 0.3597 | Accuracy: 0.9104\n","Epoch [2/2] | Step [18433/22538] | Loss: 0.3043 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18434/22538] | Loss: 0.3527 | Accuracy: 0.8827\n","Epoch [2/2] | Step [18435/22538] | Loss: 0.2939 | Accuracy: 0.9101\n","Epoch [2/2] | Step [18436/22538] | Loss: 0.3072 | Accuracy: 0.9154\n","Epoch [2/2] | Step [18437/22538] | Loss: 0.3194 | Accuracy: 0.9250\n","Epoch [2/2] | Step [18438/22538] | Loss: 0.2829 | Accuracy: 0.9237\n","Epoch [2/2] | Step [18439/22538] | Loss: 0.2580 | Accuracy: 0.9316\n","Epoch [2/2] | Step [18440/22538] | Loss: 0.3885 | Accuracy: 0.8976\n","Epoch [2/2] | Step [18441/22538] | Loss: 0.1844 | Accuracy: 0.9441\n","Epoch [2/2] | Step [18442/22538] | Loss: 0.3196 | Accuracy: 0.9137\n","Epoch [2/2] | Step [18443/22538] | Loss: 0.2063 | Accuracy: 0.9457\n","Epoch [2/2] | Step [18444/22538] | Loss: 0.2972 | Accuracy: 0.9122\n","Epoch [2/2] | Step [18445/22538] | Loss: 0.3547 | Accuracy: 0.9085\n","Epoch [2/2] | Step [18446/22538] | Loss: 0.2664 | Accuracy: 0.9279\n","Epoch [2/2] | Step [18447/22538] | Loss: 0.4972 | Accuracy: 0.8774\n","Epoch [2/2] | Step [18448/22538] | Loss: 0.4307 | Accuracy: 0.8797\n","Epoch [2/2] | Step [18449/22538] | Loss: 0.3005 | Accuracy: 0.9231\n","Epoch [2/2] | Step [18450/22538] | Loss: 0.2057 | Accuracy: 0.9413\n","Epoch [2/2] | Step [18451/22538] | Loss: 0.2593 | Accuracy: 0.9367\n","Epoch [2/2] | Step [18452/22538] | Loss: 0.4358 | Accuracy: 0.8824\n","Epoch [2/2] | Step [18453/22538] | Loss: 0.2439 | Accuracy: 0.9250\n","Epoch [2/2] | Step [18454/22538] | Loss: 0.4336 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18455/22538] | Loss: 0.2575 | Accuracy: 0.9250\n","Epoch [2/2] | Step [18456/22538] | Loss: 0.2248 | Accuracy: 0.9410\n","Epoch [2/2] | Step [18457/22538] | Loss: 0.4841 | Accuracy: 0.8545\n","Epoch [2/2] | Step [18458/22538] | Loss: 0.4356 | Accuracy: 0.8827\n","Epoch [2/2] | Step [18459/22538] | Loss: 0.2318 | Accuracy: 0.9363\n","Epoch [2/2] | Step [18460/22538] | Loss: 0.1909 | Accuracy: 0.9415\n","Epoch [2/2] | Step [18461/22538] | Loss: 0.4515 | Accuracy: 0.8883\n","Epoch [2/2] | Step [18462/22538] | Loss: 0.3188 | Accuracy: 0.9093\n","Epoch [2/2] | Step [18463/22538] | Loss: 0.3750 | Accuracy: 0.8889\n","Epoch [2/2] | Step [18464/22538] | Loss: 0.2719 | Accuracy: 0.9193\n","Epoch [2/2] | Step [18465/22538] | Loss: 0.4476 | Accuracy: 0.8886\n","Epoch [2/2] | Step [18466/22538] | Loss: 0.3364 | Accuracy: 0.9098\n","Epoch [2/2] | Step [18467/22538] | Loss: 0.2680 | Accuracy: 0.9153\n","Epoch [2/2] | Step [18468/22538] | Loss: 0.2789 | Accuracy: 0.9180\n","Epoch [2/2] | Step [18469/22538] | Loss: 0.2296 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18470/22538] | Loss: 0.2879 | Accuracy: 0.9110\n","Epoch [2/2] | Step [18471/22538] | Loss: 0.3595 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18472/22538] | Loss: 0.3553 | Accuracy: 0.9085\n","Epoch [2/2] | Step [18473/22538] | Loss: 0.2588 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18474/22538] | Loss: 0.1903 | Accuracy: 0.9405\n","Epoch [2/2] | Step [18475/22538] | Loss: 0.2780 | Accuracy: 0.9255\n","Epoch [2/2] | Step [18476/22538] | Loss: 0.4705 | Accuracy: 0.8777\n","Epoch [2/2] | Step [18477/22538] | Loss: 0.2678 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18478/22538] | Loss: 0.2567 | Accuracy: 0.9198\n","Epoch [2/2] | Step [18479/22538] | Loss: 0.4226 | Accuracy: 0.8803\n","Epoch [2/2] | Step [18480/22538] | Loss: 0.2598 | Accuracy: 0.9273\n","Epoch [2/2] | Step [18481/22538] | Loss: 0.3099 | Accuracy: 0.9336\n","Epoch [2/2] | Step [18482/22538] | Loss: 0.4330 | Accuracy: 0.8719\n","Epoch [2/2] | Step [18483/22538] | Loss: 0.2623 | Accuracy: 0.9321\n","Epoch [2/2] | Step [18484/22538] | Loss: 0.3225 | Accuracy: 0.9198\n","Epoch [2/2] | Step [18485/22538] | Loss: 0.3480 | Accuracy: 0.9191\n","Epoch [2/2] | Step [18486/22538] | Loss: 0.3122 | Accuracy: 0.9241\n","Epoch [2/2] | Step [18487/22538] | Loss: 0.2426 | Accuracy: 0.9382\n","Epoch [2/2] | Step [18488/22538] | Loss: 0.4051 | Accuracy: 0.9006\n","Epoch [2/2] | Step [18489/22538] | Loss: 0.6275 | Accuracy: 0.8611\n","Epoch [2/2] | Step [18490/22538] | Loss: 0.3963 | Accuracy: 0.8867\n","Epoch [2/2] | Step [18491/22538] | Loss: 0.3085 | Accuracy: 0.9199\n","Epoch [2/2] | Step [18492/22538] | Loss: 0.3971 | Accuracy: 0.8918\n","Epoch [2/2] | Step [18493/22538] | Loss: 0.3600 | Accuracy: 0.8938\n","Epoch [2/2] | Step [18494/22538] | Loss: 0.2236 | Accuracy: 0.9364\n","Epoch [2/2] | Step [18495/22538] | Loss: 0.2248 | Accuracy: 0.9355\n","Epoch [2/2] | Step [18496/22538] | Loss: 0.2619 | Accuracy: 0.9211\n","Epoch [2/2] | Step [18497/22538] | Loss: 0.3275 | Accuracy: 0.9144\n","Epoch [2/2] | Step [18498/22538] | Loss: 0.2789 | Accuracy: 0.9091\n","Epoch [2/2] | Step [18499/22538] | Loss: 0.2782 | Accuracy: 0.9014\n","Epoch [2/2] | Step [18500/22538] | Loss: 0.3041 | Accuracy: 0.9079\n","Epoch [2/2] | Step [18501/22538] | Loss: 0.2613 | Accuracy: 0.9407\n","Epoch [2/2] | Step [18502/22538] | Loss: 0.3320 | Accuracy: 0.9089\n","Epoch [2/2] | Step [18503/22538] | Loss: 0.3125 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18504/22538] | Loss: 0.3386 | Accuracy: 0.8951\n","Epoch [2/2] | Step [18505/22538] | Loss: 0.5729 | Accuracy: 0.8726\n","Epoch [2/2] | Step [18506/22538] | Loss: 0.3962 | Accuracy: 0.8669\n","Epoch [2/2] | Step [18507/22538] | Loss: 0.3648 | Accuracy: 0.8977\n","Epoch [2/2] | Step [18508/22538] | Loss: 0.2389 | Accuracy: 0.9297\n","Epoch [2/2] | Step [18509/22538] | Loss: 0.2983 | Accuracy: 0.9068\n","Epoch [2/2] | Step [18510/22538] | Loss: 0.4173 | Accuracy: 0.8775\n","Epoch [2/2] | Step [18511/22538] | Loss: 0.1843 | Accuracy: 0.9514\n","Epoch [2/2] | Step [18512/22538] | Loss: 0.4574 | Accuracy: 0.8618\n","Epoch [2/2] | Step [18513/22538] | Loss: 0.2032 | Accuracy: 0.9335\n","Epoch [2/2] | Step [18514/22538] | Loss: 0.3286 | Accuracy: 0.9176\n","Epoch [2/2] | Step [18515/22538] | Loss: 0.3101 | Accuracy: 0.9075\n","Epoch [2/2] | Step [18516/22538] | Loss: 0.1901 | Accuracy: 0.9392\n","Epoch [2/2] | Step [18517/22538] | Loss: 0.3916 | Accuracy: 0.8903\n","Epoch [2/2] | Step [18518/22538] | Loss: 0.3147 | Accuracy: 0.9071\n","Epoch [2/2] | Step [18519/22538] | Loss: 0.2703 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18520/22538] | Loss: 0.3159 | Accuracy: 0.9127\n","Epoch [2/2] | Step [18521/22538] | Loss: 0.4613 | Accuracy: 0.8795\n","Epoch [2/2] | Step [18522/22538] | Loss: 0.3309 | Accuracy: 0.9057\n","Epoch [2/2] | Step [18523/22538] | Loss: 0.2842 | Accuracy: 0.9148\n","Epoch [2/2] | Step [18524/22538] | Loss: 0.4388 | Accuracy: 0.8696\n","Epoch [2/2] | Step [18525/22538] | Loss: 0.3234 | Accuracy: 0.9180\n","Epoch [2/2] | Step [18526/22538] | Loss: 0.2553 | Accuracy: 0.9312\n","Epoch [2/2] | Step [18527/22538] | Loss: 0.2768 | Accuracy: 0.9239\n","Epoch [2/2] | Step [18528/22538] | Loss: 0.2727 | Accuracy: 0.9086\n","Epoch [2/2] | Step [18529/22538] | Loss: 0.3112 | Accuracy: 0.9104\n","Epoch [2/2] | Step [18530/22538] | Loss: 0.3719 | Accuracy: 0.9043\n","Epoch [2/2] | Step [18531/22538] | Loss: 0.2566 | Accuracy: 0.9329\n","Epoch [2/2] | Step [18532/22538] | Loss: 0.3343 | Accuracy: 0.9219\n","Epoch [2/2] | Step [18533/22538] | Loss: 0.3731 | Accuracy: 0.9049\n","Epoch [2/2] | Step [18534/22538] | Loss: 0.3298 | Accuracy: 0.9033\n","Epoch [2/2] | Step [18535/22538] | Loss: 0.3359 | Accuracy: 0.9116\n","Epoch [2/2] | Step [18536/22538] | Loss: 0.5118 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18537/22538] | Loss: 0.5837 | Accuracy: 0.8464\n","Epoch [2/2] | Step [18538/22538] | Loss: 0.3737 | Accuracy: 0.8938\n","Epoch [2/2] | Step [18539/22538] | Loss: 0.3455 | Accuracy: 0.8967\n","Epoch [2/2] | Step [18540/22538] | Loss: 0.2824 | Accuracy: 0.9355\n","Epoch [2/2] | Step [18541/22538] | Loss: 0.2268 | Accuracy: 0.9366\n","Epoch [2/2] | Step [18542/22538] | Loss: 0.4196 | Accuracy: 0.9021\n","Epoch [2/2] | Step [18543/22538] | Loss: 0.2879 | Accuracy: 0.9214\n","Epoch [2/2] | Step [18544/22538] | Loss: 0.2560 | Accuracy: 0.9260\n","Epoch [2/2] | Step [18545/22538] | Loss: 0.3381 | Accuracy: 0.8958\n","Epoch [2/2] | Step [18546/22538] | Loss: 0.4320 | Accuracy: 0.8979\n","Epoch [2/2] | Step [18547/22538] | Loss: 0.4177 | Accuracy: 0.8969\n","Epoch [2/2] | Step [18548/22538] | Loss: 0.2639 | Accuracy: 0.9375\n","Epoch [2/2] | Step [18549/22538] | Loss: 0.3936 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18550/22538] | Loss: 0.2656 | Accuracy: 0.9231\n","Epoch [2/2] | Step [18551/22538] | Loss: 0.4922 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18552/22538] | Loss: 0.3319 | Accuracy: 0.9032\n","Epoch [2/2] | Step [18553/22538] | Loss: 0.3223 | Accuracy: 0.9274\n","Epoch [2/2] | Step [18554/22538] | Loss: 0.2998 | Accuracy: 0.9187\n","Epoch [2/2] | Step [18555/22538] | Loss: 0.3786 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18556/22538] | Loss: 0.2238 | Accuracy: 0.9390\n","Epoch [2/2] | Step [18557/22538] | Loss: 0.4027 | Accuracy: 0.8883\n","Epoch [2/2] | Step [18558/22538] | Loss: 0.2857 | Accuracy: 0.9187\n","Epoch [2/2] | Step [18559/22538] | Loss: 0.3243 | Accuracy: 0.9160\n","Epoch [2/2] | Step [18560/22538] | Loss: 0.2256 | Accuracy: 0.9343\n","Epoch [2/2] | Step [18561/22538] | Loss: 0.3312 | Accuracy: 0.9147\n","Epoch [2/2] | Step [18562/22538] | Loss: 0.2220 | Accuracy: 0.9232\n","Epoch [2/2] | Step [18563/22538] | Loss: 0.2301 | Accuracy: 0.9324\n","Epoch [2/2] | Step [18564/22538] | Loss: 0.4598 | Accuracy: 0.8778\n","Epoch [2/2] | Step [18565/22538] | Loss: 0.3863 | Accuracy: 0.9082\n","Epoch [2/2] | Step [18566/22538] | Loss: 0.3326 | Accuracy: 0.9127\n","Epoch [2/2] | Step [18567/22538] | Loss: 0.3130 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18568/22538] | Loss: 0.4175 | Accuracy: 0.8819\n","Epoch [2/2] | Step [18569/22538] | Loss: 0.2486 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18570/22538] | Loss: 0.2950 | Accuracy: 0.9274\n","Epoch [2/2] | Step [18571/22538] | Loss: 0.3709 | Accuracy: 0.9045\n","Epoch [2/2] | Step [18572/22538] | Loss: 0.2725 | Accuracy: 0.9180\n","Epoch [2/2] | Step [18573/22538] | Loss: 0.3447 | Accuracy: 0.8850\n","Epoch [2/2] | Step [18574/22538] | Loss: 0.3116 | Accuracy: 0.9082\n","Epoch [2/2] | Step [18575/22538] | Loss: 0.3456 | Accuracy: 0.9038\n","Epoch [2/2] | Step [18576/22538] | Loss: 0.3495 | Accuracy: 0.9014\n","Epoch [2/2] | Step [18577/22538] | Loss: 0.2764 | Accuracy: 0.9240\n","Epoch [2/2] | Step [18578/22538] | Loss: 0.2797 | Accuracy: 0.9329\n","Epoch [2/2] | Step [18579/22538] | Loss: 0.3839 | Accuracy: 0.8866\n","Epoch [2/2] | Step [18580/22538] | Loss: 0.3093 | Accuracy: 0.9035\n","Epoch [2/2] | Step [18581/22538] | Loss: 0.3367 | Accuracy: 0.8938\n","Epoch [2/2] | Step [18582/22538] | Loss: 0.2834 | Accuracy: 0.9303\n","Epoch [2/2] | Step [18583/22538] | Loss: 0.3237 | Accuracy: 0.9149\n","Epoch [2/2] | Step [18584/22538] | Loss: 0.5514 | Accuracy: 0.8598\n","Epoch [2/2] | Step [18585/22538] | Loss: 0.3540 | Accuracy: 0.9194\n","Epoch [2/2] | Step [18586/22538] | Loss: 0.5896 | Accuracy: 0.8681\n","Epoch [2/2] | Step [18587/22538] | Loss: 0.3943 | Accuracy: 0.8935\n","Epoch [2/2] | Step [18588/22538] | Loss: 0.4488 | Accuracy: 0.8833\n","Epoch [2/2] | Step [18589/22538] | Loss: 0.3118 | Accuracy: 0.9093\n","Epoch [2/2] | Step [18590/22538] | Loss: 0.2883 | Accuracy: 0.9250\n","Epoch [2/2] | Step [18591/22538] | Loss: 0.2981 | Accuracy: 0.9083\n","Epoch [2/2] | Step [18592/22538] | Loss: 0.3006 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18593/22538] | Loss: 0.4469 | Accuracy: 0.8975\n","Epoch [2/2] | Step [18594/22538] | Loss: 0.2794 | Accuracy: 0.8893\n","Epoch [2/2] | Step [18595/22538] | Loss: 0.3930 | Accuracy: 0.9014\n","Epoch [2/2] | Step [18596/22538] | Loss: 0.2542 | Accuracy: 0.9236\n","Epoch [2/2] | Step [18597/22538] | Loss: 0.2223 | Accuracy: 0.9334\n","Epoch [2/2] | Step [18598/22538] | Loss: 0.4006 | Accuracy: 0.8988\n","Epoch [2/2] | Step [18599/22538] | Loss: 0.2664 | Accuracy: 0.9238\n","Epoch [2/2] | Step [18600/22538] | Loss: 0.3431 | Accuracy: 0.8995\n","Epoch [2/2] | Step [18601/22538] | Loss: 0.3292 | Accuracy: 0.8983\n","Epoch [2/2] | Step [18602/22538] | Loss: 0.3879 | Accuracy: 0.8919\n","Epoch [2/2] | Step [18603/22538] | Loss: 0.3558 | Accuracy: 0.9045\n","Epoch [2/2] | Step [18604/22538] | Loss: 0.4967 | Accuracy: 0.8904\n","Epoch [2/2] | Step [18605/22538] | Loss: 0.2810 | Accuracy: 0.9077\n","Epoch [2/2] | Step [18606/22538] | Loss: 0.2572 | Accuracy: 0.9212\n","Epoch [2/2] | Step [18607/22538] | Loss: 0.2038 | Accuracy: 0.9452\n","Epoch [2/2] | Step [18608/22538] | Loss: 0.2769 | Accuracy: 0.9315\n","Epoch [2/2] | Step [18609/22538] | Loss: 0.4415 | Accuracy: 0.8884\n","Epoch [2/2] | Step [18610/22538] | Loss: 0.3469 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18611/22538] | Loss: 0.2351 | Accuracy: 0.9329\n","Epoch [2/2] | Step [18612/22538] | Loss: 0.3780 | Accuracy: 0.9035\n","Epoch [2/2] | Step [18613/22538] | Loss: 0.2834 | Accuracy: 0.9268\n","Epoch [2/2] | Step [18614/22538] | Loss: 0.2418 | Accuracy: 0.9242\n","Epoch [2/2] | Step [18615/22538] | Loss: 0.3539 | Accuracy: 0.9202\n","Epoch [2/2] | Step [18616/22538] | Loss: 0.2388 | Accuracy: 0.9226\n","Epoch [2/2] | Step [18617/22538] | Loss: 0.3488 | Accuracy: 0.9129\n","Epoch [2/2] | Step [18618/22538] | Loss: 0.3995 | Accuracy: 0.9011\n","Epoch [2/2] | Step [18619/22538] | Loss: 0.2670 | Accuracy: 0.9111\n","Epoch [2/2] | Step [18620/22538] | Loss: 0.4301 | Accuracy: 0.8971\n","Epoch [2/2] | Step [18621/22538] | Loss: 0.5337 | Accuracy: 0.8693\n","Epoch [2/2] | Step [18622/22538] | Loss: 0.3152 | Accuracy: 0.9219\n","Epoch [2/2] | Step [18623/22538] | Loss: 0.3166 | Accuracy: 0.9096\n","Epoch [2/2] | Step [18624/22538] | Loss: 0.3580 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18625/22538] | Loss: 0.4708 | Accuracy: 0.8785\n","Epoch [2/2] | Step [18626/22538] | Loss: 0.3267 | Accuracy: 0.9120\n","Epoch [2/2] | Step [18627/22538] | Loss: 0.2476 | Accuracy: 0.9339\n","Epoch [2/2] | Step [18628/22538] | Loss: 0.3752 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18629/22538] | Loss: 0.2382 | Accuracy: 0.9397\n","Epoch [2/2] | Step [18630/22538] | Loss: 0.3878 | Accuracy: 0.8946\n","Epoch [2/2] | Step [18631/22538] | Loss: 0.2003 | Accuracy: 0.9269\n","Epoch [2/2] | Step [18632/22538] | Loss: 0.2651 | Accuracy: 0.9232\n","Epoch [2/2] | Step [18633/22538] | Loss: 0.3177 | Accuracy: 0.9240\n","Epoch [2/2] | Step [18634/22538] | Loss: 0.3492 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18635/22538] | Loss: 0.4206 | Accuracy: 0.8942\n","Epoch [2/2] | Step [18636/22538] | Loss: 0.2862 | Accuracy: 0.9067\n","Epoch [2/2] | Step [18637/22538] | Loss: 0.2798 | Accuracy: 0.9175\n","Epoch [2/2] | Step [18638/22538] | Loss: 0.2729 | Accuracy: 0.9173\n","Epoch [2/2] | Step [18639/22538] | Loss: 0.3192 | Accuracy: 0.9189\n","Epoch [2/2] | Step [18640/22538] | Loss: 0.2043 | Accuracy: 0.9457\n","Epoch [2/2] | Step [18641/22538] | Loss: 0.3487 | Accuracy: 0.9016\n","Epoch [2/2] | Step [18642/22538] | Loss: 0.3751 | Accuracy: 0.8929\n","Epoch [2/2] | Step [18643/22538] | Loss: 0.3867 | Accuracy: 0.9141\n","Epoch [2/2] | Step [18644/22538] | Loss: 0.3249 | Accuracy: 0.9010\n","Epoch [2/2] | Step [18645/22538] | Loss: 0.5088 | Accuracy: 0.8723\n","Epoch [2/2] | Step [18646/22538] | Loss: 0.4764 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18647/22538] | Loss: 0.3481 | Accuracy: 0.8850\n","Epoch [2/2] | Step [18648/22538] | Loss: 0.3452 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18649/22538] | Loss: 0.2842 | Accuracy: 0.9192\n","Epoch [2/2] | Step [18650/22538] | Loss: 0.4113 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18651/22538] | Loss: 0.2919 | Accuracy: 0.9245\n","Epoch [2/2] | Step [18652/22538] | Loss: 0.3621 | Accuracy: 0.9050\n","Epoch [2/2] | Step [18653/22538] | Loss: 0.2025 | Accuracy: 0.9321\n","Epoch [2/2] | Step [18654/22538] | Loss: 0.2645 | Accuracy: 0.9191\n","Epoch [2/2] | Step [18655/22538] | Loss: 0.3687 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18656/22538] | Loss: 0.3607 | Accuracy: 0.9096\n","Epoch [2/2] | Step [18657/22538] | Loss: 0.2662 | Accuracy: 0.9390\n","Epoch [2/2] | Step [18658/22538] | Loss: 0.2482 | Accuracy: 0.9223\n","Epoch [2/2] | Step [18659/22538] | Loss: 0.3717 | Accuracy: 0.8958\n","Epoch [2/2] | Step [18660/22538] | Loss: 0.2196 | Accuracy: 0.9330\n","Epoch [2/2] | Step [18661/22538] | Loss: 0.2217 | Accuracy: 0.9292\n","Epoch [2/2] | Step [18662/22538] | Loss: 0.1598 | Accuracy: 0.9555\n","Epoch [2/2] | Step [18663/22538] | Loss: 0.2159 | Accuracy: 0.9325\n","Epoch [2/2] | Step [18664/22538] | Loss: 0.2725 | Accuracy: 0.9315\n","Epoch [2/2] | Step [18665/22538] | Loss: 0.3277 | Accuracy: 0.9127\n","Epoch [2/2] | Step [18666/22538] | Loss: 0.3451 | Accuracy: 0.8963\n","Epoch [2/2] | Step [18667/22538] | Loss: 0.2463 | Accuracy: 0.9139\n","Epoch [2/2] | Step [18668/22538] | Loss: 0.3653 | Accuracy: 0.9031\n","Epoch [2/2] | Step [18669/22538] | Loss: 0.3786 | Accuracy: 0.8886\n","Epoch [2/2] | Step [18670/22538] | Loss: 0.4555 | Accuracy: 0.8611\n","Epoch [2/2] | Step [18671/22538] | Loss: 0.3205 | Accuracy: 0.9180\n","Epoch [2/2] | Step [18672/22538] | Loss: 0.2226 | Accuracy: 0.9503\n","Epoch [2/2] | Step [18673/22538] | Loss: 0.1981 | Accuracy: 0.9418\n","Epoch [2/2] | Step [18674/22538] | Loss: 0.2817 | Accuracy: 0.9306\n","Epoch [2/2] | Step [18675/22538] | Loss: 0.3019 | Accuracy: 0.9034\n","Epoch [2/2] | Step [18676/22538] | Loss: 0.2193 | Accuracy: 0.9375\n","Epoch [2/2] | Step [18677/22538] | Loss: 0.2428 | Accuracy: 0.9196\n","Epoch [2/2] | Step [18678/22538] | Loss: 0.2883 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18679/22538] | Loss: 0.3125 | Accuracy: 0.9085\n","Epoch [2/2] | Step [18680/22538] | Loss: 0.2768 | Accuracy: 0.9242\n","Epoch [2/2] | Step [18681/22538] | Loss: 0.4250 | Accuracy: 0.9070\n","Epoch [2/2] | Step [18682/22538] | Loss: 0.3209 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18683/22538] | Loss: 0.1847 | Accuracy: 0.9450\n","Epoch [2/2] | Step [18684/22538] | Loss: 0.3751 | Accuracy: 0.9022\n","Epoch [2/2] | Step [18685/22538] | Loss: 0.2490 | Accuracy: 0.9173\n","Epoch [2/2] | Step [18686/22538] | Loss: 0.3088 | Accuracy: 0.9159\n","Epoch [2/2] | Step [18687/22538] | Loss: 0.2450 | Accuracy: 0.9189\n","Epoch [2/2] | Step [18688/22538] | Loss: 0.2513 | Accuracy: 0.9282\n","Epoch [2/2] | Step [18689/22538] | Loss: 0.3736 | Accuracy: 0.8955\n","Epoch [2/2] | Step [18690/22538] | Loss: 0.3078 | Accuracy: 0.9030\n","Epoch [2/2] | Step [18691/22538] | Loss: 0.4720 | Accuracy: 0.8858\n","Epoch [2/2] | Step [18692/22538] | Loss: 0.3054 | Accuracy: 0.9089\n","Epoch [2/2] | Step [18693/22538] | Loss: 0.2801 | Accuracy: 0.9122\n","Epoch [2/2] | Step [18694/22538] | Loss: 0.2081 | Accuracy: 0.9384\n","Epoch [2/2] | Step [18695/22538] | Loss: 0.3209 | Accuracy: 0.9209\n","Epoch [2/2] | Step [18696/22538] | Loss: 0.4444 | Accuracy: 0.8729\n","Epoch [2/2] | Step [18697/22538] | Loss: 0.2831 | Accuracy: 0.9194\n","Epoch [2/2] | Step [18698/22538] | Loss: 0.3158 | Accuracy: 0.8965\n","Epoch [2/2] | Step [18699/22538] | Loss: 0.2754 | Accuracy: 0.9149\n","Epoch [2/2] | Step [18700/22538] | Loss: 0.2656 | Accuracy: 0.9219\n","Epoch [2/2] | Step [18701/22538] | Loss: 0.3578 | Accuracy: 0.8886\n","Epoch [2/2] | Step [18702/22538] | Loss: 0.3360 | Accuracy: 0.9044\n","Epoch [2/2] | Step [18703/22538] | Loss: 0.4185 | Accuracy: 0.8961\n","Epoch [2/2] | Step [18704/22538] | Loss: 0.3361 | Accuracy: 0.9111\n","Epoch [2/2] | Step [18705/22538] | Loss: 0.4515 | Accuracy: 0.8814\n","Epoch [2/2] | Step [18706/22538] | Loss: 0.2510 | Accuracy: 0.9331\n","Epoch [2/2] | Step [18707/22538] | Loss: 0.2826 | Accuracy: 0.9255\n","Epoch [2/2] | Step [18708/22538] | Loss: 0.3761 | Accuracy: 0.8710\n","Epoch [2/2] | Step [18709/22538] | Loss: 0.3544 | Accuracy: 0.9030\n","Epoch [2/2] | Step [18710/22538] | Loss: 0.3341 | Accuracy: 0.9091\n","Epoch [2/2] | Step [18711/22538] | Loss: 0.2819 | Accuracy: 0.9153\n","Epoch [2/2] | Step [18712/22538] | Loss: 0.3912 | Accuracy: 0.9058\n","Epoch [2/2] | Step [18713/22538] | Loss: 0.3979 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18714/22538] | Loss: 0.3020 | Accuracy: 0.9078\n","Epoch [2/2] | Step [18715/22538] | Loss: 0.4056 | Accuracy: 0.8958\n","Epoch [2/2] | Step [18716/22538] | Loss: 0.2163 | Accuracy: 0.9406\n","Epoch [2/2] | Step [18717/22538] | Loss: 0.3489 | Accuracy: 0.8977\n","Epoch [2/2] | Step [18718/22538] | Loss: 0.2155 | Accuracy: 0.9320\n","Epoch [2/2] | Step [18719/22538] | Loss: 0.2829 | Accuracy: 0.9160\n","Epoch [2/2] | Step [18720/22538] | Loss: 0.4756 | Accuracy: 0.8672\n","Epoch [2/2] | Step [18721/22538] | Loss: 0.3830 | Accuracy: 0.8983\n","Epoch [2/2] | Step [18722/22538] | Loss: 0.2769 | Accuracy: 0.9135\n","Epoch [2/2] | Step [18723/22538] | Loss: 0.3480 | Accuracy: 0.9037\n","Epoch [2/2] | Step [18724/22538] | Loss: 0.4795 | Accuracy: 0.8884\n","Epoch [2/2] | Step [18725/22538] | Loss: 0.2676 | Accuracy: 0.9247\n","Epoch [2/2] | Step [18726/22538] | Loss: 0.2795 | Accuracy: 0.9226\n","Epoch [2/2] | Step [18727/22538] | Loss: 0.4738 | Accuracy: 0.8693\n","Epoch [2/2] | Step [18728/22538] | Loss: 0.4266 | Accuracy: 0.8814\n","Epoch [2/2] | Step [18729/22538] | Loss: 0.3979 | Accuracy: 0.8920\n","Epoch [2/2] | Step [18730/22538] | Loss: 0.3220 | Accuracy: 0.9145\n","Epoch [2/2] | Step [18731/22538] | Loss: 0.3184 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18732/22538] | Loss: 0.3220 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18733/22538] | Loss: 0.4625 | Accuracy: 0.8771\n","Epoch [2/2] | Step [18734/22538] | Loss: 0.3710 | Accuracy: 0.9045\n","Epoch [2/2] | Step [18735/22538] | Loss: 0.4256 | Accuracy: 0.8605\n","Epoch [2/2] | Step [18736/22538] | Loss: 0.2833 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18737/22538] | Loss: 0.2993 | Accuracy: 0.9175\n","Epoch [2/2] | Step [18738/22538] | Loss: 0.4286 | Accuracy: 0.8910\n","Epoch [2/2] | Step [18739/22538] | Loss: 0.2853 | Accuracy: 0.9229\n","Epoch [2/2] | Step [18740/22538] | Loss: 0.3749 | Accuracy: 0.8889\n","Epoch [2/2] | Step [18741/22538] | Loss: 0.4225 | Accuracy: 0.8841\n","Epoch [2/2] | Step [18742/22538] | Loss: 0.2798 | Accuracy: 0.9236\n","Epoch [2/2] | Step [18743/22538] | Loss: 0.3010 | Accuracy: 0.9209\n","Epoch [2/2] | Step [18744/22538] | Loss: 0.2995 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18745/22538] | Loss: 0.4657 | Accuracy: 0.8587\n","Epoch [2/2] | Step [18746/22538] | Loss: 0.3553 | Accuracy: 0.8996\n","Epoch [2/2] | Step [18747/22538] | Loss: 0.4170 | Accuracy: 0.8830\n","Epoch [2/2] | Step [18748/22538] | Loss: 0.2056 | Accuracy: 0.9480\n","Epoch [2/2] | Step [18749/22538] | Loss: 0.3925 | Accuracy: 0.8871\n","Epoch [2/2] | Step [18750/22538] | Loss: 0.3549 | Accuracy: 0.9200\n","Epoch [2/2] | Step [18751/22538] | Loss: 0.2355 | Accuracy: 0.9316\n","Epoch [2/2] | Step [18752/22538] | Loss: 0.3531 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18753/22538] | Loss: 0.3574 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18754/22538] | Loss: 0.1694 | Accuracy: 0.9533\n","Epoch [2/2] | Step [18755/22538] | Loss: 0.3026 | Accuracy: 0.9057\n","Epoch [2/2] | Step [18756/22538] | Loss: 0.3988 | Accuracy: 0.8929\n","Epoch [2/2] | Step [18757/22538] | Loss: 0.3753 | Accuracy: 0.8975\n","Epoch [2/2] | Step [18758/22538] | Loss: 0.1961 | Accuracy: 0.9267\n","Epoch [2/2] | Step [18759/22538] | Loss: 0.3270 | Accuracy: 0.9098\n","Epoch [2/2] | Step [18760/22538] | Loss: 0.3406 | Accuracy: 0.9004\n","Epoch [2/2] | Step [18761/22538] | Loss: 0.4486 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18762/22538] | Loss: 0.2922 | Accuracy: 0.9175\n","Epoch [2/2] | Step [18763/22538] | Loss: 0.3798 | Accuracy: 0.8810\n","Epoch [2/2] | Step [18764/22538] | Loss: 0.2546 | Accuracy: 0.9414\n","Epoch [2/2] | Step [18765/22538] | Loss: 0.2560 | Accuracy: 0.9099\n","Epoch [2/2] | Step [18766/22538] | Loss: 0.3813 | Accuracy: 0.8946\n","Epoch [2/2] | Step [18767/22538] | Loss: 0.3108 | Accuracy: 0.9069\n","Epoch [2/2] | Step [18768/22538] | Loss: 0.2824 | Accuracy: 0.9258\n","Epoch [2/2] | Step [18769/22538] | Loss: 0.3145 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18770/22538] | Loss: 0.3848 | Accuracy: 0.8986\n","Epoch [2/2] | Step [18771/22538] | Loss: 0.2853 | Accuracy: 0.9196\n","Epoch [2/2] | Step [18772/22538] | Loss: 0.2349 | Accuracy: 0.9364\n","Epoch [2/2] | Step [18773/22538] | Loss: 0.2850 | Accuracy: 0.9068\n","Epoch [2/2] | Step [18774/22538] | Loss: 0.3313 | Accuracy: 0.9026\n","Epoch [2/2] | Step [18775/22538] | Loss: 0.3155 | Accuracy: 0.9128\n","Epoch [2/2] | Step [18776/22538] | Loss: 0.4147 | Accuracy: 0.8816\n","Epoch [2/2] | Step [18777/22538] | Loss: 0.3480 | Accuracy: 0.9222\n","Epoch [2/2] | Step [18778/22538] | Loss: 0.2881 | Accuracy: 0.9114\n","Epoch [2/2] | Step [18779/22538] | Loss: 0.3821 | Accuracy: 0.8977\n","Epoch [2/2] | Step [18780/22538] | Loss: 0.4226 | Accuracy: 0.8895\n","Epoch [2/2] | Step [18781/22538] | Loss: 0.3098 | Accuracy: 0.9256\n","Epoch [2/2] | Step [18782/22538] | Loss: 0.2851 | Accuracy: 0.9174\n","Epoch [2/2] | Step [18783/22538] | Loss: 0.3169 | Accuracy: 0.9085\n","Epoch [2/2] | Step [18784/22538] | Loss: 0.3297 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18785/22538] | Loss: 0.3899 | Accuracy: 0.9056\n","Epoch [2/2] | Step [18786/22538] | Loss: 0.3349 | Accuracy: 0.9138\n","Epoch [2/2] | Step [18787/22538] | Loss: 0.2583 | Accuracy: 0.9237\n","Epoch [2/2] | Step [18788/22538] | Loss: 0.4804 | Accuracy: 0.8591\n","Epoch [2/2] | Step [18789/22538] | Loss: 0.3747 | Accuracy: 0.9136\n","Epoch [2/2] | Step [18790/22538] | Loss: 0.3660 | Accuracy: 0.9152\n","Epoch [2/2] | Step [18791/22538] | Loss: 0.3155 | Accuracy: 0.9135\n","Epoch [2/2] | Step [18792/22538] | Loss: 0.2862 | Accuracy: 0.9268\n","Epoch [2/2] | Step [18793/22538] | Loss: 0.2300 | Accuracy: 0.9238\n","Epoch [2/2] | Step [18794/22538] | Loss: 0.2650 | Accuracy: 0.9405\n","Epoch [2/2] | Step [18795/22538] | Loss: 0.2984 | Accuracy: 0.9221\n","Epoch [2/2] | Step [18796/22538] | Loss: 0.1881 | Accuracy: 0.9420\n","Epoch [2/2] | Step [18797/22538] | Loss: 0.4050 | Accuracy: 0.8896\n","Epoch [2/2] | Step [18798/22538] | Loss: 0.2317 | Accuracy: 0.9415\n","Epoch [2/2] | Step [18799/22538] | Loss: 0.3272 | Accuracy: 0.9028\n","Epoch [2/2] | Step [18800/22538] | Loss: 0.2516 | Accuracy: 0.9306\n","Epoch [2/2] | Step [18801/22538] | Loss: 0.3418 | Accuracy: 0.9095\n","Epoch [2/2] | Step [18802/22538] | Loss: 0.1977 | Accuracy: 0.9500\n","Epoch [2/2] | Step [18803/22538] | Loss: 0.1555 | Accuracy: 0.9587\n","Epoch [2/2] | Step [18804/22538] | Loss: 0.3136 | Accuracy: 0.9132\n","Epoch [2/2] | Step [18805/22538] | Loss: 0.2199 | Accuracy: 0.9412\n","Epoch [2/2] | Step [18806/22538] | Loss: 0.2647 | Accuracy: 0.9307\n","Epoch [2/2] | Step [18807/22538] | Loss: 0.3118 | Accuracy: 0.9247\n","Epoch [2/2] | Step [18808/22538] | Loss: 0.2407 | Accuracy: 0.9306\n","Epoch [2/2] | Step [18809/22538] | Loss: 0.3134 | Accuracy: 0.9134\n","Epoch [2/2] | Step [18810/22538] | Loss: 0.3466 | Accuracy: 0.9048\n","Epoch [2/2] | Step [18811/22538] | Loss: 0.2882 | Accuracy: 0.9174\n","Epoch [2/2] | Step [18812/22538] | Loss: 0.3090 | Accuracy: 0.9114\n","Epoch [2/2] | Step [18813/22538] | Loss: 0.4248 | Accuracy: 0.9014\n","Epoch [2/2] | Step [18814/22538] | Loss: 0.2802 | Accuracy: 0.9225\n","Epoch [2/2] | Step [18815/22538] | Loss: 0.2394 | Accuracy: 0.9224\n","Epoch [2/2] | Step [18816/22538] | Loss: 0.3357 | Accuracy: 0.9054\n","Epoch [2/2] | Step [18817/22538] | Loss: 0.1684 | Accuracy: 0.9491\n","Epoch [2/2] | Step [18818/22538] | Loss: 0.2781 | Accuracy: 0.9258\n","Epoch [2/2] | Step [18819/22538] | Loss: 0.3722 | Accuracy: 0.8850\n","Epoch [2/2] | Step [18820/22538] | Loss: 0.2486 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18821/22538] | Loss: 0.3175 | Accuracy: 0.9189\n","Epoch [2/2] | Step [18822/22538] | Loss: 0.2192 | Accuracy: 0.9227\n","Epoch [2/2] | Step [18823/22538] | Loss: 0.2776 | Accuracy: 0.9125\n","Epoch [2/2] | Step [18824/22538] | Loss: 0.3994 | Accuracy: 0.9034\n","Epoch [2/2] | Step [18825/22538] | Loss: 0.2393 | Accuracy: 0.9313\n","Epoch [2/2] | Step [18826/22538] | Loss: 0.2684 | Accuracy: 0.9159\n","Epoch [2/2] | Step [18827/22538] | Loss: 0.2704 | Accuracy: 0.9292\n","Epoch [2/2] | Step [18828/22538] | Loss: 0.2754 | Accuracy: 0.9190\n","Epoch [2/2] | Step [18829/22538] | Loss: 0.5598 | Accuracy: 0.8777\n","Epoch [2/2] | Step [18830/22538] | Loss: 0.2751 | Accuracy: 0.9235\n","Epoch [2/2] | Step [18831/22538] | Loss: 0.2904 | Accuracy: 0.9155\n","Epoch [2/2] | Step [18832/22538] | Loss: 0.2513 | Accuracy: 0.9387\n","Epoch [2/2] | Step [18833/22538] | Loss: 0.4185 | Accuracy: 0.8933\n","Epoch [2/2] | Step [18834/22538] | Loss: 0.3839 | Accuracy: 0.8808\n","Epoch [2/2] | Step [18835/22538] | Loss: 0.2824 | Accuracy: 0.9210\n","Epoch [2/2] | Step [18836/22538] | Loss: 0.3657 | Accuracy: 0.9104\n","Epoch [2/2] | Step [18837/22538] | Loss: 0.3661 | Accuracy: 0.8864\n","Epoch [2/2] | Step [18838/22538] | Loss: 0.4371 | Accuracy: 0.8723\n","Epoch [2/2] | Step [18839/22538] | Loss: 0.3032 | Accuracy: 0.9193\n","Epoch [2/2] | Step [18840/22538] | Loss: 0.2139 | Accuracy: 0.9321\n","Epoch [2/2] | Step [18841/22538] | Loss: 0.3057 | Accuracy: 0.9259\n","Epoch [2/2] | Step [18842/22538] | Loss: 0.2888 | Accuracy: 0.9115\n","Epoch [2/2] | Step [18843/22538] | Loss: 0.2507 | Accuracy: 0.9203\n","Epoch [2/2] | Step [18844/22538] | Loss: 0.2324 | Accuracy: 0.9355\n","Epoch [2/2] | Step [18845/22538] | Loss: 0.3917 | Accuracy: 0.9062\n","Epoch [2/2] | Step [18846/22538] | Loss: 0.4258 | Accuracy: 0.8839\n","Epoch [2/2] | Step [18847/22538] | Loss: 0.3817 | Accuracy: 0.8979\n","Epoch [2/2] | Step [18848/22538] | Loss: 0.3758 | Accuracy: 0.8987\n","Epoch [2/2] | Step [18849/22538] | Loss: 0.2321 | Accuracy: 0.9343\n","Epoch [2/2] | Step [18850/22538] | Loss: 0.2952 | Accuracy: 0.9122\n","Epoch [2/2] | Step [18851/22538] | Loss: 0.4347 | Accuracy: 0.8775\n","Epoch [2/2] | Step [18852/22538] | Loss: 0.1555 | Accuracy: 0.9538\n","Epoch [2/2] | Step [18853/22538] | Loss: 0.3748 | Accuracy: 0.8975\n","Epoch [2/2] | Step [18854/22538] | Loss: 0.3435 | Accuracy: 0.9130\n","Epoch [2/2] | Step [18855/22538] | Loss: 0.2709 | Accuracy: 0.9335\n","Epoch [2/2] | Step [18856/22538] | Loss: 0.4108 | Accuracy: 0.8929\n","Epoch [2/2] | Step [18857/22538] | Loss: 0.3351 | Accuracy: 0.9087\n","Epoch [2/2] | Step [18858/22538] | Loss: 0.4386 | Accuracy: 0.8772\n","Epoch [2/2] | Step [18859/22538] | Loss: 0.2941 | Accuracy: 0.9203\n","Epoch [2/2] | Step [18860/22538] | Loss: 0.3100 | Accuracy: 0.9044\n","Epoch [2/2] | Step [18861/22538] | Loss: 0.2928 | Accuracy: 0.9211\n","Epoch [2/2] | Step [18862/22538] | Loss: 0.3191 | Accuracy: 0.9110\n","Epoch [2/2] | Step [18863/22538] | Loss: 0.3909 | Accuracy: 0.8995\n","Epoch [2/2] | Step [18864/22538] | Loss: 0.2489 | Accuracy: 0.9136\n","Epoch [2/2] | Step [18865/22538] | Loss: 0.4017 | Accuracy: 0.8866\n","Epoch [2/2] | Step [18866/22538] | Loss: 0.2320 | Accuracy: 0.9444\n","Epoch [2/2] | Step [18867/22538] | Loss: 0.3337 | Accuracy: 0.9051\n","Epoch [2/2] | Step [18868/22538] | Loss: 0.3827 | Accuracy: 0.8850\n","Epoch [2/2] | Step [18869/22538] | Loss: 0.2344 | Accuracy: 0.9311\n","Epoch [2/2] | Step [18870/22538] | Loss: 0.3387 | Accuracy: 0.9033\n","Epoch [2/2] | Step [18871/22538] | Loss: 0.2780 | Accuracy: 0.9120\n","Epoch [2/2] | Step [18872/22538] | Loss: 0.4378 | Accuracy: 0.8726\n","Epoch [2/2] | Step [18873/22538] | Loss: 0.2479 | Accuracy: 0.9224\n","Epoch [2/2] | Step [18874/22538] | Loss: 0.6072 | Accuracy: 0.8293\n","Epoch [2/2] | Step [18875/22538] | Loss: 0.2443 | Accuracy: 0.9310\n","Epoch [2/2] | Step [18876/22538] | Loss: 0.3357 | Accuracy: 0.9184\n","Epoch [2/2] | Step [18877/22538] | Loss: 0.2642 | Accuracy: 0.9266\n","Epoch [2/2] | Step [18878/22538] | Loss: 0.3283 | Accuracy: 0.9030\n","Epoch [2/2] | Step [18879/22538] | Loss: 0.5365 | Accuracy: 0.8900\n","Epoch [2/2] | Step [18880/22538] | Loss: 0.2598 | Accuracy: 0.9308\n","Epoch [2/2] | Step [18881/22538] | Loss: 0.3533 | Accuracy: 0.8838\n","Epoch [2/2] | Step [18882/22538] | Loss: 0.3556 | Accuracy: 0.9076\n","Epoch [2/2] | Step [18883/22538] | Loss: 0.3548 | Accuracy: 0.9110\n","Epoch [2/2] | Step [18884/22538] | Loss: 0.3079 | Accuracy: 0.9104\n","Epoch [2/2] | Step [18885/22538] | Loss: 0.4224 | Accuracy: 0.8937\n","Epoch [2/2] | Step [18886/22538] | Loss: 0.2921 | Accuracy: 0.9221\n","Epoch [2/2] | Step [18887/22538] | Loss: 0.3864 | Accuracy: 0.8848\n","Epoch [2/2] | Step [18888/22538] | Loss: 0.2734 | Accuracy: 0.9073\n","Epoch [2/2] | Step [18889/22538] | Loss: 0.3289 | Accuracy: 0.8991\n","Epoch [2/2] | Step [18890/22538] | Loss: 0.3182 | Accuracy: 0.9023\n","Epoch [2/2] | Step [18891/22538] | Loss: 0.4348 | Accuracy: 0.8822\n","Epoch [2/2] | Step [18892/22538] | Loss: 0.3106 | Accuracy: 0.9205\n","Epoch [2/2] | Step [18893/22538] | Loss: 0.3605 | Accuracy: 0.8975\n","Epoch [2/2] | Step [18894/22538] | Loss: 0.4031 | Accuracy: 0.8995\n","Epoch [2/2] | Step [18895/22538] | Loss: 0.3276 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18896/22538] | Loss: 0.3696 | Accuracy: 0.8914\n","Epoch [2/2] | Step [18897/22538] | Loss: 0.3387 | Accuracy: 0.9153\n","Epoch [2/2] | Step [18898/22538] | Loss: 0.2689 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18899/22538] | Loss: 0.3103 | Accuracy: 0.9089\n","Epoch [2/2] | Step [18900/22538] | Loss: 0.2868 | Accuracy: 0.8953\n","Epoch [2/2] | Step [18901/22538] | Loss: 0.2432 | Accuracy: 0.9346\n","Epoch [2/2] | Step [18902/22538] | Loss: 0.4522 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18903/22538] | Loss: 0.2872 | Accuracy: 0.9269\n","Epoch [2/2] | Step [18904/22538] | Loss: 0.3811 | Accuracy: 0.9036\n","Epoch [2/2] | Step [18905/22538] | Loss: 0.3738 | Accuracy: 0.8718\n","Epoch [2/2] | Step [18906/22538] | Loss: 0.4021 | Accuracy: 0.9129\n","Epoch [2/2] | Step [18907/22538] | Loss: 0.3498 | Accuracy: 0.9136\n","Epoch [2/2] | Step [18908/22538] | Loss: 0.3967 | Accuracy: 0.9000\n","Epoch [2/2] | Step [18909/22538] | Loss: 0.2080 | Accuracy: 0.9336\n","Epoch [2/2] | Step [18910/22538] | Loss: 0.4463 | Accuracy: 0.8505\n","Epoch [2/2] | Step [18911/22538] | Loss: 0.3125 | Accuracy: 0.9201\n","Epoch [2/2] | Step [18912/22538] | Loss: 0.3686 | Accuracy: 0.8922\n","Epoch [2/2] | Step [18913/22538] | Loss: 0.3160 | Accuracy: 0.9104\n","Epoch [2/2] | Step [18914/22538] | Loss: 0.3897 | Accuracy: 0.9076\n","Epoch [2/2] | Step [18915/22538] | Loss: 0.2566 | Accuracy: 0.9247\n","Epoch [2/2] | Step [18916/22538] | Loss: 0.2792 | Accuracy: 0.9177\n","Epoch [2/2] | Step [18917/22538] | Loss: 0.3201 | Accuracy: 0.9141\n","Epoch [2/2] | Step [18918/22538] | Loss: 0.3064 | Accuracy: 0.9042\n","Epoch [2/2] | Step [18919/22538] | Loss: 0.3025 | Accuracy: 0.9375\n","Epoch [2/2] | Step [18920/22538] | Loss: 0.3741 | Accuracy: 0.8987\n","Epoch [2/2] | Step [18921/22538] | Loss: 0.5115 | Accuracy: 0.8688\n","Epoch [2/2] | Step [18922/22538] | Loss: 0.3154 | Accuracy: 0.9150\n","Epoch [2/2] | Step [18923/22538] | Loss: 0.3756 | Accuracy: 0.8969\n","Epoch [2/2] | Step [18924/22538] | Loss: 0.4726 | Accuracy: 0.8750\n","Epoch [2/2] | Step [18925/22538] | Loss: 0.2689 | Accuracy: 0.9191\n","Epoch [2/2] | Step [18926/22538] | Loss: 0.2718 | Accuracy: 0.9242\n","Epoch [2/2] | Step [18927/22538] | Loss: 0.4252 | Accuracy: 0.8917\n","Epoch [2/2] | Step [18928/22538] | Loss: 0.3473 | Accuracy: 0.9184\n","Epoch [2/2] | Step [18929/22538] | Loss: 0.3233 | Accuracy: 0.8883\n","Epoch [2/2] | Step [18930/22538] | Loss: 0.2819 | Accuracy: 0.9257\n","Epoch [2/2] | Step [18931/22538] | Loss: 0.3274 | Accuracy: 0.9098\n","Epoch [2/2] | Step [18932/22538] | Loss: 0.4010 | Accuracy: 0.8932\n","Epoch [2/2] | Step [18933/22538] | Loss: 0.2153 | Accuracy: 0.9269\n","Epoch [2/2] | Step [18934/22538] | Loss: 0.3420 | Accuracy: 0.9057\n","Epoch [2/2] | Step [18935/22538] | Loss: 0.2784 | Accuracy: 0.9293\n","Epoch [2/2] | Step [18936/22538] | Loss: 0.3807 | Accuracy: 0.8932\n","Epoch [2/2] | Step [18937/22538] | Loss: 0.3216 | Accuracy: 0.9143\n","Epoch [2/2] | Step [18938/22538] | Loss: 0.3042 | Accuracy: 0.9173\n","Epoch [2/2] | Step [18939/22538] | Loss: 0.3204 | Accuracy: 0.9258\n","Epoch [2/2] | Step [18940/22538] | Loss: 0.4197 | Accuracy: 0.8724\n","Epoch [2/2] | Step [18941/22538] | Loss: 0.2689 | Accuracy: 0.9442\n","Epoch [2/2] | Step [18942/22538] | Loss: 0.2924 | Accuracy: 0.9119\n","Epoch [2/2] | Step [18943/22538] | Loss: 0.3176 | Accuracy: 0.9068\n","Epoch [2/2] | Step [18944/22538] | Loss: 0.4249 | Accuracy: 0.8806\n","Epoch [2/2] | Step [18945/22538] | Loss: 0.2396 | Accuracy: 0.9254\n","Epoch [2/2] | Step [18946/22538] | Loss: 0.3820 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18947/22538] | Loss: 0.3358 | Accuracy: 0.9131\n","Epoch [2/2] | Step [18948/22538] | Loss: 0.4338 | Accuracy: 0.8622\n","Epoch [2/2] | Step [18949/22538] | Loss: 0.3679 | Accuracy: 0.9116\n","Epoch [2/2] | Step [18950/22538] | Loss: 0.4540 | Accuracy: 0.8768\n","Epoch [2/2] | Step [18951/22538] | Loss: 0.2185 | Accuracy: 0.9366\n","Epoch [2/2] | Step [18952/22538] | Loss: 0.2619 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18953/22538] | Loss: 0.2512 | Accuracy: 0.9262\n","Epoch [2/2] | Step [18954/22538] | Loss: 0.3523 | Accuracy: 0.8807\n","Epoch [2/2] | Step [18955/22538] | Loss: 0.3881 | Accuracy: 0.8862\n","Epoch [2/2] | Step [18956/22538] | Loss: 0.3652 | Accuracy: 0.9028\n","Epoch [2/2] | Step [18957/22538] | Loss: 0.3476 | Accuracy: 0.9021\n","Epoch [2/2] | Step [18958/22538] | Loss: 0.3385 | Accuracy: 0.9035\n","Epoch [2/2] | Step [18959/22538] | Loss: 0.2355 | Accuracy: 0.9330\n","Epoch [2/2] | Step [18960/22538] | Loss: 0.3828 | Accuracy: 0.8935\n","Epoch [2/2] | Step [18961/22538] | Loss: 0.3106 | Accuracy: 0.9010\n","Epoch [2/2] | Step [18962/22538] | Loss: 0.2259 | Accuracy: 0.9298\n","Epoch [2/2] | Step [18963/22538] | Loss: 0.3380 | Accuracy: 0.8966\n","Epoch [2/2] | Step [18964/22538] | Loss: 0.4105 | Accuracy: 0.8860\n","Epoch [2/2] | Step [18965/22538] | Loss: 0.1721 | Accuracy: 0.9433\n","Epoch [2/2] | Step [18966/22538] | Loss: 0.2919 | Accuracy: 0.9147\n","Epoch [2/2] | Step [18967/22538] | Loss: 0.2589 | Accuracy: 0.9167\n","Epoch [2/2] | Step [18968/22538] | Loss: 0.2519 | Accuracy: 0.9246\n","Epoch [2/2] | Step [18969/22538] | Loss: 0.3066 | Accuracy: 0.9243\n","Epoch [2/2] | Step [18970/22538] | Loss: 0.3051 | Accuracy: 0.9013\n","Epoch [2/2] | Step [18971/22538] | Loss: 0.4353 | Accuracy: 0.8790\n","Epoch [2/2] | Step [18972/22538] | Loss: 0.2208 | Accuracy: 0.9466\n","Epoch [2/2] | Step [18973/22538] | Loss: 0.4236 | Accuracy: 0.8815\n","Epoch [2/2] | Step [18974/22538] | Loss: 0.2268 | Accuracy: 0.9286\n","Epoch [2/2] | Step [18975/22538] | Loss: 0.4574 | Accuracy: 0.9006\n","Epoch [2/2] | Step [18976/22538] | Loss: 0.4404 | Accuracy: 0.8650\n","Epoch [2/2] | Step [18977/22538] | Loss: 0.5768 | Accuracy: 0.8571\n","Epoch [2/2] | Step [18978/22538] | Loss: 0.4127 | Accuracy: 0.8988\n","Epoch [2/2] | Step [18979/22538] | Loss: 0.4498 | Accuracy: 0.8714\n","Epoch [2/2] | Step [18980/22538] | Loss: 0.3728 | Accuracy: 0.9089\n","Epoch [2/2] | Step [18981/22538] | Loss: 0.2032 | Accuracy: 0.9434\n","Epoch [2/2] | Step [18982/22538] | Loss: 0.3230 | Accuracy: 0.9023\n","Epoch [2/2] | Step [18983/22538] | Loss: 0.3707 | Accuracy: 0.8878\n","Epoch [2/2] | Step [18984/22538] | Loss: 0.3422 | Accuracy: 0.9050\n","Epoch [2/2] | Step [18985/22538] | Loss: 0.2100 | Accuracy: 0.9420\n","Epoch [2/2] | Step [18986/22538] | Loss: 0.2783 | Accuracy: 0.9401\n","Epoch [2/2] | Step [18987/22538] | Loss: 0.3821 | Accuracy: 0.9152\n","Epoch [2/2] | Step [18988/22538] | Loss: 0.3393 | Accuracy: 0.9122\n","Epoch [2/2] | Step [18989/22538] | Loss: 0.3659 | Accuracy: 0.8947\n","Epoch [2/2] | Step [18990/22538] | Loss: 0.2101 | Accuracy: 0.9462\n","Epoch [2/2] | Step [18991/22538] | Loss: 0.3754 | Accuracy: 0.9030\n","Epoch [2/2] | Step [18992/22538] | Loss: 0.3997 | Accuracy: 0.8801\n","Epoch [2/2] | Step [18993/22538] | Loss: 0.4468 | Accuracy: 0.9005\n","Epoch [2/2] | Step [18994/22538] | Loss: 0.3271 | Accuracy: 0.9057\n","Epoch [2/2] | Step [18995/22538] | Loss: 0.2498 | Accuracy: 0.9254\n","Epoch [2/2] | Step [18996/22538] | Loss: 0.3279 | Accuracy: 0.9038\n","Epoch [2/2] | Step [18997/22538] | Loss: 0.2156 | Accuracy: 0.9366\n","Epoch [2/2] | Step [18998/22538] | Loss: 0.4401 | Accuracy: 0.8810\n","Epoch [2/2] | Step [18999/22538] | Loss: 0.1718 | Accuracy: 0.9508\n","Epoch [2/2] | Step [19000/22538] | Loss: 0.3023 | Accuracy: 0.9062\n","Epoch [2/2] | Step [19001/22538] | Loss: 0.2142 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19002/22538] | Loss: 0.2024 | Accuracy: 0.9503\n","Epoch [2/2] | Step [19003/22538] | Loss: 0.1768 | Accuracy: 0.9538\n","Epoch [2/2] | Step [19004/22538] | Loss: 0.4514 | Accuracy: 0.8835\n","Epoch [2/2] | Step [19005/22538] | Loss: 0.2554 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19006/22538] | Loss: 0.4898 | Accuracy: 0.8808\n","Epoch [2/2] | Step [19007/22538] | Loss: 0.3922 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19008/22538] | Loss: 0.4110 | Accuracy: 0.8831\n","Epoch [2/2] | Step [19009/22538] | Loss: 0.3550 | Accuracy: 0.9035\n","Epoch [2/2] | Step [19010/22538] | Loss: 0.2667 | Accuracy: 0.9259\n","Epoch [2/2] | Step [19011/22538] | Loss: 0.2767 | Accuracy: 0.9191\n","Epoch [2/2] | Step [19012/22538] | Loss: 0.2349 | Accuracy: 0.9336\n","Epoch [2/2] | Step [19013/22538] | Loss: 0.2050 | Accuracy: 0.9408\n","Epoch [2/2] | Step [19014/22538] | Loss: 0.3966 | Accuracy: 0.8991\n","Epoch [2/2] | Step [19015/22538] | Loss: 0.3596 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19016/22538] | Loss: 0.3510 | Accuracy: 0.9099\n","Epoch [2/2] | Step [19017/22538] | Loss: 0.2525 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19018/22538] | Loss: 0.2257 | Accuracy: 0.9340\n","Epoch [2/2] | Step [19019/22538] | Loss: 0.3504 | Accuracy: 0.9142\n","Epoch [2/2] | Step [19020/22538] | Loss: 0.2263 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19021/22538] | Loss: 0.4546 | Accuracy: 0.8918\n","Epoch [2/2] | Step [19022/22538] | Loss: 0.4211 | Accuracy: 0.8915\n","Epoch [2/2] | Step [19023/22538] | Loss: 0.3612 | Accuracy: 0.8936\n","Epoch [2/2] | Step [19024/22538] | Loss: 0.2738 | Accuracy: 0.9149\n","Epoch [2/2] | Step [19025/22538] | Loss: 0.2551 | Accuracy: 0.9281\n","Epoch [2/2] | Step [19026/22538] | Loss: 0.4032 | Accuracy: 0.8825\n","Epoch [2/2] | Step [19027/22538] | Loss: 0.2150 | Accuracy: 0.9299\n","Epoch [2/2] | Step [19028/22538] | Loss: 0.3636 | Accuracy: 0.8967\n","Epoch [2/2] | Step [19029/22538] | Loss: 0.4295 | Accuracy: 0.8925\n","Epoch [2/2] | Step [19030/22538] | Loss: 0.3130 | Accuracy: 0.9079\n","Epoch [2/2] | Step [19031/22538] | Loss: 0.2165 | Accuracy: 0.9276\n","Epoch [2/2] | Step [19032/22538] | Loss: 0.3029 | Accuracy: 0.9154\n","Epoch [2/2] | Step [19033/22538] | Loss: 0.3932 | Accuracy: 0.8846\n","Epoch [2/2] | Step [19034/22538] | Loss: 0.3547 | Accuracy: 0.8989\n","Epoch [2/2] | Step [19035/22538] | Loss: 0.3367 | Accuracy: 0.9203\n","Epoch [2/2] | Step [19036/22538] | Loss: 0.2834 | Accuracy: 0.9155\n","Epoch [2/2] | Step [19037/22538] | Loss: 0.3084 | Accuracy: 0.9207\n","Epoch [2/2] | Step [19038/22538] | Loss: 0.4554 | Accuracy: 0.8818\n","Epoch [2/2] | Step [19039/22538] | Loss: 0.5259 | Accuracy: 0.8684\n","Epoch [2/2] | Step [19040/22538] | Loss: 0.4294 | Accuracy: 0.8971\n","Epoch [2/2] | Step [19041/22538] | Loss: 0.3390 | Accuracy: 0.9174\n","Epoch [2/2] | Step [19042/22538] | Loss: 0.2111 | Accuracy: 0.9327\n","Epoch [2/2] | Step [19043/22538] | Loss: 0.3931 | Accuracy: 0.8966\n","Epoch [2/2] | Step [19044/22538] | Loss: 0.4307 | Accuracy: 0.8564\n","Epoch [2/2] | Step [19045/22538] | Loss: 0.2745 | Accuracy: 0.9181\n","Epoch [2/2] | Step [19046/22538] | Loss: 0.3319 | Accuracy: 0.9111\n","Epoch [2/2] | Step [19047/22538] | Loss: 0.4089 | Accuracy: 0.8859\n","Epoch [2/2] | Step [19048/22538] | Loss: 0.1882 | Accuracy: 0.9453\n","Epoch [2/2] | Step [19049/22538] | Loss: 0.4233 | Accuracy: 0.8799\n","Epoch [2/2] | Step [19050/22538] | Loss: 0.2103 | Accuracy: 0.9462\n","Epoch [2/2] | Step [19051/22538] | Loss: 0.3073 | Accuracy: 0.9127\n","Epoch [2/2] | Step [19052/22538] | Loss: 0.3023 | Accuracy: 0.9178\n","Epoch [2/2] | Step [19053/22538] | Loss: 0.2644 | Accuracy: 0.9130\n","Epoch [2/2] | Step [19054/22538] | Loss: 0.4579 | Accuracy: 0.8802\n","Epoch [2/2] | Step [19055/22538] | Loss: 0.2886 | Accuracy: 0.9179\n","Epoch [2/2] | Step [19056/22538] | Loss: 0.2897 | Accuracy: 0.9016\n","Epoch [2/2] | Step [19057/22538] | Loss: 0.2568 | Accuracy: 0.9212\n","Epoch [2/2] | Step [19058/22538] | Loss: 0.3180 | Accuracy: 0.9150\n","Epoch [2/2] | Step [19059/22538] | Loss: 0.2844 | Accuracy: 0.9298\n","Epoch [2/2] | Step [19060/22538] | Loss: 0.4086 | Accuracy: 0.8781\n","Epoch [2/2] | Step [19061/22538] | Loss: 0.3099 | Accuracy: 0.8981\n","Epoch [2/2] | Step [19062/22538] | Loss: 0.3944 | Accuracy: 0.8986\n","Epoch [2/2] | Step [19063/22538] | Loss: 0.3199 | Accuracy: 0.9038\n","Epoch [2/2] | Step [19064/22538] | Loss: 0.1786 | Accuracy: 0.9467\n","Epoch [2/2] | Step [19065/22538] | Loss: 0.3310 | Accuracy: 0.9045\n","Epoch [2/2] | Step [19066/22538] | Loss: 0.3257 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19067/22538] | Loss: 0.3845 | Accuracy: 0.8915\n","Epoch [2/2] | Step [19068/22538] | Loss: 0.2722 | Accuracy: 0.9112\n","Epoch [2/2] | Step [19069/22538] | Loss: 0.3820 | Accuracy: 0.9030\n","Epoch [2/2] | Step [19070/22538] | Loss: 0.3740 | Accuracy: 0.8946\n","Epoch [2/2] | Step [19071/22538] | Loss: 0.3817 | Accuracy: 0.8986\n","Epoch [2/2] | Step [19072/22538] | Loss: 0.2593 | Accuracy: 0.9337\n","Epoch [2/2] | Step [19073/22538] | Loss: 0.3383 | Accuracy: 0.9177\n","Epoch [2/2] | Step [19074/22538] | Loss: 0.2852 | Accuracy: 0.9193\n","Epoch [2/2] | Step [19075/22538] | Loss: 0.3780 | Accuracy: 0.8932\n","Epoch [2/2] | Step [19076/22538] | Loss: 0.3997 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19077/22538] | Loss: 0.3748 | Accuracy: 0.8918\n","Epoch [2/2] | Step [19078/22538] | Loss: 0.3138 | Accuracy: 0.9000\n","Epoch [2/2] | Step [19079/22538] | Loss: 0.3623 | Accuracy: 0.9044\n","Epoch [2/2] | Step [19080/22538] | Loss: 0.3180 | Accuracy: 0.9195\n","Epoch [2/2] | Step [19081/22538] | Loss: 0.3250 | Accuracy: 0.9148\n","Epoch [2/2] | Step [19082/22538] | Loss: 0.2012 | Accuracy: 0.9325\n","Epoch [2/2] | Step [19083/22538] | Loss: 0.2985 | Accuracy: 0.9158\n","Epoch [2/2] | Step [19084/22538] | Loss: 0.1955 | Accuracy: 0.9493\n","Epoch [2/2] | Step [19085/22538] | Loss: 0.3046 | Accuracy: 0.9242\n","Epoch [2/2] | Step [19086/22538] | Loss: 0.1643 | Accuracy: 0.9441\n","Epoch [2/2] | Step [19087/22538] | Loss: 0.1802 | Accuracy: 0.9449\n","Epoch [2/2] | Step [19088/22538] | Loss: 0.3520 | Accuracy: 0.9063\n","Epoch [2/2] | Step [19089/22538] | Loss: 0.2534 | Accuracy: 0.9245\n","Epoch [2/2] | Step [19090/22538] | Loss: 0.4823 | Accuracy: 0.8654\n","Epoch [2/2] | Step [19091/22538] | Loss: 0.2388 | Accuracy: 0.9265\n","Epoch [2/2] | Step [19092/22538] | Loss: 0.3116 | Accuracy: 0.9057\n","Epoch [2/2] | Step [19093/22538] | Loss: 0.2988 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19094/22538] | Loss: 0.2944 | Accuracy: 0.9158\n","Epoch [2/2] | Step [19095/22538] | Loss: 0.2176 | Accuracy: 0.9299\n","Epoch [2/2] | Step [19096/22538] | Loss: 0.3536 | Accuracy: 0.9128\n","Epoch [2/2] | Step [19097/22538] | Loss: 0.2892 | Accuracy: 0.9194\n","Epoch [2/2] | Step [19098/22538] | Loss: 0.3932 | Accuracy: 0.8798\n","Epoch [2/2] | Step [19099/22538] | Loss: 0.3262 | Accuracy: 0.8947\n","Epoch [2/2] | Step [19100/22538] | Loss: 0.1845 | Accuracy: 0.9449\n","Epoch [2/2] | Step [19101/22538] | Loss: 0.2580 | Accuracy: 0.9129\n","Epoch [2/2] | Step [19102/22538] | Loss: 0.2821 | Accuracy: 0.9194\n","Epoch [2/2] | Step [19103/22538] | Loss: 0.2791 | Accuracy: 0.9159\n","Epoch [2/2] | Step [19104/22538] | Loss: 0.3455 | Accuracy: 0.9009\n","Epoch [2/2] | Step [19105/22538] | Loss: 0.3818 | Accuracy: 0.8837\n","Epoch [2/2] | Step [19106/22538] | Loss: 0.4241 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19107/22538] | Loss: 0.3570 | Accuracy: 0.8816\n","Epoch [2/2] | Step [19108/22538] | Loss: 0.3928 | Accuracy: 0.8931\n","Epoch [2/2] | Step [19109/22538] | Loss: 0.2902 | Accuracy: 0.9082\n","Epoch [2/2] | Step [19110/22538] | Loss: 0.2757 | Accuracy: 0.9247\n","Epoch [2/2] | Step [19111/22538] | Loss: 0.3449 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19112/22538] | Loss: 0.3421 | Accuracy: 0.9113\n","Epoch [2/2] | Step [19113/22538] | Loss: 0.1935 | Accuracy: 0.9395\n","Epoch [2/2] | Step [19114/22538] | Loss: 0.2513 | Accuracy: 0.9286\n","Epoch [2/2] | Step [19115/22538] | Loss: 0.2838 | Accuracy: 0.9225\n","Epoch [2/2] | Step [19116/22538] | Loss: 0.3335 | Accuracy: 0.9079\n","Epoch [2/2] | Step [19117/22538] | Loss: 0.5449 | Accuracy: 0.8558\n","Epoch [2/2] | Step [19118/22538] | Loss: 0.4096 | Accuracy: 0.8881\n","Epoch [2/2] | Step [19119/22538] | Loss: 0.3150 | Accuracy: 0.9149\n","Epoch [2/2] | Step [19120/22538] | Loss: 0.3152 | Accuracy: 0.9174\n","Epoch [2/2] | Step [19121/22538] | Loss: 0.3124 | Accuracy: 0.9279\n","Epoch [2/2] | Step [19122/22538] | Loss: 0.2929 | Accuracy: 0.9095\n","Epoch [2/2] | Step [19123/22538] | Loss: 0.3588 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19124/22538] | Loss: 0.2899 | Accuracy: 0.9142\n","Epoch [2/2] | Step [19125/22538] | Loss: 0.3474 | Accuracy: 0.9033\n","Epoch [2/2] | Step [19126/22538] | Loss: 0.2982 | Accuracy: 0.9235\n","Epoch [2/2] | Step [19127/22538] | Loss: 0.3190 | Accuracy: 0.8966\n","Epoch [2/2] | Step [19128/22538] | Loss: 0.4242 | Accuracy: 0.8962\n","Epoch [2/2] | Step [19129/22538] | Loss: 0.2312 | Accuracy: 0.9283\n","Epoch [2/2] | Step [19130/22538] | Loss: 0.3715 | Accuracy: 0.9156\n","Epoch [2/2] | Step [19131/22538] | Loss: 0.1640 | Accuracy: 0.9448\n","Epoch [2/2] | Step [19132/22538] | Loss: 0.2271 | Accuracy: 0.9318\n","Epoch [2/2] | Step [19133/22538] | Loss: 0.2233 | Accuracy: 0.9393\n","Epoch [2/2] | Step [19134/22538] | Loss: 0.3316 | Accuracy: 0.9105\n","Epoch [2/2] | Step [19135/22538] | Loss: 0.3468 | Accuracy: 0.9225\n","Epoch [2/2] | Step [19136/22538] | Loss: 0.3367 | Accuracy: 0.9097\n","Epoch [2/2] | Step [19137/22538] | Loss: 0.2970 | Accuracy: 0.9257\n","Epoch [2/2] | Step [19138/22538] | Loss: 0.2904 | Accuracy: 0.9191\n","Epoch [2/2] | Step [19139/22538] | Loss: 0.3526 | Accuracy: 0.8843\n","Epoch [2/2] | Step [19140/22538] | Loss: 0.3104 | Accuracy: 0.8980\n","Epoch [2/2] | Step [19141/22538] | Loss: 0.3949 | Accuracy: 0.9050\n","Epoch [2/2] | Step [19142/22538] | Loss: 0.2878 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19143/22538] | Loss: 0.4485 | Accuracy: 0.8844\n","Epoch [2/2] | Step [19144/22538] | Loss: 0.2737 | Accuracy: 0.9254\n","Epoch [2/2] | Step [19145/22538] | Loss: 0.3381 | Accuracy: 0.9159\n","Epoch [2/2] | Step [19146/22538] | Loss: 0.2909 | Accuracy: 0.9091\n","Epoch [2/2] | Step [19147/22538] | Loss: 0.3408 | Accuracy: 0.9035\n","Epoch [2/2] | Step [19148/22538] | Loss: 0.3052 | Accuracy: 0.9189\n","Epoch [2/2] | Step [19149/22538] | Loss: 0.2837 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19150/22538] | Loss: 0.4816 | Accuracy: 0.8721\n","Epoch [2/2] | Step [19151/22538] | Loss: 0.2927 | Accuracy: 0.9085\n","Epoch [2/2] | Step [19152/22538] | Loss: 0.2035 | Accuracy: 0.9352\n","Epoch [2/2] | Step [19153/22538] | Loss: 0.3641 | Accuracy: 0.9038\n","Epoch [2/2] | Step [19154/22538] | Loss: 0.3660 | Accuracy: 0.8936\n","Epoch [2/2] | Step [19155/22538] | Loss: 0.2342 | Accuracy: 0.9435\n","Epoch [2/2] | Step [19156/22538] | Loss: 0.4296 | Accuracy: 0.9104\n","Epoch [2/2] | Step [19157/22538] | Loss: 0.3267 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19158/22538] | Loss: 0.2123 | Accuracy: 0.9269\n","Epoch [2/2] | Step [19159/22538] | Loss: 0.3884 | Accuracy: 0.8988\n","Epoch [2/2] | Step [19160/22538] | Loss: 0.3638 | Accuracy: 0.9077\n","Epoch [2/2] | Step [19161/22538] | Loss: 0.3580 | Accuracy: 0.9096\n","Epoch [2/2] | Step [19162/22538] | Loss: 0.3657 | Accuracy: 0.8929\n","Epoch [2/2] | Step [19163/22538] | Loss: 0.4816 | Accuracy: 0.8781\n","Epoch [2/2] | Step [19164/22538] | Loss: 0.2226 | Accuracy: 0.9453\n","Epoch [2/2] | Step [19165/22538] | Loss: 0.4411 | Accuracy: 0.8817\n","Epoch [2/2] | Step [19166/22538] | Loss: 0.2793 | Accuracy: 0.9199\n","Epoch [2/2] | Step [19167/22538] | Loss: 0.2439 | Accuracy: 0.9393\n","Epoch [2/2] | Step [19168/22538] | Loss: 0.3154 | Accuracy: 0.9133\n","Epoch [2/2] | Step [19169/22538] | Loss: 0.2852 | Accuracy: 0.9138\n","Epoch [2/2] | Step [19170/22538] | Loss: 0.2350 | Accuracy: 0.9232\n","Epoch [2/2] | Step [19171/22538] | Loss: 0.3866 | Accuracy: 0.8962\n","Epoch [2/2] | Step [19172/22538] | Loss: 0.3646 | Accuracy: 0.9007\n","Epoch [2/2] | Step [19173/22538] | Loss: 0.2353 | Accuracy: 0.9231\n","Epoch [2/2] | Step [19174/22538] | Loss: 0.3406 | Accuracy: 0.9076\n","Epoch [2/2] | Step [19175/22538] | Loss: 0.2487 | Accuracy: 0.9316\n","Epoch [2/2] | Step [19176/22538] | Loss: 0.2191 | Accuracy: 0.9333\n","Epoch [2/2] | Step [19177/22538] | Loss: 0.4395 | Accuracy: 0.8899\n","Epoch [2/2] | Step [19178/22538] | Loss: 0.4824 | Accuracy: 0.8724\n","Epoch [2/2] | Step [19179/22538] | Loss: 0.3630 | Accuracy: 0.8951\n","Epoch [2/2] | Step [19180/22538] | Loss: 0.3970 | Accuracy: 0.9009\n","Epoch [2/2] | Step [19181/22538] | Loss: 0.2704 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19182/22538] | Loss: 0.2853 | Accuracy: 0.9174\n","Epoch [2/2] | Step [19183/22538] | Loss: 0.2791 | Accuracy: 0.9138\n","Epoch [2/2] | Step [19184/22538] | Loss: 0.3992 | Accuracy: 0.8700\n","Epoch [2/2] | Step [19185/22538] | Loss: 0.5483 | Accuracy: 0.8878\n","Epoch [2/2] | Step [19186/22538] | Loss: 0.3006 | Accuracy: 0.9154\n","Epoch [2/2] | Step [19187/22538] | Loss: 0.3215 | Accuracy: 0.8897\n","Epoch [2/2] | Step [19188/22538] | Loss: 0.3849 | Accuracy: 0.8917\n","Epoch [2/2] | Step [19189/22538] | Loss: 0.2255 | Accuracy: 0.9385\n","Epoch [2/2] | Step [19190/22538] | Loss: 0.3206 | Accuracy: 0.9119\n","Epoch [2/2] | Step [19191/22538] | Loss: 0.2855 | Accuracy: 0.9198\n","Epoch [2/2] | Step [19192/22538] | Loss: 0.2846 | Accuracy: 0.9222\n","Epoch [2/2] | Step [19193/22538] | Loss: 0.4196 | Accuracy: 0.8844\n","Epoch [2/2] | Step [19194/22538] | Loss: 0.3966 | Accuracy: 0.9000\n","Epoch [2/2] | Step [19195/22538] | Loss: 0.3832 | Accuracy: 0.8897\n","Epoch [2/2] | Step [19196/22538] | Loss: 0.2964 | Accuracy: 0.9173\n","Epoch [2/2] | Step [19197/22538] | Loss: 0.2268 | Accuracy: 0.9310\n","Epoch [2/2] | Step [19198/22538] | Loss: 0.3301 | Accuracy: 0.9153\n","Epoch [2/2] | Step [19199/22538] | Loss: 0.4420 | Accuracy: 0.8597\n","Epoch [2/2] | Step [19200/22538] | Loss: 0.2852 | Accuracy: 0.9150\n","Epoch [2/2] | Step [19201/22538] | Loss: 0.4543 | Accuracy: 0.8833\n","Epoch [2/2] | Step [19202/22538] | Loss: 0.2565 | Accuracy: 0.9280\n","Epoch [2/2] | Step [19203/22538] | Loss: 0.2230 | Accuracy: 0.9318\n","Epoch [2/2] | Step [19204/22538] | Loss: 0.3420 | Accuracy: 0.9006\n","Epoch [2/2] | Step [19205/22538] | Loss: 0.4105 | Accuracy: 0.8904\n","Epoch [2/2] | Step [19206/22538] | Loss: 0.2778 | Accuracy: 0.9223\n","Epoch [2/2] | Step [19207/22538] | Loss: 0.3641 | Accuracy: 0.8973\n","Epoch [2/2] | Step [19208/22538] | Loss: 0.3860 | Accuracy: 0.8868\n","Epoch [2/2] | Step [19209/22538] | Loss: 0.3601 | Accuracy: 0.8810\n","Epoch [2/2] | Step [19210/22538] | Loss: 0.3416 | Accuracy: 0.9021\n","Epoch [2/2] | Step [19211/22538] | Loss: 0.3293 | Accuracy: 0.9199\n","Epoch [2/2] | Step [19212/22538] | Loss: 0.2887 | Accuracy: 0.9289\n","Epoch [2/2] | Step [19213/22538] | Loss: 0.4022 | Accuracy: 0.8922\n","Epoch [2/2] | Step [19214/22538] | Loss: 0.3472 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19215/22538] | Loss: 0.3221 | Accuracy: 0.9083\n","Epoch [2/2] | Step [19216/22538] | Loss: 0.2561 | Accuracy: 0.9273\n","Epoch [2/2] | Step [19217/22538] | Loss: 0.3209 | Accuracy: 0.9093\n","Epoch [2/2] | Step [19218/22538] | Loss: 0.2529 | Accuracy: 0.9190\n","Epoch [2/2] | Step [19219/22538] | Loss: 0.3412 | Accuracy: 0.9193\n","Epoch [2/2] | Step [19220/22538] | Loss: 0.2443 | Accuracy: 0.9362\n","Epoch [2/2] | Step [19221/22538] | Loss: 0.4261 | Accuracy: 0.8885\n","Epoch [2/2] | Step [19222/22538] | Loss: 0.1593 | Accuracy: 0.9604\n","Epoch [2/2] | Step [19223/22538] | Loss: 0.3097 | Accuracy: 0.8955\n","Epoch [2/2] | Step [19224/22538] | Loss: 0.2294 | Accuracy: 0.9339\n","Epoch [2/2] | Step [19225/22538] | Loss: 0.2642 | Accuracy: 0.9276\n","Epoch [2/2] | Step [19226/22538] | Loss: 0.5264 | Accuracy: 0.8708\n","Epoch [2/2] | Step [19227/22538] | Loss: 0.4405 | Accuracy: 0.8723\n","Epoch [2/2] | Step [19228/22538] | Loss: 0.4120 | Accuracy: 0.8856\n","Epoch [2/2] | Step [19229/22538] | Loss: 0.3330 | Accuracy: 0.9097\n","Epoch [2/2] | Step [19230/22538] | Loss: 0.2847 | Accuracy: 0.9082\n","Epoch [2/2] | Step [19231/22538] | Loss: 0.3087 | Accuracy: 0.9192\n","Epoch [2/2] | Step [19232/22538] | Loss: 0.3266 | Accuracy: 0.9175\n","Epoch [2/2] | Step [19233/22538] | Loss: 0.3335 | Accuracy: 0.8912\n","Epoch [2/2] | Step [19234/22538] | Loss: 0.4719 | Accuracy: 0.8632\n","Epoch [2/2] | Step [19235/22538] | Loss: 0.2219 | Accuracy: 0.9375\n","Epoch [2/2] | Step [19236/22538] | Loss: 0.4718 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19237/22538] | Loss: 0.3485 | Accuracy: 0.9026\n","Epoch [2/2] | Step [19238/22538] | Loss: 0.1951 | Accuracy: 0.9439\n","Epoch [2/2] | Step [19239/22538] | Loss: 0.3058 | Accuracy: 0.9087\n","Epoch [2/2] | Step [19240/22538] | Loss: 0.6393 | Accuracy: 0.8412\n","Epoch [2/2] | Step [19241/22538] | Loss: 0.3313 | Accuracy: 0.9074\n","Epoch [2/2] | Step [19242/22538] | Loss: 0.2729 | Accuracy: 0.9265\n","Epoch [2/2] | Step [19243/22538] | Loss: 0.5178 | Accuracy: 0.8632\n","Epoch [2/2] | Step [19244/22538] | Loss: 0.4464 | Accuracy: 0.8954\n","Epoch [2/2] | Step [19245/22538] | Loss: 0.3066 | Accuracy: 0.9107\n","Epoch [2/2] | Step [19246/22538] | Loss: 0.4102 | Accuracy: 0.8901\n","Epoch [2/2] | Step [19247/22538] | Loss: 0.3161 | Accuracy: 0.9118\n","Epoch [2/2] | Step [19248/22538] | Loss: 0.3215 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19249/22538] | Loss: 0.2940 | Accuracy: 0.9152\n","Epoch [2/2] | Step [19250/22538] | Loss: 0.2942 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19251/22538] | Loss: 0.2192 | Accuracy: 0.9335\n","Epoch [2/2] | Step [19252/22538] | Loss: 0.3651 | Accuracy: 0.9000\n","Epoch [2/2] | Step [19253/22538] | Loss: 0.3148 | Accuracy: 0.9107\n","Epoch [2/2] | Step [19254/22538] | Loss: 0.2822 | Accuracy: 0.9183\n","Epoch [2/2] | Step [19255/22538] | Loss: 0.3762 | Accuracy: 0.9137\n","Epoch [2/2] | Step [19256/22538] | Loss: 0.2129 | Accuracy: 0.9390\n","Epoch [2/2] | Step [19257/22538] | Loss: 0.4426 | Accuracy: 0.8962\n","Epoch [2/2] | Step [19258/22538] | Loss: 0.4115 | Accuracy: 0.8987\n","Epoch [2/2] | Step [19259/22538] | Loss: 0.4497 | Accuracy: 0.8817\n","Epoch [2/2] | Step [19260/22538] | Loss: 0.4046 | Accuracy: 0.8904\n","Epoch [2/2] | Step [19261/22538] | Loss: 0.3429 | Accuracy: 0.9100\n","Epoch [2/2] | Step [19262/22538] | Loss: 0.3681 | Accuracy: 0.8898\n","Epoch [2/2] | Step [19263/22538] | Loss: 0.2984 | Accuracy: 0.9062\n","Epoch [2/2] | Step [19264/22538] | Loss: 0.2240 | Accuracy: 0.9264\n","Epoch [2/2] | Step [19265/22538] | Loss: 0.2677 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19266/22538] | Loss: 0.1995 | Accuracy: 0.9472\n","Epoch [2/2] | Step [19267/22538] | Loss: 0.3619 | Accuracy: 0.9159\n","Epoch [2/2] | Step [19268/22538] | Loss: 0.2991 | Accuracy: 0.9151\n","Epoch [2/2] | Step [19269/22538] | Loss: 0.3993 | Accuracy: 0.9057\n","Epoch [2/2] | Step [19270/22538] | Loss: 0.4585 | Accuracy: 0.8839\n","Epoch [2/2] | Step [19271/22538] | Loss: 0.2412 | Accuracy: 0.9280\n","Epoch [2/2] | Step [19272/22538] | Loss: 0.3157 | Accuracy: 0.9093\n","Epoch [2/2] | Step [19273/22538] | Loss: 0.4369 | Accuracy: 0.8835\n","Epoch [2/2] | Step [19274/22538] | Loss: 0.3423 | Accuracy: 0.9110\n","Epoch [2/2] | Step [19275/22538] | Loss: 0.3321 | Accuracy: 0.9095\n","Epoch [2/2] | Step [19276/22538] | Loss: 0.3815 | Accuracy: 0.8774\n","Epoch [2/2] | Step [19277/22538] | Loss: 0.2341 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19278/22538] | Loss: 0.2518 | Accuracy: 0.9257\n","Epoch [2/2] | Step [19279/22538] | Loss: 0.1881 | Accuracy: 0.9362\n","Epoch [2/2] | Step [19280/22538] | Loss: 0.1906 | Accuracy: 0.9418\n","Epoch [2/2] | Step [19281/22538] | Loss: 0.3331 | Accuracy: 0.9013\n","Epoch [2/2] | Step [19282/22538] | Loss: 0.2950 | Accuracy: 0.9133\n","Epoch [2/2] | Step [19283/22538] | Loss: 0.2602 | Accuracy: 0.9276\n","Epoch [2/2] | Step [19284/22538] | Loss: 0.3092 | Accuracy: 0.9052\n","Epoch [2/2] | Step [19285/22538] | Loss: 0.2645 | Accuracy: 0.9228\n","Epoch [2/2] | Step [19286/22538] | Loss: 0.3140 | Accuracy: 0.9139\n","Epoch [2/2] | Step [19287/22538] | Loss: 0.2118 | Accuracy: 0.9395\n","Epoch [2/2] | Step [19288/22538] | Loss: 0.2994 | Accuracy: 0.9082\n","Epoch [2/2] | Step [19289/22538] | Loss: 0.3785 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19290/22538] | Loss: 0.3243 | Accuracy: 0.9193\n","Epoch [2/2] | Step [19291/22538] | Loss: 0.3535 | Accuracy: 0.8983\n","Epoch [2/2] | Step [19292/22538] | Loss: 0.2954 | Accuracy: 0.9026\n","Epoch [2/2] | Step [19293/22538] | Loss: 0.3692 | Accuracy: 0.8929\n","Epoch [2/2] | Step [19294/22538] | Loss: 0.2200 | Accuracy: 0.9359\n","Epoch [2/2] | Step [19295/22538] | Loss: 0.3099 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19296/22538] | Loss: 0.4179 | Accuracy: 0.8906\n","Epoch [2/2] | Step [19297/22538] | Loss: 0.4324 | Accuracy: 0.8810\n","Epoch [2/2] | Step [19298/22538] | Loss: 0.3432 | Accuracy: 0.9028\n","Epoch [2/2] | Step [19299/22538] | Loss: 0.5498 | Accuracy: 0.8830\n","Epoch [2/2] | Step [19300/22538] | Loss: 0.2787 | Accuracy: 0.9213\n","Epoch [2/2] | Step [19301/22538] | Loss: 0.2705 | Accuracy: 0.9268\n","Epoch [2/2] | Step [19302/22538] | Loss: 0.4496 | Accuracy: 0.8774\n","Epoch [2/2] | Step [19303/22538] | Loss: 0.4486 | Accuracy: 0.8812\n","Epoch [2/2] | Step [19304/22538] | Loss: 0.2315 | Accuracy: 0.9384\n","Epoch [2/2] | Step [19305/22538] | Loss: 0.3895 | Accuracy: 0.8877\n","Epoch [2/2] | Step [19306/22538] | Loss: 0.2636 | Accuracy: 0.9295\n","Epoch [2/2] | Step [19307/22538] | Loss: 0.3454 | Accuracy: 0.9190\n","Epoch [2/2] | Step [19308/22538] | Loss: 0.2178 | Accuracy: 0.9434\n","Epoch [2/2] | Step [19309/22538] | Loss: 0.3611 | Accuracy: 0.8981\n","Epoch [2/2] | Step [19310/22538] | Loss: 0.4109 | Accuracy: 0.9022\n","Epoch [2/2] | Step [19311/22538] | Loss: 0.2689 | Accuracy: 0.9366\n","Epoch [2/2] | Step [19312/22538] | Loss: 0.2990 | Accuracy: 0.9323\n","Epoch [2/2] | Step [19313/22538] | Loss: 0.2579 | Accuracy: 0.9409\n","Epoch [2/2] | Step [19314/22538] | Loss: 0.3245 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19315/22538] | Loss: 0.2997 | Accuracy: 0.9211\n","Epoch [2/2] | Step [19316/22538] | Loss: 0.3270 | Accuracy: 0.9178\n","Epoch [2/2] | Step [19317/22538] | Loss: 0.3174 | Accuracy: 0.9142\n","Epoch [2/2] | Step [19318/22538] | Loss: 0.5785 | Accuracy: 0.8700\n","Epoch [2/2] | Step [19319/22538] | Loss: 0.3172 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19320/22538] | Loss: 0.2860 | Accuracy: 0.9154\n","Epoch [2/2] | Step [19321/22538] | Loss: 0.2297 | Accuracy: 0.9358\n","Epoch [2/2] | Step [19322/22538] | Loss: 0.2757 | Accuracy: 0.9121\n","Epoch [2/2] | Step [19323/22538] | Loss: 0.2611 | Accuracy: 0.9223\n","Epoch [2/2] | Step [19324/22538] | Loss: 0.2254 | Accuracy: 0.9178\n","Epoch [2/2] | Step [19325/22538] | Loss: 0.2991 | Accuracy: 0.9191\n","Epoch [2/2] | Step [19326/22538] | Loss: 0.4092 | Accuracy: 0.9071\n","Epoch [2/2] | Step [19327/22538] | Loss: 0.3397 | Accuracy: 0.9147\n","Epoch [2/2] | Step [19328/22538] | Loss: 0.3696 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19329/22538] | Loss: 0.2908 | Accuracy: 0.9050\n","Epoch [2/2] | Step [19330/22538] | Loss: 0.4136 | Accuracy: 0.8933\n","Epoch [2/2] | Step [19331/22538] | Loss: 0.2382 | Accuracy: 0.9393\n","Epoch [2/2] | Step [19332/22538] | Loss: 0.2692 | Accuracy: 0.9336\n","Epoch [2/2] | Step [19333/22538] | Loss: 0.3473 | Accuracy: 0.9133\n","Epoch [2/2] | Step [19334/22538] | Loss: 0.2859 | Accuracy: 0.9329\n","Epoch [2/2] | Step [19335/22538] | Loss: 0.2603 | Accuracy: 0.9328\n","Epoch [2/2] | Step [19336/22538] | Loss: 0.2915 | Accuracy: 0.9340\n","Epoch [2/2] | Step [19337/22538] | Loss: 0.2515 | Accuracy: 0.9288\n","Epoch [2/2] | Step [19338/22538] | Loss: 0.3343 | Accuracy: 0.9125\n","Epoch [2/2] | Step [19339/22538] | Loss: 0.2270 | Accuracy: 0.9338\n","Epoch [2/2] | Step [19340/22538] | Loss: 0.3662 | Accuracy: 0.8919\n","Epoch [2/2] | Step [19341/22538] | Loss: 0.3503 | Accuracy: 0.8986\n","Epoch [2/2] | Step [19342/22538] | Loss: 0.4054 | Accuracy: 0.8835\n","Epoch [2/2] | Step [19343/22538] | Loss: 0.3235 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19344/22538] | Loss: 0.3760 | Accuracy: 0.8920\n","Epoch [2/2] | Step [19345/22538] | Loss: 0.4342 | Accuracy: 0.8993\n","Epoch [2/2] | Step [19346/22538] | Loss: 0.3426 | Accuracy: 0.8900\n","Epoch [2/2] | Step [19347/22538] | Loss: 0.2432 | Accuracy: 0.9375\n","Epoch [2/2] | Step [19348/22538] | Loss: 0.5180 | Accuracy: 0.8675\n","Epoch [2/2] | Step [19349/22538] | Loss: 0.2157 | Accuracy: 0.9365\n","Epoch [2/2] | Step [19350/22538] | Loss: 0.3386 | Accuracy: 0.9082\n","Epoch [2/2] | Step [19351/22538] | Loss: 0.5970 | Accuracy: 0.8615\n","Epoch [2/2] | Step [19352/22538] | Loss: 0.5137 | Accuracy: 0.8693\n","Epoch [2/2] | Step [19353/22538] | Loss: 0.2963 | Accuracy: 0.9236\n","Epoch [2/2] | Step [19354/22538] | Loss: 0.3678 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19355/22538] | Loss: 0.4456 | Accuracy: 0.8825\n","Epoch [2/2] | Step [19356/22538] | Loss: 0.3535 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19357/22538] | Loss: 0.3608 | Accuracy: 0.8947\n","Epoch [2/2] | Step [19358/22538] | Loss: 0.2536 | Accuracy: 0.9289\n","Epoch [2/2] | Step [19359/22538] | Loss: 0.4389 | Accuracy: 0.9012\n","Epoch [2/2] | Step [19360/22538] | Loss: 0.4594 | Accuracy: 0.8897\n","Epoch [2/2] | Step [19361/22538] | Loss: 0.3787 | Accuracy: 0.8774\n","Epoch [2/2] | Step [19362/22538] | Loss: 0.2613 | Accuracy: 0.9273\n","Epoch [2/2] | Step [19363/22538] | Loss: 0.3458 | Accuracy: 0.8988\n","Epoch [2/2] | Step [19364/22538] | Loss: 0.3861 | Accuracy: 0.9075\n","Epoch [2/2] | Step [19365/22538] | Loss: 0.4913 | Accuracy: 0.8517\n","Epoch [2/2] | Step [19366/22538] | Loss: 0.4068 | Accuracy: 0.8856\n","Epoch [2/2] | Step [19367/22538] | Loss: 0.2562 | Accuracy: 0.9359\n","Epoch [2/2] | Step [19368/22538] | Loss: 0.2400 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19369/22538] | Loss: 0.3143 | Accuracy: 0.9122\n","Epoch [2/2] | Step [19370/22538] | Loss: 0.3018 | Accuracy: 0.9180\n","Epoch [2/2] | Step [19371/22538] | Loss: 0.3128 | Accuracy: 0.9038\n","Epoch [2/2] | Step [19372/22538] | Loss: 0.2978 | Accuracy: 0.9172\n","Epoch [2/2] | Step [19373/22538] | Loss: 0.3082 | Accuracy: 0.8892\n","Epoch [2/2] | Step [19374/22538] | Loss: 0.3688 | Accuracy: 0.9016\n","Epoch [2/2] | Step [19375/22538] | Loss: 0.3233 | Accuracy: 0.9078\n","Epoch [2/2] | Step [19376/22538] | Loss: 0.1795 | Accuracy: 0.9531\n","Epoch [2/2] | Step [19377/22538] | Loss: 0.3287 | Accuracy: 0.9107\n","Epoch [2/2] | Step [19378/22538] | Loss: 0.2963 | Accuracy: 0.9190\n","Epoch [2/2] | Step [19379/22538] | Loss: 0.6427 | Accuracy: 0.8354\n","Epoch [2/2] | Step [19380/22538] | Loss: 0.3616 | Accuracy: 0.9054\n","Epoch [2/2] | Step [19381/22538] | Loss: 0.2695 | Accuracy: 0.9315\n","Epoch [2/2] | Step [19382/22538] | Loss: 0.2537 | Accuracy: 0.9237\n","Epoch [2/2] | Step [19383/22538] | Loss: 0.3385 | Accuracy: 0.9052\n","Epoch [2/2] | Step [19384/22538] | Loss: 0.3495 | Accuracy: 0.8948\n","Epoch [2/2] | Step [19385/22538] | Loss: 0.3104 | Accuracy: 0.9195\n","Epoch [2/2] | Step [19386/22538] | Loss: 0.3152 | Accuracy: 0.9179\n","Epoch [2/2] | Step [19387/22538] | Loss: 0.3622 | Accuracy: 0.9009\n","Epoch [2/2] | Step [19388/22538] | Loss: 0.3875 | Accuracy: 0.8859\n","Epoch [2/2] | Step [19389/22538] | Loss: 0.2864 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19390/22538] | Loss: 0.3212 | Accuracy: 0.9256\n","Epoch [2/2] | Step [19391/22538] | Loss: 0.3021 | Accuracy: 0.9119\n","Epoch [2/2] | Step [19392/22538] | Loss: 0.3024 | Accuracy: 0.9212\n","Epoch [2/2] | Step [19393/22538] | Loss: 0.5009 | Accuracy: 0.8802\n","Epoch [2/2] | Step [19394/22538] | Loss: 0.3862 | Accuracy: 0.9022\n","Epoch [2/2] | Step [19395/22538] | Loss: 0.2180 | Accuracy: 0.9393\n","Epoch [2/2] | Step [19396/22538] | Loss: 0.2808 | Accuracy: 0.9151\n","Epoch [2/2] | Step [19397/22538] | Loss: 0.4442 | Accuracy: 0.8772\n","Epoch [2/2] | Step [19398/22538] | Loss: 0.2698 | Accuracy: 0.9137\n","Epoch [2/2] | Step [19399/22538] | Loss: 0.2858 | Accuracy: 0.9286\n","Epoch [2/2] | Step [19400/22538] | Loss: 0.3523 | Accuracy: 0.9158\n","Epoch [2/2] | Step [19401/22538] | Loss: 0.4229 | Accuracy: 0.8932\n","Epoch [2/2] | Step [19402/22538] | Loss: 0.2074 | Accuracy: 0.9375\n","Epoch [2/2] | Step [19403/22538] | Loss: 0.2670 | Accuracy: 0.9076\n","Epoch [2/2] | Step [19404/22538] | Loss: 0.3179 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19405/22538] | Loss: 0.3022 | Accuracy: 0.9224\n","Epoch [2/2] | Step [19406/22538] | Loss: 0.3320 | Accuracy: 0.9152\n","Epoch [2/2] | Step [19407/22538] | Loss: 0.3730 | Accuracy: 0.8781\n","Epoch [2/2] | Step [19408/22538] | Loss: 0.3915 | Accuracy: 0.8906\n","Epoch [2/2] | Step [19409/22538] | Loss: 0.2924 | Accuracy: 0.9113\n","Epoch [2/2] | Step [19410/22538] | Loss: 0.3076 | Accuracy: 0.9043\n","Epoch [2/2] | Step [19411/22538] | Loss: 0.4829 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19412/22538] | Loss: 0.2823 | Accuracy: 0.9143\n","Epoch [2/2] | Step [19413/22538] | Loss: 0.3563 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19414/22538] | Loss: 0.2803 | Accuracy: 0.9266\n","Epoch [2/2] | Step [19415/22538] | Loss: 0.2435 | Accuracy: 0.9255\n","Epoch [2/2] | Step [19416/22538] | Loss: 0.3168 | Accuracy: 0.9198\n","Epoch [2/2] | Step [19417/22538] | Loss: 0.3251 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19418/22538] | Loss: 0.3235 | Accuracy: 0.9189\n","Epoch [2/2] | Step [19419/22538] | Loss: 0.3129 | Accuracy: 0.8925\n","Epoch [2/2] | Step [19420/22538] | Loss: 0.2994 | Accuracy: 0.9186\n","Epoch [2/2] | Step [19421/22538] | Loss: 0.2332 | Accuracy: 0.9345\n","Epoch [2/2] | Step [19422/22538] | Loss: 0.3719 | Accuracy: 0.8984\n","Epoch [2/2] | Step [19423/22538] | Loss: 0.4181 | Accuracy: 0.8802\n","Epoch [2/2] | Step [19424/22538] | Loss: 0.1509 | Accuracy: 0.9564\n","Epoch [2/2] | Step [19425/22538] | Loss: 0.2649 | Accuracy: 0.9275\n","Epoch [2/2] | Step [19426/22538] | Loss: 0.4472 | Accuracy: 0.8917\n","Epoch [2/2] | Step [19427/22538] | Loss: 0.5024 | Accuracy: 0.8556\n","Epoch [2/2] | Step [19428/22538] | Loss: 0.2754 | Accuracy: 0.9271\n","Epoch [2/2] | Step [19429/22538] | Loss: 0.3373 | Accuracy: 0.9036\n","Epoch [2/2] | Step [19430/22538] | Loss: 0.2334 | Accuracy: 0.9288\n","Epoch [2/2] | Step [19431/22538] | Loss: 0.3491 | Accuracy: 0.9005\n","Epoch [2/2] | Step [19432/22538] | Loss: 0.3470 | Accuracy: 0.8925\n","Epoch [2/2] | Step [19433/22538] | Loss: 0.3895 | Accuracy: 0.9004\n","Epoch [2/2] | Step [19434/22538] | Loss: 0.2548 | Accuracy: 0.9238\n","Epoch [2/2] | Step [19435/22538] | Loss: 0.1896 | Accuracy: 0.9384\n","Epoch [2/2] | Step [19436/22538] | Loss: 0.2592 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19437/22538] | Loss: 0.4456 | Accuracy: 0.8939\n","Epoch [2/2] | Step [19438/22538] | Loss: 0.3525 | Accuracy: 0.9040\n","Epoch [2/2] | Step [19439/22538] | Loss: 0.2976 | Accuracy: 0.9261\n","Epoch [2/2] | Step [19440/22538] | Loss: 0.2703 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19441/22538] | Loss: 0.2572 | Accuracy: 0.9375\n","Epoch [2/2] | Step [19442/22538] | Loss: 0.4033 | Accuracy: 0.9018\n","Epoch [2/2] | Step [19443/22538] | Loss: 0.3027 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19444/22538] | Loss: 0.2392 | Accuracy: 0.9277\n","Epoch [2/2] | Step [19445/22538] | Loss: 0.3271 | Accuracy: 0.9038\n","Epoch [2/2] | Step [19446/22538] | Loss: 0.3396 | Accuracy: 0.9283\n","Epoch [2/2] | Step [19447/22538] | Loss: 0.3713 | Accuracy: 0.8824\n","Epoch [2/2] | Step [19448/22538] | Loss: 0.3806 | Accuracy: 0.8988\n","Epoch [2/2] | Step [19449/22538] | Loss: 0.3869 | Accuracy: 0.8939\n","Epoch [2/2] | Step [19450/22538] | Loss: 0.2780 | Accuracy: 0.9174\n","Epoch [2/2] | Step [19451/22538] | Loss: 0.3082 | Accuracy: 0.9119\n","Epoch [2/2] | Step [19452/22538] | Loss: 0.4204 | Accuracy: 0.8822\n","Epoch [2/2] | Step [19453/22538] | Loss: 0.7304 | Accuracy: 0.8484\n","Epoch [2/2] | Step [19454/22538] | Loss: 0.3416 | Accuracy: 0.9063\n","Epoch [2/2] | Step [19455/22538] | Loss: 0.3339 | Accuracy: 0.9079\n","Epoch [2/2] | Step [19456/22538] | Loss: 0.2538 | Accuracy: 0.9229\n","Epoch [2/2] | Step [19457/22538] | Loss: 0.4063 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19458/22538] | Loss: 0.3756 | Accuracy: 0.8904\n","Epoch [2/2] | Step [19459/22538] | Loss: 0.3168 | Accuracy: 0.9286\n","Epoch [2/2] | Step [19460/22538] | Loss: 0.2689 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19461/22538] | Loss: 0.3514 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19462/22538] | Loss: 0.4706 | Accuracy: 0.8773\n","Epoch [2/2] | Step [19463/22538] | Loss: 0.4421 | Accuracy: 0.8975\n","Epoch [2/2] | Step [19464/22538] | Loss: 0.2293 | Accuracy: 0.9345\n","Epoch [2/2] | Step [19465/22538] | Loss: 0.4072 | Accuracy: 0.8947\n","Epoch [2/2] | Step [19466/22538] | Loss: 0.2919 | Accuracy: 0.9115\n","Epoch [2/2] | Step [19467/22538] | Loss: 0.3627 | Accuracy: 0.8918\n","Epoch [2/2] | Step [19468/22538] | Loss: 0.3642 | Accuracy: 0.8989\n","Epoch [2/2] | Step [19469/22538] | Loss: 0.3533 | Accuracy: 0.9012\n","Epoch [2/2] | Step [19470/22538] | Loss: 0.4036 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19471/22538] | Loss: 0.3602 | Accuracy: 0.9184\n","Epoch [2/2] | Step [19472/22538] | Loss: 0.4763 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19473/22538] | Loss: 0.1913 | Accuracy: 0.9472\n","Epoch [2/2] | Step [19474/22538] | Loss: 0.3054 | Accuracy: 0.9173\n","Epoch [2/2] | Step [19475/22538] | Loss: 0.3370 | Accuracy: 0.9136\n","Epoch [2/2] | Step [19476/22538] | Loss: 0.3438 | Accuracy: 0.9045\n","Epoch [2/2] | Step [19477/22538] | Loss: 0.5817 | Accuracy: 0.8571\n","Epoch [2/2] | Step [19478/22538] | Loss: 0.4161 | Accuracy: 0.8913\n","Epoch [2/2] | Step [19479/22538] | Loss: 0.2914 | Accuracy: 0.9267\n","Epoch [2/2] | Step [19480/22538] | Loss: 0.3919 | Accuracy: 0.8963\n","Epoch [2/2] | Step [19481/22538] | Loss: 0.3531 | Accuracy: 0.8906\n","Epoch [2/2] | Step [19482/22538] | Loss: 0.2437 | Accuracy: 0.9161\n","Epoch [2/2] | Step [19483/22538] | Loss: 0.2389 | Accuracy: 0.9410\n","Epoch [2/2] | Step [19484/22538] | Loss: 0.2600 | Accuracy: 0.9229\n","Epoch [2/2] | Step [19485/22538] | Loss: 0.4012 | Accuracy: 0.8906\n","Epoch [2/2] | Step [19486/22538] | Loss: 0.2257 | Accuracy: 0.9289\n","Epoch [2/2] | Step [19487/22538] | Loss: 0.5360 | Accuracy: 0.8712\n","Epoch [2/2] | Step [19488/22538] | Loss: 0.2251 | Accuracy: 0.9232\n","Epoch [2/2] | Step [19489/22538] | Loss: 0.3246 | Accuracy: 0.9148\n","Epoch [2/2] | Step [19490/22538] | Loss: 0.3926 | Accuracy: 0.8955\n","Epoch [2/2] | Step [19491/22538] | Loss: 0.3392 | Accuracy: 0.8797\n","Epoch [2/2] | Step [19492/22538] | Loss: 0.6289 | Accuracy: 0.8675\n","Epoch [2/2] | Step [19493/22538] | Loss: 0.2923 | Accuracy: 0.9142\n","Epoch [2/2] | Step [19494/22538] | Loss: 0.3474 | Accuracy: 0.9123\n","Epoch [2/2] | Step [19495/22538] | Loss: 0.4869 | Accuracy: 0.9044\n","Epoch [2/2] | Step [19496/22538] | Loss: 0.2572 | Accuracy: 0.9412\n","Epoch [2/2] | Step [19497/22538] | Loss: 0.2390 | Accuracy: 0.9355\n","Epoch [2/2] | Step [19498/22538] | Loss: 0.2210 | Accuracy: 0.9375\n","Epoch [2/2] | Step [19499/22538] | Loss: 0.3973 | Accuracy: 0.8798\n","Epoch [2/2] | Step [19500/22538] | Loss: 0.3144 | Accuracy: 0.9094\n","Epoch [2/2] | Step [19501/22538] | Loss: 0.4110 | Accuracy: 0.8806\n","Epoch [2/2] | Step [19502/22538] | Loss: 0.3117 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19503/22538] | Loss: 0.3121 | Accuracy: 0.9162\n","Epoch [2/2] | Step [19504/22538] | Loss: 0.2613 | Accuracy: 0.9338\n","Epoch [2/2] | Step [19505/22538] | Loss: 0.2889 | Accuracy: 0.9259\n","Epoch [2/2] | Step [19506/22538] | Loss: 0.2761 | Accuracy: 0.9214\n","Epoch [2/2] | Step [19507/22538] | Loss: 0.2408 | Accuracy: 0.9244\n","Epoch [2/2] | Step [19508/22538] | Loss: 0.3186 | Accuracy: 0.9051\n","Epoch [2/2] | Step [19509/22538] | Loss: 0.4598 | Accuracy: 0.9000\n","Epoch [2/2] | Step [19510/22538] | Loss: 0.4575 | Accuracy: 0.8854\n","Epoch [2/2] | Step [19511/22538] | Loss: 0.3881 | Accuracy: 0.8967\n","Epoch [2/2] | Step [19512/22538] | Loss: 0.2735 | Accuracy: 0.9292\n","Epoch [2/2] | Step [19513/22538] | Loss: 0.2924 | Accuracy: 0.9127\n","Epoch [2/2] | Step [19514/22538] | Loss: 0.2630 | Accuracy: 0.9235\n","Epoch [2/2] | Step [19515/22538] | Loss: 0.3207 | Accuracy: 0.9035\n","Epoch [2/2] | Step [19516/22538] | Loss: 0.3404 | Accuracy: 0.9078\n","Epoch [2/2] | Step [19517/22538] | Loss: 0.5628 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19518/22538] | Loss: 0.3093 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19519/22538] | Loss: 0.3498 | Accuracy: 0.8955\n","Epoch [2/2] | Step [19520/22538] | Loss: 0.3204 | Accuracy: 0.9257\n","Epoch [2/2] | Step [19521/22538] | Loss: 0.2842 | Accuracy: 0.9257\n","Epoch [2/2] | Step [19522/22538] | Loss: 0.3250 | Accuracy: 0.9043\n","Epoch [2/2] | Step [19523/22538] | Loss: 0.2450 | Accuracy: 0.9434\n","Epoch [2/2] | Step [19524/22538] | Loss: 0.2592 | Accuracy: 0.9231\n","Epoch [2/2] | Step [19525/22538] | Loss: 0.2243 | Accuracy: 0.9357\n","Epoch [2/2] | Step [19526/22538] | Loss: 0.3530 | Accuracy: 0.9062\n","Epoch [2/2] | Step [19527/22538] | Loss: 0.2454 | Accuracy: 0.9280\n","Epoch [2/2] | Step [19528/22538] | Loss: 0.3362 | Accuracy: 0.9153\n","Epoch [2/2] | Step [19529/22538] | Loss: 0.1918 | Accuracy: 0.9515\n","Epoch [2/2] | Step [19530/22538] | Loss: 0.2612 | Accuracy: 0.9209\n","Epoch [2/2] | Step [19531/22538] | Loss: 0.3787 | Accuracy: 0.9118\n","Epoch [2/2] | Step [19532/22538] | Loss: 0.4139 | Accuracy: 0.8904\n","Epoch [2/2] | Step [19533/22538] | Loss: 0.3850 | Accuracy: 0.9062\n","Epoch [2/2] | Step [19534/22538] | Loss: 0.3991 | Accuracy: 0.8988\n","Epoch [2/2] | Step [19535/22538] | Loss: 0.3473 | Accuracy: 0.8902\n","Epoch [2/2] | Step [19536/22538] | Loss: 0.3378 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19537/22538] | Loss: 0.3567 | Accuracy: 0.9040\n","Epoch [2/2] | Step [19538/22538] | Loss: 0.2267 | Accuracy: 0.9451\n","Epoch [2/2] | Step [19539/22538] | Loss: 0.4550 | Accuracy: 0.8774\n","Epoch [2/2] | Step [19540/22538] | Loss: 0.4391 | Accuracy: 0.9023\n","Epoch [2/2] | Step [19541/22538] | Loss: 0.4036 | Accuracy: 0.8803\n","Epoch [2/2] | Step [19542/22538] | Loss: 0.3037 | Accuracy: 0.9107\n","Epoch [2/2] | Step [19543/22538] | Loss: 0.1825 | Accuracy: 0.9352\n","Epoch [2/2] | Step [19544/22538] | Loss: 0.3166 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19545/22538] | Loss: 0.3600 | Accuracy: 0.9046\n","Epoch [2/2] | Step [19546/22538] | Loss: 0.3534 | Accuracy: 0.9009\n","Epoch [2/2] | Step [19547/22538] | Loss: 0.3214 | Accuracy: 0.9005\n","Epoch [2/2] | Step [19548/22538] | Loss: 0.3793 | Accuracy: 0.8986\n","Epoch [2/2] | Step [19549/22538] | Loss: 0.3452 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19550/22538] | Loss: 0.2595 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19551/22538] | Loss: 0.2342 | Accuracy: 0.9429\n","Epoch [2/2] | Step [19552/22538] | Loss: 0.2959 | Accuracy: 0.9190\n","Epoch [2/2] | Step [19553/22538] | Loss: 0.3237 | Accuracy: 0.9022\n","Epoch [2/2] | Step [19554/22538] | Loss: 0.4450 | Accuracy: 0.8815\n","Epoch [2/2] | Step [19555/22538] | Loss: 0.4287 | Accuracy: 0.8912\n","Epoch [2/2] | Step [19556/22538] | Loss: 0.3609 | Accuracy: 0.8966\n","Epoch [2/2] | Step [19557/22538] | Loss: 0.4366 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19558/22538] | Loss: 0.2972 | Accuracy: 0.9136\n","Epoch [2/2] | Step [19559/22538] | Loss: 0.2933 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19560/22538] | Loss: 0.2486 | Accuracy: 0.9209\n","Epoch [2/2] | Step [19561/22538] | Loss: 0.2967 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19562/22538] | Loss: 0.2702 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19563/22538] | Loss: 0.3049 | Accuracy: 0.9077\n","Epoch [2/2] | Step [19564/22538] | Loss: 0.4419 | Accuracy: 0.8730\n","Epoch [2/2] | Step [19565/22538] | Loss: 0.4031 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19566/22538] | Loss: 0.3044 | Accuracy: 0.9160\n","Epoch [2/2] | Step [19567/22538] | Loss: 0.1784 | Accuracy: 0.9533\n","Epoch [2/2] | Step [19568/22538] | Loss: 0.1662 | Accuracy: 0.9470\n","Epoch [2/2] | Step [19569/22538] | Loss: 0.3315 | Accuracy: 0.9130\n","Epoch [2/2] | Step [19570/22538] | Loss: 0.2994 | Accuracy: 0.9227\n","Epoch [2/2] | Step [19571/22538] | Loss: 0.3731 | Accuracy: 0.9127\n","Epoch [2/2] | Step [19572/22538] | Loss: 0.3833 | Accuracy: 0.9012\n","Epoch [2/2] | Step [19573/22538] | Loss: 0.3776 | Accuracy: 0.9095\n","Epoch [2/2] | Step [19574/22538] | Loss: 0.3048 | Accuracy: 0.9119\n","Epoch [2/2] | Step [19575/22538] | Loss: 0.3441 | Accuracy: 0.8991\n","Epoch [2/2] | Step [19576/22538] | Loss: 0.2712 | Accuracy: 0.9315\n","Epoch [2/2] | Step [19577/22538] | Loss: 0.3684 | Accuracy: 0.8962\n","Epoch [2/2] | Step [19578/22538] | Loss: 0.2225 | Accuracy: 0.9383\n","Epoch [2/2] | Step [19579/22538] | Loss: 0.5484 | Accuracy: 0.8966\n","Epoch [2/2] | Step [19580/22538] | Loss: 0.2827 | Accuracy: 0.9078\n","Epoch [2/2] | Step [19581/22538] | Loss: 0.3815 | Accuracy: 0.9076\n","Epoch [2/2] | Step [19582/22538] | Loss: 0.2917 | Accuracy: 0.9095\n","Epoch [2/2] | Step [19583/22538] | Loss: 0.3534 | Accuracy: 0.8963\n","Epoch [2/2] | Step [19584/22538] | Loss: 0.5659 | Accuracy: 0.8548\n","Epoch [2/2] | Step [19585/22538] | Loss: 0.4509 | Accuracy: 0.8909\n","Epoch [2/2] | Step [19586/22538] | Loss: 0.4049 | Accuracy: 0.9125\n","Epoch [2/2] | Step [19587/22538] | Loss: 0.2264 | Accuracy: 0.9336\n","Epoch [2/2] | Step [19588/22538] | Loss: 0.3675 | Accuracy: 0.8854\n","Epoch [2/2] | Step [19589/22538] | Loss: 0.3617 | Accuracy: 0.9076\n","Epoch [2/2] | Step [19590/22538] | Loss: 0.3754 | Accuracy: 0.8856\n","Epoch [2/2] | Step [19591/22538] | Loss: 0.4465 | Accuracy: 0.8878\n","Epoch [2/2] | Step [19592/22538] | Loss: 0.3261 | Accuracy: 0.9014\n","Epoch [2/2] | Step [19593/22538] | Loss: 0.2875 | Accuracy: 0.9114\n","Epoch [2/2] | Step [19594/22538] | Loss: 0.4627 | Accuracy: 0.9005\n","Epoch [2/2] | Step [19595/22538] | Loss: 0.2458 | Accuracy: 0.9208\n","Epoch [2/2] | Step [19596/22538] | Loss: 0.2449 | Accuracy: 0.9223\n","Epoch [2/2] | Step [19597/22538] | Loss: 0.2607 | Accuracy: 0.9253\n","Epoch [2/2] | Step [19598/22538] | Loss: 0.2325 | Accuracy: 0.9337\n","Epoch [2/2] | Step [19599/22538] | Loss: 0.2766 | Accuracy: 0.9083\n","Epoch [2/2] | Step [19600/22538] | Loss: 0.5906 | Accuracy: 0.8592\n","Epoch [2/2] | Step [19601/22538] | Loss: 0.3339 | Accuracy: 0.8994\n","Epoch [2/2] | Step [19602/22538] | Loss: 0.3642 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19603/22538] | Loss: 0.4856 | Accuracy: 0.8827\n","Epoch [2/2] | Step [19604/22538] | Loss: 0.2528 | Accuracy: 0.9363\n","Epoch [2/2] | Step [19605/22538] | Loss: 0.3584 | Accuracy: 0.8989\n","Epoch [2/2] | Step [19606/22538] | Loss: 0.5410 | Accuracy: 0.8661\n","Epoch [2/2] | Step [19607/22538] | Loss: 0.2866 | Accuracy: 0.9154\n","Epoch [2/2] | Step [19608/22538] | Loss: 0.2988 | Accuracy: 0.9111\n","Epoch [2/2] | Step [19609/22538] | Loss: 0.3199 | Accuracy: 0.9077\n","Epoch [2/2] | Step [19610/22538] | Loss: 0.5015 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19611/22538] | Loss: 0.4457 | Accuracy: 0.8727\n","Epoch [2/2] | Step [19612/22538] | Loss: 0.3649 | Accuracy: 0.8988\n","Epoch [2/2] | Step [19613/22538] | Loss: 0.3388 | Accuracy: 0.9133\n","Epoch [2/2] | Step [19614/22538] | Loss: 0.2361 | Accuracy: 0.9327\n","Epoch [2/2] | Step [19615/22538] | Loss: 0.2226 | Accuracy: 0.9318\n","Epoch [2/2] | Step [19616/22538] | Loss: 0.5392 | Accuracy: 0.8717\n","Epoch [2/2] | Step [19617/22538] | Loss: 0.4219 | Accuracy: 0.8862\n","Epoch [2/2] | Step [19618/22538] | Loss: 0.2262 | Accuracy: 0.9471\n","Epoch [2/2] | Step [19619/22538] | Loss: 0.2644 | Accuracy: 0.9274\n","Epoch [2/2] | Step [19620/22538] | Loss: 0.2427 | Accuracy: 0.9266\n","Epoch [2/2] | Step [19621/22538] | Loss: 0.3585 | Accuracy: 0.8973\n","Epoch [2/2] | Step [19622/22538] | Loss: 0.2438 | Accuracy: 0.9321\n","Epoch [2/2] | Step [19623/22538] | Loss: 0.3907 | Accuracy: 0.8903\n","Epoch [2/2] | Step [19624/22538] | Loss: 0.3929 | Accuracy: 0.9012\n","Epoch [2/2] | Step [19625/22538] | Loss: 0.2165 | Accuracy: 0.9260\n","Epoch [2/2] | Step [19626/22538] | Loss: 0.2996 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19627/22538] | Loss: 0.2814 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19628/22538] | Loss: 0.3399 | Accuracy: 0.9160\n","Epoch [2/2] | Step [19629/22538] | Loss: 0.2877 | Accuracy: 0.9191\n","Epoch [2/2] | Step [19630/22538] | Loss: 0.5164 | Accuracy: 0.8617\n","Epoch [2/2] | Step [19631/22538] | Loss: 0.3588 | Accuracy: 0.8816\n","Epoch [2/2] | Step [19632/22538] | Loss: 0.2324 | Accuracy: 0.9203\n","Epoch [2/2] | Step [19633/22538] | Loss: 0.1729 | Accuracy: 0.9569\n","Epoch [2/2] | Step [19634/22538] | Loss: 0.3924 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19635/22538] | Loss: 0.4123 | Accuracy: 0.8944\n","Epoch [2/2] | Step [19636/22538] | Loss: 0.3051 | Accuracy: 0.9043\n","Epoch [2/2] | Step [19637/22538] | Loss: 0.2952 | Accuracy: 0.9100\n","Epoch [2/2] | Step [19638/22538] | Loss: 0.4613 | Accuracy: 0.8686\n","Epoch [2/2] | Step [19639/22538] | Loss: 0.2940 | Accuracy: 0.9222\n","Epoch [2/2] | Step [19640/22538] | Loss: 0.3812 | Accuracy: 0.9025\n","Epoch [2/2] | Step [19641/22538] | Loss: 0.2495 | Accuracy: 0.9221\n","Epoch [2/2] | Step [19642/22538] | Loss: 0.3336 | Accuracy: 0.8949\n","Epoch [2/2] | Step [19643/22538] | Loss: 0.5182 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19644/22538] | Loss: 0.2848 | Accuracy: 0.9265\n","Epoch [2/2] | Step [19645/22538] | Loss: 0.2707 | Accuracy: 0.9213\n","Epoch [2/2] | Step [19646/22538] | Loss: 0.3173 | Accuracy: 0.9008\n","Epoch [2/2] | Step [19647/22538] | Loss: 0.2211 | Accuracy: 0.9269\n","Epoch [2/2] | Step [19648/22538] | Loss: 0.2930 | Accuracy: 0.9073\n","Epoch [2/2] | Step [19649/22538] | Loss: 0.2944 | Accuracy: 0.9184\n","Epoch [2/2] | Step [19650/22538] | Loss: 0.3051 | Accuracy: 0.9103\n","Epoch [2/2] | Step [19651/22538] | Loss: 0.3674 | Accuracy: 0.9049\n","Epoch [2/2] | Step [19652/22538] | Loss: 0.3215 | Accuracy: 0.9097\n","Epoch [2/2] | Step [19653/22538] | Loss: 0.3424 | Accuracy: 0.9031\n","Epoch [2/2] | Step [19654/22538] | Loss: 0.4166 | Accuracy: 0.8906\n","Epoch [2/2] | Step [19655/22538] | Loss: 0.2697 | Accuracy: 0.9275\n","Epoch [2/2] | Step [19656/22538] | Loss: 0.3525 | Accuracy: 0.9004\n","Epoch [2/2] | Step [19657/22538] | Loss: 0.3017 | Accuracy: 0.9074\n","Epoch [2/2] | Step [19658/22538] | Loss: 0.2275 | Accuracy: 0.9337\n","Epoch [2/2] | Step [19659/22538] | Loss: 0.2972 | Accuracy: 0.9145\n","Epoch [2/2] | Step [19660/22538] | Loss: 0.2767 | Accuracy: 0.9212\n","Epoch [2/2] | Step [19661/22538] | Loss: 0.2158 | Accuracy: 0.9424\n","Epoch [2/2] | Step [19662/22538] | Loss: 0.3097 | Accuracy: 0.9179\n","Epoch [2/2] | Step [19663/22538] | Loss: 0.3221 | Accuracy: 0.9141\n","Epoch [2/2] | Step [19664/22538] | Loss: 0.1980 | Accuracy: 0.9460\n","Epoch [2/2] | Step [19665/22538] | Loss: 0.3098 | Accuracy: 0.9211\n","Epoch [2/2] | Step [19666/22538] | Loss: 0.3807 | Accuracy: 0.8953\n","Epoch [2/2] | Step [19667/22538] | Loss: 0.3363 | Accuracy: 0.9052\n","Epoch [2/2] | Step [19668/22538] | Loss: 0.3801 | Accuracy: 0.8984\n","Epoch [2/2] | Step [19669/22538] | Loss: 0.2993 | Accuracy: 0.9182\n","Epoch [2/2] | Step [19670/22538] | Loss: 0.3066 | Accuracy: 0.9125\n","Epoch [2/2] | Step [19671/22538] | Loss: 0.3253 | Accuracy: 0.9092\n","Epoch [2/2] | Step [19672/22538] | Loss: 0.3635 | Accuracy: 0.8929\n","Epoch [2/2] | Step [19673/22538] | Loss: 0.4235 | Accuracy: 0.8824\n","Epoch [2/2] | Step [19674/22538] | Loss: 0.2827 | Accuracy: 0.9182\n","Epoch [2/2] | Step [19675/22538] | Loss: 0.2819 | Accuracy: 0.9295\n","Epoch [2/2] | Step [19676/22538] | Loss: 0.3138 | Accuracy: 0.9207\n","Epoch [2/2] | Step [19677/22538] | Loss: 0.2905 | Accuracy: 0.8995\n","Epoch [2/2] | Step [19678/22538] | Loss: 0.3429 | Accuracy: 0.8965\n","Epoch [2/2] | Step [19679/22538] | Loss: 0.5189 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19680/22538] | Loss: 0.2858 | Accuracy: 0.9093\n","Epoch [2/2] | Step [19681/22538] | Loss: 0.5065 | Accuracy: 0.8980\n","Epoch [2/2] | Step [19682/22538] | Loss: 0.2312 | Accuracy: 0.9298\n","Epoch [2/2] | Step [19683/22538] | Loss: 0.3245 | Accuracy: 0.9073\n","Epoch [2/2] | Step [19684/22538] | Loss: 0.2858 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19685/22538] | Loss: 0.3512 | Accuracy: 0.9298\n","Epoch [2/2] | Step [19686/22538] | Loss: 0.3531 | Accuracy: 0.8965\n","Epoch [2/2] | Step [19687/22538] | Loss: 0.2780 | Accuracy: 0.9115\n","Epoch [2/2] | Step [19688/22538] | Loss: 0.2478 | Accuracy: 0.9239\n","Epoch [2/2] | Step [19689/22538] | Loss: 0.2678 | Accuracy: 0.9273\n","Epoch [2/2] | Step [19690/22538] | Loss: 0.2626 | Accuracy: 0.9280\n","Epoch [2/2] | Step [19691/22538] | Loss: 0.3582 | Accuracy: 0.9110\n","Epoch [2/2] | Step [19692/22538] | Loss: 0.4460 | Accuracy: 0.8871\n","Epoch [2/2] | Step [19693/22538] | Loss: 0.3229 | Accuracy: 0.9000\n","Epoch [2/2] | Step [19694/22538] | Loss: 0.3064 | Accuracy: 0.9242\n","Epoch [2/2] | Step [19695/22538] | Loss: 0.3861 | Accuracy: 0.8942\n","Epoch [2/2] | Step [19696/22538] | Loss: 0.3961 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19697/22538] | Loss: 0.2528 | Accuracy: 0.9288\n","Epoch [2/2] | Step [19698/22538] | Loss: 0.3634 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19699/22538] | Loss: 0.3840 | Accuracy: 0.8995\n","Epoch [2/2] | Step [19700/22538] | Loss: 0.2413 | Accuracy: 0.9261\n","Epoch [2/2] | Step [19701/22538] | Loss: 0.4094 | Accuracy: 0.9020\n","Epoch [2/2] | Step [19702/22538] | Loss: 0.3613 | Accuracy: 0.8947\n","Epoch [2/2] | Step [19703/22538] | Loss: 0.3462 | Accuracy: 0.9135\n","Epoch [2/2] | Step [19704/22538] | Loss: 0.2872 | Accuracy: 0.9069\n","Epoch [2/2] | Step [19705/22538] | Loss: 0.3587 | Accuracy: 0.9077\n","Epoch [2/2] | Step [19706/22538] | Loss: 0.3164 | Accuracy: 0.9100\n","Epoch [2/2] | Step [19707/22538] | Loss: 0.2603 | Accuracy: 0.9306\n","Epoch [2/2] | Step [19708/22538] | Loss: 0.1688 | Accuracy: 0.9567\n","Epoch [2/2] | Step [19709/22538] | Loss: 0.3974 | Accuracy: 0.8827\n","Epoch [2/2] | Step [19710/22538] | Loss: 0.3988 | Accuracy: 0.8818\n","Epoch [2/2] | Step [19711/22538] | Loss: 0.2487 | Accuracy: 0.9189\n","Epoch [2/2] | Step [19712/22538] | Loss: 0.3439 | Accuracy: 0.8932\n","Epoch [2/2] | Step [19713/22538] | Loss: 0.3840 | Accuracy: 0.8895\n","Epoch [2/2] | Step [19714/22538] | Loss: 0.2881 | Accuracy: 0.9079\n","Epoch [2/2] | Step [19715/22538] | Loss: 0.2771 | Accuracy: 0.9056\n","Epoch [2/2] | Step [19716/22538] | Loss: 0.2491 | Accuracy: 0.9364\n","Epoch [2/2] | Step [19717/22538] | Loss: 0.3371 | Accuracy: 0.9231\n","Epoch [2/2] | Step [19718/22538] | Loss: 0.4392 | Accuracy: 0.9071\n","Epoch [2/2] | Step [19719/22538] | Loss: 0.3578 | Accuracy: 0.9046\n","Epoch [2/2] | Step [19720/22538] | Loss: 0.4290 | Accuracy: 0.8750\n","Epoch [2/2] | Step [19721/22538] | Loss: 0.3366 | Accuracy: 0.9264\n","Epoch [2/2] | Step [19722/22538] | Loss: 0.3646 | Accuracy: 0.8983\n","Epoch [2/2] | Step [19723/22538] | Loss: 0.3589 | Accuracy: 0.9067\n","Epoch [2/2] | Step [19724/22538] | Loss: 0.2558 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19725/22538] | Loss: 0.4699 | Accuracy: 0.9069\n","Epoch [2/2] | Step [19726/22538] | Loss: 0.3296 | Accuracy: 0.9018\n","Epoch [2/2] | Step [19727/22538] | Loss: 0.1815 | Accuracy: 0.9492\n","Epoch [2/2] | Step [19728/22538] | Loss: 0.3301 | Accuracy: 0.9118\n","Epoch [2/2] | Step [19729/22538] | Loss: 0.3946 | Accuracy: 0.9043\n","Epoch [2/2] | Step [19730/22538] | Loss: 0.4678 | Accuracy: 0.8810\n","Epoch [2/2] | Step [19731/22538] | Loss: 0.4017 | Accuracy: 0.9007\n","Epoch [2/2] | Step [19732/22538] | Loss: 0.2789 | Accuracy: 0.9201\n","Epoch [2/2] | Step [19733/22538] | Loss: 0.2296 | Accuracy: 0.9186\n","Epoch [2/2] | Step [19734/22538] | Loss: 0.1906 | Accuracy: 0.9440\n","Epoch [2/2] | Step [19735/22538] | Loss: 0.1741 | Accuracy: 0.9471\n","Epoch [2/2] | Step [19736/22538] | Loss: 0.5587 | Accuracy: 0.8722\n","Epoch [2/2] | Step [19737/22538] | Loss: 0.4116 | Accuracy: 0.9036\n","Epoch [2/2] | Step [19738/22538] | Loss: 0.2388 | Accuracy: 0.9261\n","Epoch [2/2] | Step [19739/22538] | Loss: 0.3673 | Accuracy: 0.8977\n","Epoch [2/2] | Step [19740/22538] | Loss: 0.3643 | Accuracy: 0.9049\n","Epoch [2/2] | Step [19741/22538] | Loss: 0.3300 | Accuracy: 0.9049\n","Epoch [2/2] | Step [19742/22538] | Loss: 0.3048 | Accuracy: 0.9235\n","Epoch [2/2] | Step [19743/22538] | Loss: 0.2753 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19744/22538] | Loss: 0.3378 | Accuracy: 0.9073\n","Epoch [2/2] | Step [19745/22538] | Loss: 0.2833 | Accuracy: 0.9195\n","Epoch [2/2] | Step [19746/22538] | Loss: 0.4601 | Accuracy: 0.8789\n","Epoch [2/2] | Step [19747/22538] | Loss: 0.2985 | Accuracy: 0.9118\n","Epoch [2/2] | Step [19748/22538] | Loss: 0.2828 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19749/22538] | Loss: 0.3053 | Accuracy: 0.9049\n","Epoch [2/2] | Step [19750/22538] | Loss: 0.6158 | Accuracy: 0.8494\n","Epoch [2/2] | Step [19751/22538] | Loss: 0.2216 | Accuracy: 0.9411\n","Epoch [2/2] | Step [19752/22538] | Loss: 0.2804 | Accuracy: 0.9348\n","Epoch [2/2] | Step [19753/22538] | Loss: 0.2150 | Accuracy: 0.9390\n","Epoch [2/2] | Step [19754/22538] | Loss: 0.2107 | Accuracy: 0.9306\n","Epoch [2/2] | Step [19755/22538] | Loss: 0.4295 | Accuracy: 0.8929\n","Epoch [2/2] | Step [19756/22538] | Loss: 0.3050 | Accuracy: 0.9196\n","Epoch [2/2] | Step [19757/22538] | Loss: 0.2730 | Accuracy: 0.9200\n","Epoch [2/2] | Step [19758/22538] | Loss: 0.3281 | Accuracy: 0.9118\n","Epoch [2/2] | Step [19759/22538] | Loss: 0.3727 | Accuracy: 0.9111\n","Epoch [2/2] | Step [19760/22538] | Loss: 0.4195 | Accuracy: 0.8885\n","Epoch [2/2] | Step [19761/22538] | Loss: 0.3485 | Accuracy: 0.9155\n","Epoch [2/2] | Step [19762/22538] | Loss: 0.3319 | Accuracy: 0.9175\n","Epoch [2/2] | Step [19763/22538] | Loss: 0.3431 | Accuracy: 0.9266\n","Epoch [2/2] | Step [19764/22538] | Loss: 0.3425 | Accuracy: 0.9158\n","Epoch [2/2] | Step [19765/22538] | Loss: 0.4585 | Accuracy: 0.8682\n","Epoch [2/2] | Step [19766/22538] | Loss: 0.3572 | Accuracy: 0.8946\n","Epoch [2/2] | Step [19767/22538] | Loss: 0.2240 | Accuracy: 0.9265\n","Epoch [2/2] | Step [19768/22538] | Loss: 0.3091 | Accuracy: 0.9112\n","Epoch [2/2] | Step [19769/22538] | Loss: 0.2875 | Accuracy: 0.9172\n","Epoch [2/2] | Step [19770/22538] | Loss: 0.4369 | Accuracy: 0.8900\n","Epoch [2/2] | Step [19771/22538] | Loss: 0.2178 | Accuracy: 0.9351\n","Epoch [2/2] | Step [19772/22538] | Loss: 0.3962 | Accuracy: 0.8942\n","Epoch [2/2] | Step [19773/22538] | Loss: 0.3937 | Accuracy: 0.8919\n","Epoch [2/2] | Step [19774/22538] | Loss: 0.3180 | Accuracy: 0.9068\n","Epoch [2/2] | Step [19775/22538] | Loss: 0.2981 | Accuracy: 0.9023\n","Epoch [2/2] | Step [19776/22538] | Loss: 0.2634 | Accuracy: 0.9246\n","Epoch [2/2] | Step [19777/22538] | Loss: 0.3257 | Accuracy: 0.9038\n","Epoch [2/2] | Step [19778/22538] | Loss: 0.2803 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19779/22538] | Loss: 0.2779 | Accuracy: 0.9201\n","Epoch [2/2] | Step [19780/22538] | Loss: 0.2880 | Accuracy: 0.9289\n","Epoch [2/2] | Step [19781/22538] | Loss: 0.2287 | Accuracy: 0.9335\n","Epoch [2/2] | Step [19782/22538] | Loss: 0.3118 | Accuracy: 0.9139\n","Epoch [2/2] | Step [19783/22538] | Loss: 0.4325 | Accuracy: 0.8827\n","Epoch [2/2] | Step [19784/22538] | Loss: 0.4247 | Accuracy: 0.8790\n","Epoch [2/2] | Step [19785/22538] | Loss: 0.2008 | Accuracy: 0.9508\n","Epoch [2/2] | Step [19786/22538] | Loss: 0.2641 | Accuracy: 0.9173\n","Epoch [2/2] | Step [19787/22538] | Loss: 0.2798 | Accuracy: 0.9337\n","Epoch [2/2] | Step [19788/22538] | Loss: 0.4290 | Accuracy: 0.8591\n","Epoch [2/2] | Step [19789/22538] | Loss: 0.3293 | Accuracy: 0.9111\n","Epoch [2/2] | Step [19790/22538] | Loss: 0.3370 | Accuracy: 0.9240\n","Epoch [2/2] | Step [19791/22538] | Loss: 0.2769 | Accuracy: 0.9245\n","Epoch [2/2] | Step [19792/22538] | Loss: 0.2414 | Accuracy: 0.9313\n","Epoch [2/2] | Step [19793/22538] | Loss: 0.3921 | Accuracy: 0.9063\n","Epoch [2/2] | Step [19794/22538] | Loss: 0.3898 | Accuracy: 0.8940\n","Epoch [2/2] | Step [19795/22538] | Loss: 0.1967 | Accuracy: 0.9452\n","Epoch [2/2] | Step [19796/22538] | Loss: 0.1925 | Accuracy: 0.9531\n","Epoch [2/2] | Step [19797/22538] | Loss: 0.2316 | Accuracy: 0.9410\n","Epoch [2/2] | Step [19798/22538] | Loss: 0.3879 | Accuracy: 0.9020\n","Epoch [2/2] | Step [19799/22538] | Loss: 0.3487 | Accuracy: 0.9096\n","Epoch [2/2] | Step [19800/22538] | Loss: 0.3200 | Accuracy: 0.9180\n","Epoch [2/2] | Step [19801/22538] | Loss: 0.2747 | Accuracy: 0.9159\n","Epoch [2/2] | Step [19802/22538] | Loss: 0.3618 | Accuracy: 0.9006\n","Epoch [2/2] | Step [19803/22538] | Loss: 0.2782 | Accuracy: 0.9063\n","Epoch [2/2] | Step [19804/22538] | Loss: 0.4432 | Accuracy: 0.8852\n","Epoch [2/2] | Step [19805/22538] | Loss: 0.3230 | Accuracy: 0.9023\n","Epoch [2/2] | Step [19806/22538] | Loss: 0.2878 | Accuracy: 0.9179\n","Epoch [2/2] | Step [19807/22538] | Loss: 0.3087 | Accuracy: 0.9028\n","Epoch [2/2] | Step [19808/22538] | Loss: 0.2576 | Accuracy: 0.9353\n","Epoch [2/2] | Step [19809/22538] | Loss: 0.4088 | Accuracy: 0.9110\n","Epoch [2/2] | Step [19810/22538] | Loss: 0.3123 | Accuracy: 0.9182\n","Epoch [2/2] | Step [19811/22538] | Loss: 0.2146 | Accuracy: 0.9365\n","Epoch [2/2] | Step [19812/22538] | Loss: 0.3168 | Accuracy: 0.9190\n","Epoch [2/2] | Step [19813/22538] | Loss: 0.4580 | Accuracy: 0.8608\n","Epoch [2/2] | Step [19814/22538] | Loss: 0.2729 | Accuracy: 0.9193\n","Epoch [2/2] | Step [19815/22538] | Loss: 0.3340 | Accuracy: 0.8996\n","Epoch [2/2] | Step [19816/22538] | Loss: 0.3110 | Accuracy: 0.9013\n","Epoch [2/2] | Step [19817/22538] | Loss: 0.4439 | Accuracy: 0.9031\n","Epoch [2/2] | Step [19818/22538] | Loss: 0.2330 | Accuracy: 0.9462\n","Epoch [2/2] | Step [19819/22538] | Loss: 0.3224 | Accuracy: 0.9085\n","Epoch [2/2] | Step [19820/22538] | Loss: 0.2875 | Accuracy: 0.9085\n","Epoch [2/2] | Step [19821/22538] | Loss: 0.3799 | Accuracy: 0.8914\n","Epoch [2/2] | Step [19822/22538] | Loss: 0.2320 | Accuracy: 0.9303\n","Epoch [2/2] | Step [19823/22538] | Loss: 0.3336 | Accuracy: 0.8929\n","Epoch [2/2] | Step [19824/22538] | Loss: 0.3454 | Accuracy: 0.9102\n","Epoch [2/2] | Step [19825/22538] | Loss: 0.4026 | Accuracy: 0.9083\n","Epoch [2/2] | Step [19826/22538] | Loss: 0.3013 | Accuracy: 0.9279\n","Epoch [2/2] | Step [19827/22538] | Loss: 0.3143 | Accuracy: 0.9222\n","Epoch [2/2] | Step [19828/22538] | Loss: 0.4816 | Accuracy: 0.8835\n","Epoch [2/2] | Step [19829/22538] | Loss: 0.3170 | Accuracy: 0.9213\n","Epoch [2/2] | Step [19830/22538] | Loss: 0.3814 | Accuracy: 0.9005\n","Epoch [2/2] | Step [19831/22538] | Loss: 0.2914 | Accuracy: 0.9082\n","Epoch [2/2] | Step [19832/22538] | Loss: 0.2911 | Accuracy: 0.9314\n","Epoch [2/2] | Step [19833/22538] | Loss: 0.2290 | Accuracy: 0.9310\n","Epoch [2/2] | Step [19834/22538] | Loss: 0.2802 | Accuracy: 0.9089\n","Epoch [2/2] | Step [19835/22538] | Loss: 0.2607 | Accuracy: 0.9259\n","Epoch [2/2] | Step [19836/22538] | Loss: 0.2575 | Accuracy: 0.9275\n","Epoch [2/2] | Step [19837/22538] | Loss: 0.2272 | Accuracy: 0.9294\n","Epoch [2/2] | Step [19838/22538] | Loss: 0.5098 | Accuracy: 0.8790\n","Epoch [2/2] | Step [19839/22538] | Loss: 0.3385 | Accuracy: 0.9175\n","Epoch [2/2] | Step [19840/22538] | Loss: 0.3667 | Accuracy: 0.8856\n","Epoch [2/2] | Step [19841/22538] | Loss: 0.3322 | Accuracy: 0.9216\n","Epoch [2/2] | Step [19842/22538] | Loss: 0.2751 | Accuracy: 0.9104\n","Epoch [2/2] | Step [19843/22538] | Loss: 0.4382 | Accuracy: 0.8913\n","Epoch [2/2] | Step [19844/22538] | Loss: 0.3675 | Accuracy: 0.8925\n","Epoch [2/2] | Step [19845/22538] | Loss: 0.2642 | Accuracy: 0.9237\n","Epoch [2/2] | Step [19846/22538] | Loss: 0.3722 | Accuracy: 0.9181\n","Epoch [2/2] | Step [19847/22538] | Loss: 0.2903 | Accuracy: 0.9118\n","Epoch [2/2] | Step [19848/22538] | Loss: 0.2979 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19849/22538] | Loss: 0.3856 | Accuracy: 0.8937\n","Epoch [2/2] | Step [19850/22538] | Loss: 0.2349 | Accuracy: 0.9352\n","Epoch [2/2] | Step [19851/22538] | Loss: 0.3489 | Accuracy: 0.9004\n","Epoch [2/2] | Step [19852/22538] | Loss: 0.4018 | Accuracy: 0.8894\n","Epoch [2/2] | Step [19853/22538] | Loss: 0.4854 | Accuracy: 0.8872\n","Epoch [2/2] | Step [19854/22538] | Loss: 0.2845 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19855/22538] | Loss: 0.3291 | Accuracy: 0.9211\n","Epoch [2/2] | Step [19856/22538] | Loss: 0.3221 | Accuracy: 0.9127\n","Epoch [2/2] | Step [19857/22538] | Loss: 0.2831 | Accuracy: 0.9110\n","Epoch [2/2] | Step [19858/22538] | Loss: 0.3706 | Accuracy: 0.9005\n","Epoch [2/2] | Step [19859/22538] | Loss: 0.4275 | Accuracy: 0.8721\n","Epoch [2/2] | Step [19860/22538] | Loss: 0.3074 | Accuracy: 0.9125\n","Epoch [2/2] | Step [19861/22538] | Loss: 0.2603 | Accuracy: 0.9327\n","Epoch [2/2] | Step [19862/22538] | Loss: 0.2857 | Accuracy: 0.9114\n","Epoch [2/2] | Step [19863/22538] | Loss: 0.3209 | Accuracy: 0.9014\n","Epoch [2/2] | Step [19864/22538] | Loss: 0.2647 | Accuracy: 0.9280\n","Epoch [2/2] | Step [19865/22538] | Loss: 0.3202 | Accuracy: 0.9005\n","Epoch [2/2] | Step [19866/22538] | Loss: 0.2098 | Accuracy: 0.9446\n","Epoch [2/2] | Step [19867/22538] | Loss: 0.3807 | Accuracy: 0.8892\n","Epoch [2/2] | Step [19868/22538] | Loss: 0.2273 | Accuracy: 0.9359\n","Epoch [2/2] | Step [19869/22538] | Loss: 0.3141 | Accuracy: 0.9160\n","Epoch [2/2] | Step [19870/22538] | Loss: 0.3308 | Accuracy: 0.8977\n","Epoch [2/2] | Step [19871/22538] | Loss: 0.2693 | Accuracy: 0.9184\n","Epoch [2/2] | Step [19872/22538] | Loss: 0.2082 | Accuracy: 0.9438\n","Epoch [2/2] | Step [19873/22538] | Loss: 0.2603 | Accuracy: 0.9239\n","Epoch [2/2] | Step [19874/22538] | Loss: 0.2881 | Accuracy: 0.9241\n","Epoch [2/2] | Step [19875/22538] | Loss: 0.3564 | Accuracy: 0.9047\n","Epoch [2/2] | Step [19876/22538] | Loss: 0.1895 | Accuracy: 0.9496\n","Epoch [2/2] | Step [19877/22538] | Loss: 0.3411 | Accuracy: 0.9122\n","Epoch [2/2] | Step [19878/22538] | Loss: 0.2850 | Accuracy: 0.9159\n","Epoch [2/2] | Step [19879/22538] | Loss: 0.3760 | Accuracy: 0.8864\n","Epoch [2/2] | Step [19880/22538] | Loss: 0.3472 | Accuracy: 0.9038\n","Epoch [2/2] | Step [19881/22538] | Loss: 0.2340 | Accuracy: 0.9412\n","Epoch [2/2] | Step [19882/22538] | Loss: 0.3265 | Accuracy: 0.9071\n","Epoch [2/2] | Step [19883/22538] | Loss: 0.4700 | Accuracy: 0.8837\n","Epoch [2/2] | Step [19884/22538] | Loss: 0.2877 | Accuracy: 0.9178\n","Epoch [2/2] | Step [19885/22538] | Loss: 0.6323 | Accuracy: 0.8466\n","Epoch [2/2] | Step [19886/22538] | Loss: 0.2637 | Accuracy: 0.9139\n","Epoch [2/2] | Step [19887/22538] | Loss: 0.1558 | Accuracy: 0.9490\n","Epoch [2/2] | Step [19888/22538] | Loss: 0.3639 | Accuracy: 0.9042\n","Epoch [2/2] | Step [19889/22538] | Loss: 0.2149 | Accuracy: 0.9303\n","Epoch [2/2] | Step [19890/22538] | Loss: 0.3552 | Accuracy: 0.8938\n","Epoch [2/2] | Step [19891/22538] | Loss: 0.2650 | Accuracy: 0.9267\n","Epoch [2/2] | Step [19892/22538] | Loss: 0.2210 | Accuracy: 0.9301\n","Epoch [2/2] | Step [19893/22538] | Loss: 0.2994 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19894/22538] | Loss: 0.2571 | Accuracy: 0.9254\n","Epoch [2/2] | Step [19895/22538] | Loss: 0.2684 | Accuracy: 0.9167\n","Epoch [2/2] | Step [19896/22538] | Loss: 0.2753 | Accuracy: 0.9263\n","Epoch [2/2] | Step [19897/22538] | Loss: 0.2508 | Accuracy: 0.9296\n","Epoch [2/2] | Step [19898/22538] | Loss: 0.2758 | Accuracy: 0.9306\n","Epoch [2/2] | Step [19899/22538] | Loss: 0.2878 | Accuracy: 0.9205\n","Epoch [2/2] | Step [19900/22538] | Loss: 0.3267 | Accuracy: 0.9107\n","Epoch [2/2] | Step [19901/22538] | Loss: 0.2337 | Accuracy: 0.9433\n","Epoch [2/2] | Step [19902/22538] | Loss: 0.4566 | Accuracy: 0.8924\n","Epoch [2/2] | Step [19903/22538] | Loss: 0.3618 | Accuracy: 0.8981\n","Epoch [2/2] | Step [19904/22538] | Loss: 0.3724 | Accuracy: 0.9040\n","Epoch [2/2] | Step [19905/22538] | Loss: 0.2784 | Accuracy: 0.9229\n","Epoch [2/2] | Step [19906/22538] | Loss: 0.2792 | Accuracy: 0.9131\n","Epoch [2/2] | Step [19907/22538] | Loss: 0.4950 | Accuracy: 0.8578\n","Epoch [2/2] | Step [19908/22538] | Loss: 0.3473 | Accuracy: 0.8981\n","Epoch [2/2] | Step [19909/22538] | Loss: 0.3671 | Accuracy: 0.9042\n","Epoch [2/2] | Step [19910/22538] | Loss: 0.3464 | Accuracy: 0.9036\n","Epoch [2/2] | Step [19911/22538] | Loss: 0.2111 | Accuracy: 0.9323\n","Epoch [2/2] | Step [19912/22538] | Loss: 0.3278 | Accuracy: 0.9093\n","Epoch [2/2] | Step [19913/22538] | Loss: 0.2231 | Accuracy: 0.9338\n","Epoch [2/2] | Step [19914/22538] | Loss: 0.3651 | Accuracy: 0.8833\n","Epoch [2/2] | Step [19915/22538] | Loss: 0.2997 | Accuracy: 0.9212\n","Epoch [2/2] | Step [19916/22538] | Loss: 0.2655 | Accuracy: 0.9263\n","Epoch [2/2] | Step [19917/22538] | Loss: 0.3428 | Accuracy: 0.8941\n","Epoch [2/2] | Step [19918/22538] | Loss: 0.3178 | Accuracy: 0.9147\n","Epoch [2/2] | Step [19919/22538] | Loss: 0.3538 | Accuracy: 0.8954\n","Epoch [2/2] | Step [19920/22538] | Loss: 0.2590 | Accuracy: 0.9231\n","Epoch [2/2] | Step [19921/22538] | Loss: 0.3484 | Accuracy: 0.9085\n","Epoch [2/2] | Step [19922/22538] | Loss: 0.5585 | Accuracy: 0.8482\n","Epoch [2/2] | Step [19923/22538] | Loss: 0.2817 | Accuracy: 0.8984\n","Epoch [2/2] | Step [19924/22538] | Loss: 0.3725 | Accuracy: 0.9141\n","Epoch [2/2] | Step [19925/22538] | Loss: 0.2445 | Accuracy: 0.9288\n","Epoch [2/2] | Step [19926/22538] | Loss: 0.2874 | Accuracy: 0.9234\n","Epoch [2/2] | Step [19927/22538] | Loss: 0.4011 | Accuracy: 0.9025\n","Epoch [2/2] | Step [19928/22538] | Loss: 0.3387 | Accuracy: 0.9173\n","Epoch [2/2] | Step [19929/22538] | Loss: 0.2388 | Accuracy: 0.9306\n","Epoch [2/2] | Step [19930/22538] | Loss: 0.3400 | Accuracy: 0.8971\n","Epoch [2/2] | Step [19931/22538] | Loss: 0.2935 | Accuracy: 0.9219\n","Epoch [2/2] | Step [19932/22538] | Loss: 0.3430 | Accuracy: 0.9101\n","Epoch [2/2] | Step [19933/22538] | Loss: 0.4289 | Accuracy: 0.8819\n","Epoch [2/2] | Step [19934/22538] | Loss: 0.2569 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19935/22538] | Loss: 0.3216 | Accuracy: 0.9250\n","Epoch [2/2] | Step [19936/22538] | Loss: 0.4408 | Accuracy: 0.8831\n","Epoch [2/2] | Step [19937/22538] | Loss: 0.4762 | Accuracy: 0.8795\n","Epoch [2/2] | Step [19938/22538] | Loss: 0.2413 | Accuracy: 0.9283\n","Epoch [2/2] | Step [19939/22538] | Loss: 0.2009 | Accuracy: 0.9492\n","Epoch [2/2] | Step [19940/22538] | Loss: 0.3004 | Accuracy: 0.9083\n","Epoch [2/2] | Step [19941/22538] | Loss: 0.2220 | Accuracy: 0.9299\n","Epoch [2/2] | Step [19942/22538] | Loss: 0.3186 | Accuracy: 0.9107\n","Epoch [2/2] | Step [19943/22538] | Loss: 0.2839 | Accuracy: 0.9286\n","Epoch [2/2] | Step [19944/22538] | Loss: 0.2387 | Accuracy: 0.9281\n","Epoch [2/2] | Step [19945/22538] | Loss: 0.3190 | Accuracy: 0.9268\n","Epoch [2/2] | Step [19946/22538] | Loss: 0.3126 | Accuracy: 0.9113\n","Epoch [2/2] | Step [19947/22538] | Loss: 0.3441 | Accuracy: 0.9121\n","Epoch [2/2] | Step [19948/22538] | Loss: 0.3864 | Accuracy: 0.8950\n","Epoch [2/2] | Step [19949/22538] | Loss: 0.3863 | Accuracy: 0.8988\n","Epoch [2/2] | Step [19950/22538] | Loss: 0.3526 | Accuracy: 0.8892\n","Epoch [2/2] | Step [19951/22538] | Loss: 0.3183 | Accuracy: 0.8969\n","Epoch [2/2] | Step [19952/22538] | Loss: 0.3252 | Accuracy: 0.9120\n","Epoch [2/2] | Step [19953/22538] | Loss: 0.2936 | Accuracy: 0.9146\n","Epoch [2/2] | Step [19954/22538] | Loss: 0.2890 | Accuracy: 0.9222\n","Epoch [2/2] | Step [19955/22538] | Loss: 0.4293 | Accuracy: 0.8728\n","Epoch [2/2] | Step [19956/22538] | Loss: 0.2712 | Accuracy: 0.9310\n","Epoch [2/2] | Step [19957/22538] | Loss: 0.3429 | Accuracy: 0.9087\n","Epoch [2/2] | Step [19958/22538] | Loss: 0.2253 | Accuracy: 0.9318\n","Epoch [2/2] | Step [19959/22538] | Loss: 0.2821 | Accuracy: 0.9203\n","Epoch [2/2] | Step [19960/22538] | Loss: 0.4222 | Accuracy: 0.9114\n","Epoch [2/2] | Step [19961/22538] | Loss: 0.2367 | Accuracy: 0.9424\n","Epoch [2/2] | Step [19962/22538] | Loss: 0.3603 | Accuracy: 0.9062\n","Epoch [2/2] | Step [19963/22538] | Loss: 0.3612 | Accuracy: 0.8922\n","Epoch [2/2] | Step [19964/22538] | Loss: 0.2265 | Accuracy: 0.9408\n","Epoch [2/2] | Step [19965/22538] | Loss: 0.2314 | Accuracy: 0.9464\n","Epoch [2/2] | Step [19966/22538] | Loss: 0.4094 | Accuracy: 0.9012\n","Epoch [2/2] | Step [19967/22538] | Loss: 0.2754 | Accuracy: 0.9226\n","Epoch [2/2] | Step [19968/22538] | Loss: 0.4072 | Accuracy: 0.8942\n","Epoch [2/2] | Step [19969/22538] | Loss: 0.5816 | Accuracy: 0.8704\n","Epoch [2/2] | Step [19970/22538] | Loss: 0.2845 | Accuracy: 0.9188\n","Epoch [2/2] | Step [19971/22538] | Loss: 0.3078 | Accuracy: 0.9159\n","Epoch [2/2] | Step [19972/22538] | Loss: 0.3521 | Accuracy: 0.9153\n","Epoch [2/2] | Step [19973/22538] | Loss: 0.1876 | Accuracy: 0.9462\n","Epoch [2/2] | Step [19974/22538] | Loss: 0.5111 | Accuracy: 0.8617\n","Epoch [2/2] | Step [19975/22538] | Loss: 0.3753 | Accuracy: 0.9102\n","Epoch [2/2] | Step [19976/22538] | Loss: 0.3605 | Accuracy: 0.8955\n","Epoch [2/2] | Step [19977/22538] | Loss: 0.2479 | Accuracy: 0.9303\n","Epoch [2/2] | Step [19978/22538] | Loss: 0.2746 | Accuracy: 0.9273\n","Epoch [2/2] | Step [19979/22538] | Loss: 0.3554 | Accuracy: 0.8992\n","Epoch [2/2] | Step [19980/22538] | Loss: 0.2208 | Accuracy: 0.9375\n","Epoch [2/2] | Step [19981/22538] | Loss: 0.2983 | Accuracy: 0.9174\n","Epoch [2/2] | Step [19982/22538] | Loss: 0.2672 | Accuracy: 0.9191\n","Epoch [2/2] | Step [19983/22538] | Loss: 0.2946 | Accuracy: 0.9067\n","Epoch [2/2] | Step [19984/22538] | Loss: 0.2668 | Accuracy: 0.9245\n","Epoch [2/2] | Step [19985/22538] | Loss: 0.3972 | Accuracy: 0.8958\n","Epoch [2/2] | Step [19986/22538] | Loss: 0.2606 | Accuracy: 0.9347\n","Epoch [2/2] | Step [19987/22538] | Loss: 0.2705 | Accuracy: 0.9280\n","Epoch [2/2] | Step [19988/22538] | Loss: 0.4349 | Accuracy: 0.8889\n","Epoch [2/2] | Step [19989/22538] | Loss: 0.3212 | Accuracy: 0.9010\n","Epoch [2/2] | Step [19990/22538] | Loss: 0.4974 | Accuracy: 0.8705\n","Epoch [2/2] | Step [19991/22538] | Loss: 0.3039 | Accuracy: 0.9153\n","Epoch [2/2] | Step [19992/22538] | Loss: 0.2386 | Accuracy: 0.9257\n","Epoch [2/2] | Step [19993/22538] | Loss: 0.2939 | Accuracy: 0.9125\n","Epoch [2/2] | Step [19994/22538] | Loss: 0.2767 | Accuracy: 0.9298\n","Epoch [2/2] | Step [19995/22538] | Loss: 0.5441 | Accuracy: 0.8673\n","Epoch [2/2] | Step [19996/22538] | Loss: 0.3666 | Accuracy: 0.9036\n","Epoch [2/2] | Step [19997/22538] | Loss: 0.3820 | Accuracy: 0.8906\n","Epoch [2/2] | Step [19998/22538] | Loss: 0.3493 | Accuracy: 0.9031\n","Epoch [2/2] | Step [19999/22538] | Loss: 0.3596 | Accuracy: 0.9181\n","Epoch [2/2] | Step [20000/22538] | Loss: 0.2804 | Accuracy: 0.9352\n","Epoch [2/2] | Step [20001/22538] | Loss: 0.3575 | Accuracy: 0.8778\n","Epoch [2/2] | Step [20002/22538] | Loss: 0.4021 | Accuracy: 0.8914\n","Epoch [2/2] | Step [20003/22538] | Loss: 0.4487 | Accuracy: 0.8625\n","Epoch [2/2] | Step [20004/22538] | Loss: 0.3291 | Accuracy: 0.9144\n","Epoch [2/2] | Step [20005/22538] | Loss: 0.3383 | Accuracy: 0.9161\n","Epoch [2/2] | Step [20006/22538] | Loss: 0.2692 | Accuracy: 0.9236\n","Epoch [2/2] | Step [20007/22538] | Loss: 0.3135 | Accuracy: 0.9105\n","Epoch [2/2] | Step [20008/22538] | Loss: 0.4984 | Accuracy: 0.8750\n","Epoch [2/2] | Step [20009/22538] | Loss: 0.2857 | Accuracy: 0.9207\n","Epoch [2/2] | Step [20010/22538] | Loss: 0.4345 | Accuracy: 0.8902\n","Epoch [2/2] | Step [20011/22538] | Loss: 0.3099 | Accuracy: 0.9066\n","Epoch [2/2] | Step [20012/22538] | Loss: 0.4743 | Accuracy: 0.8830\n","Epoch [2/2] | Step [20013/22538] | Loss: 0.4503 | Accuracy: 0.8875\n","Epoch [2/2] | Step [20014/22538] | Loss: 0.2777 | Accuracy: 0.9141\n","Epoch [2/2] | Step [20015/22538] | Loss: 0.2831 | Accuracy: 0.9237\n","Epoch [2/2] | Step [20016/22538] | Loss: 0.2597 | Accuracy: 0.9268\n","Epoch [2/2] | Step [20017/22538] | Loss: 0.3628 | Accuracy: 0.8990\n","Epoch [2/2] | Step [20018/22538] | Loss: 0.2819 | Accuracy: 0.9201\n","Epoch [2/2] | Step [20019/22538] | Loss: 0.3355 | Accuracy: 0.9074\n","Epoch [2/2] | Step [20020/22538] | Loss: 0.2876 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20021/22538] | Loss: 0.3031 | Accuracy: 0.9114\n","Epoch [2/2] | Step [20022/22538] | Loss: 0.3138 | Accuracy: 0.9089\n","Epoch [2/2] | Step [20023/22538] | Loss: 0.2420 | Accuracy: 0.9278\n","Epoch [2/2] | Step [20024/22538] | Loss: 0.3017 | Accuracy: 0.9210\n","Epoch [2/2] | Step [20025/22538] | Loss: 0.4289 | Accuracy: 0.8950\n","Epoch [2/2] | Step [20026/22538] | Loss: 0.3546 | Accuracy: 0.9028\n","Epoch [2/2] | Step [20027/22538] | Loss: 0.2468 | Accuracy: 0.9426\n","Epoch [2/2] | Step [20028/22538] | Loss: 0.2007 | Accuracy: 0.9451\n","Epoch [2/2] | Step [20029/22538] | Loss: 0.2216 | Accuracy: 0.9399\n","Epoch [2/2] | Step [20030/22538] | Loss: 0.2916 | Accuracy: 0.9231\n","Epoch [2/2] | Step [20031/22538] | Loss: 0.2500 | Accuracy: 0.9206\n","Epoch [2/2] | Step [20032/22538] | Loss: 0.3121 | Accuracy: 0.9110\n","Epoch [2/2] | Step [20033/22538] | Loss: 0.3342 | Accuracy: 0.9226\n","Epoch [2/2] | Step [20034/22538] | Loss: 0.3612 | Accuracy: 0.9069\n","Epoch [2/2] | Step [20035/22538] | Loss: 0.3826 | Accuracy: 0.9049\n","Epoch [2/2] | Step [20036/22538] | Loss: 0.3105 | Accuracy: 0.9188\n","Epoch [2/2] | Step [20037/22538] | Loss: 0.3365 | Accuracy: 0.9091\n","Epoch [2/2] | Step [20038/22538] | Loss: 0.4076 | Accuracy: 0.8988\n","Epoch [2/2] | Step [20039/22538] | Loss: 0.3192 | Accuracy: 0.9121\n","Epoch [2/2] | Step [20040/22538] | Loss: 0.3021 | Accuracy: 0.9100\n","Epoch [2/2] | Step [20041/22538] | Loss: 0.1595 | Accuracy: 0.9496\n","Epoch [2/2] | Step [20042/22538] | Loss: 0.3445 | Accuracy: 0.9297\n","Epoch [2/2] | Step [20043/22538] | Loss: 0.4636 | Accuracy: 0.8718\n","Epoch [2/2] | Step [20044/22538] | Loss: 0.2423 | Accuracy: 0.9313\n","Epoch [2/2] | Step [20045/22538] | Loss: 0.4330 | Accuracy: 0.8981\n","Epoch [2/2] | Step [20046/22538] | Loss: 0.3787 | Accuracy: 0.9056\n","Epoch [2/2] | Step [20047/22538] | Loss: 0.2566 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20048/22538] | Loss: 0.4098 | Accuracy: 0.8812\n","Epoch [2/2] | Step [20049/22538] | Loss: 0.3327 | Accuracy: 0.9010\n","Epoch [2/2] | Step [20050/22538] | Loss: 0.3908 | Accuracy: 0.8989\n","Epoch [2/2] | Step [20051/22538] | Loss: 0.2958 | Accuracy: 0.9214\n","Epoch [2/2] | Step [20052/22538] | Loss: 0.3043 | Accuracy: 0.9185\n","Epoch [2/2] | Step [20053/22538] | Loss: 0.3839 | Accuracy: 0.8996\n","Epoch [2/2] | Step [20054/22538] | Loss: 0.2474 | Accuracy: 0.9283\n","Epoch [2/2] | Step [20055/22538] | Loss: 0.2731 | Accuracy: 0.9158\n","Epoch [2/2] | Step [20056/22538] | Loss: 0.3411 | Accuracy: 0.8980\n","Epoch [2/2] | Step [20057/22538] | Loss: 0.2606 | Accuracy: 0.9196\n","Epoch [2/2] | Step [20058/22538] | Loss: 0.3022 | Accuracy: 0.9151\n","Epoch [2/2] | Step [20059/22538] | Loss: 0.3523 | Accuracy: 0.8902\n","Epoch [2/2] | Step [20060/22538] | Loss: 0.2766 | Accuracy: 0.9231\n","Epoch [2/2] | Step [20061/22538] | Loss: 0.3829 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20062/22538] | Loss: 0.1668 | Accuracy: 0.9497\n","Epoch [2/2] | Step [20063/22538] | Loss: 0.2047 | Accuracy: 0.9451\n","Epoch [2/2] | Step [20064/22538] | Loss: 0.4038 | Accuracy: 0.8965\n","Epoch [2/2] | Step [20065/22538] | Loss: 0.2195 | Accuracy: 0.9407\n","Epoch [2/2] | Step [20066/22538] | Loss: 0.5357 | Accuracy: 0.8516\n","Epoch [2/2] | Step [20067/22538] | Loss: 0.2596 | Accuracy: 0.9194\n","Epoch [2/2] | Step [20068/22538] | Loss: 0.2674 | Accuracy: 0.9257\n","Epoch [2/2] | Step [20069/22538] | Loss: 0.3512 | Accuracy: 0.9099\n","Epoch [2/2] | Step [20070/22538] | Loss: 0.3330 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20071/22538] | Loss: 0.2923 | Accuracy: 0.9182\n","Epoch [2/2] | Step [20072/22538] | Loss: 0.3901 | Accuracy: 0.8889\n","Epoch [2/2] | Step [20073/22538] | Loss: 0.2645 | Accuracy: 0.9151\n","Epoch [2/2] | Step [20074/22538] | Loss: 0.4193 | Accuracy: 0.8841\n","Epoch [2/2] | Step [20075/22538] | Loss: 0.3334 | Accuracy: 0.9212\n","Epoch [2/2] | Step [20076/22538] | Loss: 0.3352 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20077/22538] | Loss: 0.3380 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20078/22538] | Loss: 0.3241 | Accuracy: 0.9147\n","Epoch [2/2] | Step [20079/22538] | Loss: 0.1883 | Accuracy: 0.9496\n","Epoch [2/2] | Step [20080/22538] | Loss: 0.2470 | Accuracy: 0.9392\n","Epoch [2/2] | Step [20081/22538] | Loss: 0.2536 | Accuracy: 0.9355\n","Epoch [2/2] | Step [20082/22538] | Loss: 0.2863 | Accuracy: 0.9040\n","Epoch [2/2] | Step [20083/22538] | Loss: 0.2493 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20084/22538] | Loss: 0.5121 | Accuracy: 0.8821\n","Epoch [2/2] | Step [20085/22538] | Loss: 0.5027 | Accuracy: 0.8726\n","Epoch [2/2] | Step [20086/22538] | Loss: 0.2818 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20087/22538] | Loss: 0.3092 | Accuracy: 0.9091\n","Epoch [2/2] | Step [20088/22538] | Loss: 0.2974 | Accuracy: 0.8996\n","Epoch [2/2] | Step [20089/22538] | Loss: 0.1480 | Accuracy: 0.9639\n","Epoch [2/2] | Step [20090/22538] | Loss: 0.2466 | Accuracy: 0.9265\n","Epoch [2/2] | Step [20091/22538] | Loss: 0.2788 | Accuracy: 0.9195\n","Epoch [2/2] | Step [20092/22538] | Loss: 0.3059 | Accuracy: 0.9091\n","Epoch [2/2] | Step [20093/22538] | Loss: 0.2892 | Accuracy: 0.9173\n","Epoch [2/2] | Step [20094/22538] | Loss: 0.5535 | Accuracy: 0.8776\n","Epoch [2/2] | Step [20095/22538] | Loss: 0.3900 | Accuracy: 0.8929\n","Epoch [2/2] | Step [20096/22538] | Loss: 0.2881 | Accuracy: 0.9205\n","Epoch [2/2] | Step [20097/22538] | Loss: 0.3984 | Accuracy: 0.8750\n","Epoch [2/2] | Step [20098/22538] | Loss: 0.2044 | Accuracy: 0.9279\n","Epoch [2/2] | Step [20099/22538] | Loss: 0.1939 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20100/22538] | Loss: 0.4063 | Accuracy: 0.9009\n","Epoch [2/2] | Step [20101/22538] | Loss: 0.4567 | Accuracy: 0.8750\n","Epoch [2/2] | Step [20102/22538] | Loss: 0.1956 | Accuracy: 0.9320\n","Epoch [2/2] | Step [20103/22538] | Loss: 0.2746 | Accuracy: 0.9274\n","Epoch [2/2] | Step [20104/22538] | Loss: 0.2888 | Accuracy: 0.9184\n","Epoch [2/2] | Step [20105/22538] | Loss: 0.2724 | Accuracy: 0.9304\n","Epoch [2/2] | Step [20106/22538] | Loss: 0.2441 | Accuracy: 0.9226\n","Epoch [2/2] | Step [20107/22538] | Loss: 0.3260 | Accuracy: 0.8987\n","Epoch [2/2] | Step [20108/22538] | Loss: 0.4072 | Accuracy: 0.8871\n","Epoch [2/2] | Step [20109/22538] | Loss: 0.3136 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20110/22538] | Loss: 0.4131 | Accuracy: 0.8910\n","Epoch [2/2] | Step [20111/22538] | Loss: 0.3222 | Accuracy: 0.9082\n","Epoch [2/2] | Step [20112/22538] | Loss: 0.3674 | Accuracy: 0.8947\n","Epoch [2/2] | Step [20113/22538] | Loss: 0.3222 | Accuracy: 0.9142\n","Epoch [2/2] | Step [20114/22538] | Loss: 0.3389 | Accuracy: 0.9085\n","Epoch [2/2] | Step [20115/22538] | Loss: 0.3336 | Accuracy: 0.9183\n","Epoch [2/2] | Step [20116/22538] | Loss: 0.2830 | Accuracy: 0.9148\n","Epoch [2/2] | Step [20117/22538] | Loss: 0.2658 | Accuracy: 0.9293\n","Epoch [2/2] | Step [20118/22538] | Loss: 0.2541 | Accuracy: 0.9299\n","Epoch [2/2] | Step [20119/22538] | Loss: 0.3955 | Accuracy: 0.9051\n","Epoch [2/2] | Step [20120/22538] | Loss: 0.3000 | Accuracy: 0.9125\n","Epoch [2/2] | Step [20121/22538] | Loss: 0.2382 | Accuracy: 0.9329\n","Epoch [2/2] | Step [20122/22538] | Loss: 0.4099 | Accuracy: 0.8825\n","Epoch [2/2] | Step [20123/22538] | Loss: 0.1663 | Accuracy: 0.9487\n","Epoch [2/2] | Step [20124/22538] | Loss: 0.3557 | Accuracy: 0.8933\n","Epoch [2/2] | Step [20125/22538] | Loss: 0.3885 | Accuracy: 0.8929\n","Epoch [2/2] | Step [20126/22538] | Loss: 0.2523 | Accuracy: 0.9279\n","Epoch [2/2] | Step [20127/22538] | Loss: 0.2122 | Accuracy: 0.9511\n","Epoch [2/2] | Step [20128/22538] | Loss: 0.2306 | Accuracy: 0.9263\n","Epoch [2/2] | Step [20129/22538] | Loss: 0.2595 | Accuracy: 0.9193\n","Epoch [2/2] | Step [20130/22538] | Loss: 0.3661 | Accuracy: 0.8958\n","Epoch [2/2] | Step [20131/22538] | Loss: 0.3098 | Accuracy: 0.9144\n","Epoch [2/2] | Step [20132/22538] | Loss: 0.2966 | Accuracy: 0.9078\n","Epoch [2/2] | Step [20133/22538] | Loss: 0.3860 | Accuracy: 0.9025\n","Epoch [2/2] | Step [20134/22538] | Loss: 0.2602 | Accuracy: 0.9277\n","Epoch [2/2] | Step [20135/22538] | Loss: 0.2214 | Accuracy: 0.9293\n","Epoch [2/2] | Step [20136/22538] | Loss: 0.3323 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20137/22538] | Loss: 0.4123 | Accuracy: 0.8913\n","Epoch [2/2] | Step [20138/22538] | Loss: 0.2785 | Accuracy: 0.9119\n","Epoch [2/2] | Step [20139/22538] | Loss: 0.4466 | Accuracy: 0.8906\n","Epoch [2/2] | Step [20140/22538] | Loss: 0.4319 | Accuracy: 0.8819\n","Epoch [2/2] | Step [20141/22538] | Loss: 0.2392 | Accuracy: 0.9272\n","Epoch [2/2] | Step [20142/22538] | Loss: 0.3728 | Accuracy: 0.9118\n","Epoch [2/2] | Step [20143/22538] | Loss: 0.4635 | Accuracy: 0.8944\n","Epoch [2/2] | Step [20144/22538] | Loss: 0.3484 | Accuracy: 0.9104\n","Epoch [2/2] | Step [20145/22538] | Loss: 0.2962 | Accuracy: 0.9208\n","Epoch [2/2] | Step [20146/22538] | Loss: 0.2917 | Accuracy: 0.9365\n","Epoch [2/2] | Step [20147/22538] | Loss: 0.3677 | Accuracy: 0.8866\n","Epoch [2/2] | Step [20148/22538] | Loss: 0.2763 | Accuracy: 0.9174\n","Epoch [2/2] | Step [20149/22538] | Loss: 0.2815 | Accuracy: 0.9179\n","Epoch [2/2] | Step [20150/22538] | Loss: 0.3655 | Accuracy: 0.8892\n","Epoch [2/2] | Step [20151/22538] | Loss: 0.2380 | Accuracy: 0.9254\n","Epoch [2/2] | Step [20152/22538] | Loss: 0.3572 | Accuracy: 0.8902\n","Epoch [2/2] | Step [20153/22538] | Loss: 0.5597 | Accuracy: 0.8523\n","Epoch [2/2] | Step [20154/22538] | Loss: 0.3403 | Accuracy: 0.9102\n","Epoch [2/2] | Step [20155/22538] | Loss: 0.3913 | Accuracy: 0.8981\n","Epoch [2/2] | Step [20156/22538] | Loss: 0.2814 | Accuracy: 0.9207\n","Epoch [2/2] | Step [20157/22538] | Loss: 0.2929 | Accuracy: 0.9035\n","Epoch [2/2] | Step [20158/22538] | Loss: 0.4203 | Accuracy: 0.8898\n","Epoch [2/2] | Step [20159/22538] | Loss: 0.4227 | Accuracy: 0.8871\n","Epoch [2/2] | Step [20160/22538] | Loss: 0.3068 | Accuracy: 0.8984\n","Epoch [2/2] | Step [20161/22538] | Loss: 0.2826 | Accuracy: 0.9235\n","Epoch [2/2] | Step [20162/22538] | Loss: 0.2754 | Accuracy: 0.9180\n","Epoch [2/2] | Step [20163/22538] | Loss: 0.4170 | Accuracy: 0.8848\n","Epoch [2/2] | Step [20164/22538] | Loss: 0.3837 | Accuracy: 0.8886\n","Epoch [2/2] | Step [20165/22538] | Loss: 0.2316 | Accuracy: 0.9283\n","Epoch [2/2] | Step [20166/22538] | Loss: 0.2494 | Accuracy: 0.9296\n","Epoch [2/2] | Step [20167/22538] | Loss: 0.2740 | Accuracy: 0.9308\n","Epoch [2/2] | Step [20168/22538] | Loss: 0.2826 | Accuracy: 0.9254\n","Epoch [2/2] | Step [20169/22538] | Loss: 0.3081 | Accuracy: 0.9195\n","Epoch [2/2] | Step [20170/22538] | Loss: 0.2462 | Accuracy: 0.9310\n","Epoch [2/2] | Step [20171/22538] | Loss: 0.5349 | Accuracy: 0.8694\n","Epoch [2/2] | Step [20172/22538] | Loss: 0.3672 | Accuracy: 0.8844\n","Epoch [2/2] | Step [20173/22538] | Loss: 0.4302 | Accuracy: 0.8866\n","Epoch [2/2] | Step [20174/22538] | Loss: 0.4279 | Accuracy: 0.8848\n","Epoch [2/2] | Step [20175/22538] | Loss: 0.3074 | Accuracy: 0.9192\n","Epoch [2/2] | Step [20176/22538] | Loss: 0.3251 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20177/22538] | Loss: 0.2825 | Accuracy: 0.9078\n","Epoch [2/2] | Step [20178/22538] | Loss: 0.3017 | Accuracy: 0.9219\n","Epoch [2/2] | Step [20179/22538] | Loss: 0.3185 | Accuracy: 0.9096\n","Epoch [2/2] | Step [20180/22538] | Loss: 0.3761 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20181/22538] | Loss: 0.2768 | Accuracy: 0.9256\n","Epoch [2/2] | Step [20182/22538] | Loss: 0.3025 | Accuracy: 0.9138\n","Epoch [2/2] | Step [20183/22538] | Loss: 0.3719 | Accuracy: 0.9139\n","Epoch [2/2] | Step [20184/22538] | Loss: 0.3231 | Accuracy: 0.8986\n","Epoch [2/2] | Step [20185/22538] | Loss: 0.2524 | Accuracy: 0.9185\n","Epoch [2/2] | Step [20186/22538] | Loss: 0.3177 | Accuracy: 0.9156\n","Epoch [2/2] | Step [20187/22538] | Loss: 0.2567 | Accuracy: 0.9283\n","Epoch [2/2] | Step [20188/22538] | Loss: 0.2999 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20189/22538] | Loss: 0.2568 | Accuracy: 0.9340\n","Epoch [2/2] | Step [20190/22538] | Loss: 0.3815 | Accuracy: 0.8954\n","Epoch [2/2] | Step [20191/22538] | Loss: 0.4333 | Accuracy: 0.8886\n","Epoch [2/2] | Step [20192/22538] | Loss: 0.2148 | Accuracy: 0.9349\n","Epoch [2/2] | Step [20193/22538] | Loss: 0.3140 | Accuracy: 0.9239\n","Epoch [2/2] | Step [20194/22538] | Loss: 0.1946 | Accuracy: 0.9492\n","Epoch [2/2] | Step [20195/22538] | Loss: 0.3773 | Accuracy: 0.9043\n","Epoch [2/2] | Step [20196/22538] | Loss: 0.3511 | Accuracy: 0.8975\n","Epoch [2/2] | Step [20197/22538] | Loss: 0.2979 | Accuracy: 0.9269\n","Epoch [2/2] | Step [20198/22538] | Loss: 0.2683 | Accuracy: 0.9286\n","Epoch [2/2] | Step [20199/22538] | Loss: 0.3546 | Accuracy: 0.8958\n","Epoch [2/2] | Step [20200/22538] | Loss: 0.3762 | Accuracy: 0.9057\n","Epoch [2/2] | Step [20201/22538] | Loss: 0.3148 | Accuracy: 0.9196\n","Epoch [2/2] | Step [20202/22538] | Loss: 0.4175 | Accuracy: 0.8953\n","Epoch [2/2] | Step [20203/22538] | Loss: 0.3512 | Accuracy: 0.9041\n","Epoch [2/2] | Step [20204/22538] | Loss: 0.3763 | Accuracy: 0.8922\n","Epoch [2/2] | Step [20205/22538] | Loss: 0.4377 | Accuracy: 0.8979\n","Epoch [2/2] | Step [20206/22538] | Loss: 0.4516 | Accuracy: 0.8897\n","Epoch [2/2] | Step [20207/22538] | Loss: 0.4473 | Accuracy: 0.8790\n","Epoch [2/2] | Step [20208/22538] | Loss: 0.2668 | Accuracy: 0.9254\n","Epoch [2/2] | Step [20209/22538] | Loss: 0.3026 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20210/22538] | Loss: 0.2405 | Accuracy: 0.9138\n","Epoch [2/2] | Step [20211/22538] | Loss: 0.6372 | Accuracy: 0.8320\n","Epoch [2/2] | Step [20212/22538] | Loss: 0.3080 | Accuracy: 0.9099\n","Epoch [2/2] | Step [20213/22538] | Loss: 0.3765 | Accuracy: 0.8856\n","Epoch [2/2] | Step [20214/22538] | Loss: 0.2615 | Accuracy: 0.9286\n","Epoch [2/2] | Step [20215/22538] | Loss: 0.3819 | Accuracy: 0.9013\n","Epoch [2/2] | Step [20216/22538] | Loss: 0.2119 | Accuracy: 0.9187\n","Epoch [2/2] | Step [20217/22538] | Loss: 0.4236 | Accuracy: 0.8818\n","Epoch [2/2] | Step [20218/22538] | Loss: 0.3146 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20219/22538] | Loss: 0.4628 | Accuracy: 0.8883\n","Epoch [2/2] | Step [20220/22538] | Loss: 0.4288 | Accuracy: 0.8931\n","Epoch [2/2] | Step [20221/22538] | Loss: 0.2954 | Accuracy: 0.9200\n","Epoch [2/2] | Step [20222/22538] | Loss: 0.3579 | Accuracy: 0.8983\n","Epoch [2/2] | Step [20223/22538] | Loss: 0.3331 | Accuracy: 0.9016\n","Epoch [2/2] | Step [20224/22538] | Loss: 0.3982 | Accuracy: 0.8822\n","Epoch [2/2] | Step [20225/22538] | Loss: 0.2546 | Accuracy: 0.9320\n","Epoch [2/2] | Step [20226/22538] | Loss: 0.2919 | Accuracy: 0.9159\n","Epoch [2/2] | Step [20227/22538] | Loss: 0.5730 | Accuracy: 0.8678\n","Epoch [2/2] | Step [20228/22538] | Loss: 0.3237 | Accuracy: 0.9056\n","Epoch [2/2] | Step [20229/22538] | Loss: 0.2573 | Accuracy: 0.9303\n","Epoch [2/2] | Step [20230/22538] | Loss: 0.2816 | Accuracy: 0.9188\n","Epoch [2/2] | Step [20231/22538] | Loss: 0.3897 | Accuracy: 0.9028\n","Epoch [2/2] | Step [20232/22538] | Loss: 0.3365 | Accuracy: 0.9073\n","Epoch [2/2] | Step [20233/22538] | Loss: 0.2671 | Accuracy: 0.9302\n","Epoch [2/2] | Step [20234/22538] | Loss: 0.3091 | Accuracy: 0.8895\n","Epoch [2/2] | Step [20235/22538] | Loss: 0.2049 | Accuracy: 0.9394\n","Epoch [2/2] | Step [20236/22538] | Loss: 0.1975 | Accuracy: 0.9426\n","Epoch [2/2] | Step [20237/22538] | Loss: 0.2395 | Accuracy: 0.9462\n","Epoch [2/2] | Step [20238/22538] | Loss: 0.2520 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20239/22538] | Loss: 0.5447 | Accuracy: 0.8674\n","Epoch [2/2] | Step [20240/22538] | Loss: 0.3860 | Accuracy: 0.8967\n","Epoch [2/2] | Step [20241/22538] | Loss: 0.2125 | Accuracy: 0.9367\n","Epoch [2/2] | Step [20242/22538] | Loss: 0.2365 | Accuracy: 0.9334\n","Epoch [2/2] | Step [20243/22538] | Loss: 0.3943 | Accuracy: 0.8980\n","Epoch [2/2] | Step [20244/22538] | Loss: 0.2143 | Accuracy: 0.9450\n","Epoch [2/2] | Step [20245/22538] | Loss: 0.4356 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20246/22538] | Loss: 0.2804 | Accuracy: 0.9174\n","Epoch [2/2] | Step [20247/22538] | Loss: 0.4518 | Accuracy: 0.8923\n","Epoch [2/2] | Step [20248/22538] | Loss: 0.2809 | Accuracy: 0.9214\n","Epoch [2/2] | Step [20249/22538] | Loss: 0.3072 | Accuracy: 0.9120\n","Epoch [2/2] | Step [20250/22538] | Loss: 0.2486 | Accuracy: 0.9306\n","Epoch [2/2] | Step [20251/22538] | Loss: 0.2202 | Accuracy: 0.9382\n","Epoch [2/2] | Step [20252/22538] | Loss: 0.1484 | Accuracy: 0.9670\n","Epoch [2/2] | Step [20253/22538] | Loss: 0.3185 | Accuracy: 0.9237\n","Epoch [2/2] | Step [20254/22538] | Loss: 0.3273 | Accuracy: 0.9078\n","Epoch [2/2] | Step [20255/22538] | Loss: 0.2984 | Accuracy: 0.9146\n","Epoch [2/2] | Step [20256/22538] | Loss: 0.3060 | Accuracy: 0.9132\n","Epoch [2/2] | Step [20257/22538] | Loss: 0.3526 | Accuracy: 0.9011\n","Epoch [2/2] | Step [20258/22538] | Loss: 0.2034 | Accuracy: 0.9330\n","Epoch [2/2] | Step [20259/22538] | Loss: 0.4159 | Accuracy: 0.8977\n","Epoch [2/2] | Step [20260/22538] | Loss: 0.3574 | Accuracy: 0.8980\n","Epoch [2/2] | Step [20261/22538] | Loss: 0.3244 | Accuracy: 0.9123\n","Epoch [2/2] | Step [20262/22538] | Loss: 0.3855 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20263/22538] | Loss: 0.7220 | Accuracy: 0.8354\n","Epoch [2/2] | Step [20264/22538] | Loss: 0.4380 | Accuracy: 0.8778\n","Epoch [2/2] | Step [20265/22538] | Loss: 0.3339 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20266/22538] | Loss: 0.5843 | Accuracy: 0.8614\n","Epoch [2/2] | Step [20267/22538] | Loss: 0.2920 | Accuracy: 0.9207\n","Epoch [2/2] | Step [20268/22538] | Loss: 0.3170 | Accuracy: 0.9022\n","Epoch [2/2] | Step [20269/22538] | Loss: 0.2972 | Accuracy: 0.9208\n","Epoch [2/2] | Step [20270/22538] | Loss: 0.2231 | Accuracy: 0.9337\n","Epoch [2/2] | Step [20271/22538] | Loss: 0.3361 | Accuracy: 0.9031\n","Epoch [2/2] | Step [20272/22538] | Loss: 0.4751 | Accuracy: 0.8696\n","Epoch [2/2] | Step [20273/22538] | Loss: 0.2945 | Accuracy: 0.9040\n","Epoch [2/2] | Step [20274/22538] | Loss: 0.3048 | Accuracy: 0.9153\n","Epoch [2/2] | Step [20275/22538] | Loss: 0.4760 | Accuracy: 0.8835\n","Epoch [2/2] | Step [20276/22538] | Loss: 0.2497 | Accuracy: 0.9246\n","Epoch [2/2] | Step [20277/22538] | Loss: 0.3348 | Accuracy: 0.9096\n","Epoch [2/2] | Step [20278/22538] | Loss: 0.2073 | Accuracy: 0.9440\n","Epoch [2/2] | Step [20279/22538] | Loss: 0.3643 | Accuracy: 0.8909\n","Epoch [2/2] | Step [20280/22538] | Loss: 0.3524 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20281/22538] | Loss: 0.2810 | Accuracy: 0.9266\n","Epoch [2/2] | Step [20282/22538] | Loss: 0.3810 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20283/22538] | Loss: 0.2759 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20284/22538] | Loss: 0.2255 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20285/22538] | Loss: 0.3127 | Accuracy: 0.9152\n","Epoch [2/2] | Step [20286/22538] | Loss: 0.1846 | Accuracy: 0.9428\n","Epoch [2/2] | Step [20287/22538] | Loss: 0.4154 | Accuracy: 0.8987\n","Epoch [2/2] | Step [20288/22538] | Loss: 0.3872 | Accuracy: 0.8940\n","Epoch [2/2] | Step [20289/22538] | Loss: 0.4360 | Accuracy: 0.8821\n","Epoch [2/2] | Step [20290/22538] | Loss: 0.3792 | Accuracy: 0.9038\n","Epoch [2/2] | Step [20291/22538] | Loss: 0.3037 | Accuracy: 0.9139\n","Epoch [2/2] | Step [20292/22538] | Loss: 0.4896 | Accuracy: 0.8648\n","Epoch [2/2] | Step [20293/22538] | Loss: 0.4087 | Accuracy: 0.8878\n","Epoch [2/2] | Step [20294/22538] | Loss: 0.3400 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20295/22538] | Loss: 0.3037 | Accuracy: 0.9293\n","Epoch [2/2] | Step [20296/22538] | Loss: 0.4168 | Accuracy: 0.8875\n","Epoch [2/2] | Step [20297/22538] | Loss: 0.5874 | Accuracy: 0.8656\n","Epoch [2/2] | Step [20298/22538] | Loss: 0.2169 | Accuracy: 0.9315\n","Epoch [2/2] | Step [20299/22538] | Loss: 0.3790 | Accuracy: 0.8952\n","Epoch [2/2] | Step [20300/22538] | Loss: 0.3596 | Accuracy: 0.9119\n","Epoch [2/2] | Step [20301/22538] | Loss: 0.3271 | Accuracy: 0.9072\n","Epoch [2/2] | Step [20302/22538] | Loss: 0.3538 | Accuracy: 0.9036\n","Epoch [2/2] | Step [20303/22538] | Loss: 0.2898 | Accuracy: 0.9246\n","Epoch [2/2] | Step [20304/22538] | Loss: 0.2579 | Accuracy: 0.9172\n","Epoch [2/2] | Step [20305/22538] | Loss: 0.3217 | Accuracy: 0.9103\n","Epoch [2/2] | Step [20306/22538] | Loss: 0.3139 | Accuracy: 0.9130\n","Epoch [2/2] | Step [20307/22538] | Loss: 0.1494 | Accuracy: 0.9588\n","Epoch [2/2] | Step [20308/22538] | Loss: 0.3111 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20309/22538] | Loss: 0.2758 | Accuracy: 0.9295\n","Epoch [2/2] | Step [20310/22538] | Loss: 0.3323 | Accuracy: 0.9136\n","Epoch [2/2] | Step [20311/22538] | Loss: 0.2459 | Accuracy: 0.9294\n","Epoch [2/2] | Step [20312/22538] | Loss: 0.3570 | Accuracy: 0.8965\n","Epoch [2/2] | Step [20313/22538] | Loss: 0.3234 | Accuracy: 0.8979\n","Epoch [2/2] | Step [20314/22538] | Loss: 0.2458 | Accuracy: 0.9271\n","Epoch [2/2] | Step [20315/22538] | Loss: 0.2557 | Accuracy: 0.9147\n","Epoch [2/2] | Step [20316/22538] | Loss: 0.2895 | Accuracy: 0.9269\n","Epoch [2/2] | Step [20317/22538] | Loss: 0.2830 | Accuracy: 0.9050\n","Epoch [2/2] | Step [20318/22538] | Loss: 0.3786 | Accuracy: 0.8971\n","Epoch [2/2] | Step [20319/22538] | Loss: 0.3345 | Accuracy: 0.9097\n","Epoch [2/2] | Step [20320/22538] | Loss: 0.3407 | Accuracy: 0.9128\n","Epoch [2/2] | Step [20321/22538] | Loss: 0.2897 | Accuracy: 0.9153\n","Epoch [2/2] | Step [20322/22538] | Loss: 0.3092 | Accuracy: 0.9063\n","Epoch [2/2] | Step [20323/22538] | Loss: 0.2370 | Accuracy: 0.9393\n","Epoch [2/2] | Step [20324/22538] | Loss: 0.3921 | Accuracy: 0.8958\n","Epoch [2/2] | Step [20325/22538] | Loss: 0.3085 | Accuracy: 0.9176\n","Epoch [2/2] | Step [20326/22538] | Loss: 0.4938 | Accuracy: 0.8980\n","Epoch [2/2] | Step [20327/22538] | Loss: 0.2508 | Accuracy: 0.9347\n","Epoch [2/2] | Step [20328/22538] | Loss: 0.2314 | Accuracy: 0.9292\n","Epoch [2/2] | Step [20329/22538] | Loss: 0.3074 | Accuracy: 0.9050\n","Epoch [2/2] | Step [20330/22538] | Loss: 0.3975 | Accuracy: 0.8977\n","Epoch [2/2] | Step [20331/22538] | Loss: 0.3341 | Accuracy: 0.9200\n","Epoch [2/2] | Step [20332/22538] | Loss: 0.3769 | Accuracy: 0.8906\n","Epoch [2/2] | Step [20333/22538] | Loss: 0.2894 | Accuracy: 0.9130\n","Epoch [2/2] | Step [20334/22538] | Loss: 0.3465 | Accuracy: 0.8949\n","Epoch [2/2] | Step [20335/22538] | Loss: 0.5028 | Accuracy: 0.8824\n","Epoch [2/2] | Step [20336/22538] | Loss: 0.4194 | Accuracy: 0.8932\n","Epoch [2/2] | Step [20337/22538] | Loss: 0.3058 | Accuracy: 0.9098\n","Epoch [2/2] | Step [20338/22538] | Loss: 0.4266 | Accuracy: 0.8821\n","Epoch [2/2] | Step [20339/22538] | Loss: 0.3321 | Accuracy: 0.9067\n","Epoch [2/2] | Step [20340/22538] | Loss: 0.2348 | Accuracy: 0.9349\n","Epoch [2/2] | Step [20341/22538] | Loss: 0.3145 | Accuracy: 0.9182\n","Epoch [2/2] | Step [20342/22538] | Loss: 0.3321 | Accuracy: 0.9063\n","Epoch [2/2] | Step [20343/22538] | Loss: 0.4724 | Accuracy: 0.8722\n","Epoch [2/2] | Step [20344/22538] | Loss: 0.2817 | Accuracy: 0.9156\n","Epoch [2/2] | Step [20345/22538] | Loss: 0.3461 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20346/22538] | Loss: 0.3658 | Accuracy: 0.8850\n","Epoch [2/2] | Step [20347/22538] | Loss: 0.3009 | Accuracy: 0.9028\n","Epoch [2/2] | Step [20348/22538] | Loss: 0.4152 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20349/22538] | Loss: 0.3978 | Accuracy: 0.9028\n","Epoch [2/2] | Step [20350/22538] | Loss: 0.1840 | Accuracy: 0.9406\n","Epoch [2/2] | Step [20351/22538] | Loss: 0.3526 | Accuracy: 0.8913\n","Epoch [2/2] | Step [20352/22538] | Loss: 0.3603 | Accuracy: 0.9006\n","Epoch [2/2] | Step [20353/22538] | Loss: 0.4603 | Accuracy: 0.8730\n","Epoch [2/2] | Step [20354/22538] | Loss: 0.2325 | Accuracy: 0.9216\n","Epoch [2/2] | Step [20355/22538] | Loss: 0.1962 | Accuracy: 0.9459\n","Epoch [2/2] | Step [20356/22538] | Loss: 0.4208 | Accuracy: 0.8785\n","Epoch [2/2] | Step [20357/22538] | Loss: 0.4015 | Accuracy: 0.8903\n","Epoch [2/2] | Step [20358/22538] | Loss: 0.4433 | Accuracy: 0.8925\n","Epoch [2/2] | Step [20359/22538] | Loss: 0.4470 | Accuracy: 0.8869\n","Epoch [2/2] | Step [20360/22538] | Loss: 0.3366 | Accuracy: 0.8866\n","Epoch [2/2] | Step [20361/22538] | Loss: 0.4148 | Accuracy: 0.8897\n","Epoch [2/2] | Step [20362/22538] | Loss: 0.3229 | Accuracy: 0.9097\n","Epoch [2/2] | Step [20363/22538] | Loss: 0.2342 | Accuracy: 0.9349\n","Epoch [2/2] | Step [20364/22538] | Loss: 0.3409 | Accuracy: 0.9025\n","Epoch [2/2] | Step [20365/22538] | Loss: 0.3912 | Accuracy: 0.8958\n","Epoch [2/2] | Step [20366/22538] | Loss: 0.2524 | Accuracy: 0.9364\n","Epoch [2/2] | Step [20367/22538] | Loss: 0.3120 | Accuracy: 0.9082\n","Epoch [2/2] | Step [20368/22538] | Loss: 0.3439 | Accuracy: 0.9174\n","Epoch [2/2] | Step [20369/22538] | Loss: 0.2718 | Accuracy: 0.9273\n","Epoch [2/2] | Step [20370/22538] | Loss: 0.3439 | Accuracy: 0.9136\n","Epoch [2/2] | Step [20371/22538] | Loss: 0.2109 | Accuracy: 0.9432\n","Epoch [2/2] | Step [20372/22538] | Loss: 0.2041 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20373/22538] | Loss: 0.4332 | Accuracy: 0.8859\n","Epoch [2/2] | Step [20374/22538] | Loss: 0.4083 | Accuracy: 0.8977\n","Epoch [2/2] | Step [20375/22538] | Loss: 0.4543 | Accuracy: 0.8603\n","Epoch [2/2] | Step [20376/22538] | Loss: 0.3629 | Accuracy: 0.8953\n","Epoch [2/2] | Step [20377/22538] | Loss: 0.3399 | Accuracy: 0.8984\n","Epoch [2/2] | Step [20378/22538] | Loss: 0.3233 | Accuracy: 0.8962\n","Epoch [2/2] | Step [20379/22538] | Loss: 0.3748 | Accuracy: 0.9123\n","Epoch [2/2] | Step [20380/22538] | Loss: 0.3429 | Accuracy: 0.8919\n","Epoch [2/2] | Step [20381/22538] | Loss: 0.3066 | Accuracy: 0.9114\n","Epoch [2/2] | Step [20382/22538] | Loss: 0.4249 | Accuracy: 0.8778\n","Epoch [2/2] | Step [20383/22538] | Loss: 0.3825 | Accuracy: 0.8880\n","Epoch [2/2] | Step [20384/22538] | Loss: 0.2531 | Accuracy: 0.9291\n","Epoch [2/2] | Step [20385/22538] | Loss: 0.3162 | Accuracy: 0.9219\n","Epoch [2/2] | Step [20386/22538] | Loss: 0.2639 | Accuracy: 0.9280\n","Epoch [2/2] | Step [20387/22538] | Loss: 0.2406 | Accuracy: 0.9313\n","Epoch [2/2] | Step [20388/22538] | Loss: 0.3101 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20389/22538] | Loss: 0.2753 | Accuracy: 0.9123\n","Epoch [2/2] | Step [20390/22538] | Loss: 0.4128 | Accuracy: 0.8807\n","Epoch [2/2] | Step [20391/22538] | Loss: 0.3314 | Accuracy: 0.9282\n","Epoch [2/2] | Step [20392/22538] | Loss: 0.2306 | Accuracy: 0.9408\n","Epoch [2/2] | Step [20393/22538] | Loss: 0.2886 | Accuracy: 0.9272\n","Epoch [2/2] | Step [20394/22538] | Loss: 0.2588 | Accuracy: 0.9340\n","Epoch [2/2] | Step [20395/22538] | Loss: 0.3602 | Accuracy: 0.8952\n","Epoch [2/2] | Step [20396/22538] | Loss: 0.3095 | Accuracy: 0.9096\n","Epoch [2/2] | Step [20397/22538] | Loss: 0.4066 | Accuracy: 0.9048\n","Epoch [2/2] | Step [20398/22538] | Loss: 0.4107 | Accuracy: 0.8886\n","Epoch [2/2] | Step [20399/22538] | Loss: 0.2526 | Accuracy: 0.9345\n","Epoch [2/2] | Step [20400/22538] | Loss: 0.2987 | Accuracy: 0.9256\n","Epoch [2/2] | Step [20401/22538] | Loss: 0.3827 | Accuracy: 0.8875\n","Epoch [2/2] | Step [20402/22538] | Loss: 0.3096 | Accuracy: 0.9205\n","Epoch [2/2] | Step [20403/22538] | Loss: 0.3504 | Accuracy: 0.9137\n","Epoch [2/2] | Step [20404/22538] | Loss: 0.1862 | Accuracy: 0.9419\n","Epoch [2/2] | Step [20405/22538] | Loss: 0.3518 | Accuracy: 0.9087\n","Epoch [2/2] | Step [20406/22538] | Loss: 0.2914 | Accuracy: 0.9020\n","Epoch [2/2] | Step [20407/22538] | Loss: 0.2988 | Accuracy: 0.9246\n","Epoch [2/2] | Step [20408/22538] | Loss: 0.2354 | Accuracy: 0.9395\n","Epoch [2/2] | Step [20409/22538] | Loss: 0.4654 | Accuracy: 0.8859\n","Epoch [2/2] | Step [20410/22538] | Loss: 0.3710 | Accuracy: 0.8873\n","Epoch [2/2] | Step [20411/22538] | Loss: 0.3417 | Accuracy: 0.9093\n","Epoch [2/2] | Step [20412/22538] | Loss: 0.2578 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20413/22538] | Loss: 0.3718 | Accuracy: 0.8889\n","Epoch [2/2] | Step [20414/22538] | Loss: 0.4329 | Accuracy: 0.8892\n","Epoch [2/2] | Step [20415/22538] | Loss: 0.2350 | Accuracy: 0.9485\n","Epoch [2/2] | Step [20416/22538] | Loss: 0.3011 | Accuracy: 0.9253\n","Epoch [2/2] | Step [20417/22538] | Loss: 0.4575 | Accuracy: 0.8810\n","Epoch [2/2] | Step [20418/22538] | Loss: 0.2553 | Accuracy: 0.9110\n","Epoch [2/2] | Step [20419/22538] | Loss: 0.2478 | Accuracy: 0.9301\n","Epoch [2/2] | Step [20420/22538] | Loss: 0.4188 | Accuracy: 0.8941\n","Epoch [2/2] | Step [20421/22538] | Loss: 0.3145 | Accuracy: 0.9240\n","Epoch [2/2] | Step [20422/22538] | Loss: 0.2477 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20423/22538] | Loss: 0.3195 | Accuracy: 0.8984\n","Epoch [2/2] | Step [20424/22538] | Loss: 0.3581 | Accuracy: 0.9107\n","Epoch [2/2] | Step [20425/22538] | Loss: 0.3340 | Accuracy: 0.8961\n","Epoch [2/2] | Step [20426/22538] | Loss: 0.3521 | Accuracy: 0.9012\n","Epoch [2/2] | Step [20427/22538] | Loss: 0.3039 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20428/22538] | Loss: 0.2766 | Accuracy: 0.9275\n","Epoch [2/2] | Step [20429/22538] | Loss: 0.3448 | Accuracy: 0.9079\n","Epoch [2/2] | Step [20430/22538] | Loss: 0.3324 | Accuracy: 0.8981\n","Epoch [2/2] | Step [20431/22538] | Loss: 0.3810 | Accuracy: 0.8944\n","Epoch [2/2] | Step [20432/22538] | Loss: 0.3086 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20433/22538] | Loss: 0.3007 | Accuracy: 0.9050\n","Epoch [2/2] | Step [20434/22538] | Loss: 0.3413 | Accuracy: 0.9049\n","Epoch [2/2] | Step [20435/22538] | Loss: 0.2156 | Accuracy: 0.9360\n","Epoch [2/2] | Step [20436/22538] | Loss: 0.2789 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20437/22538] | Loss: 0.3322 | Accuracy: 0.9033\n","Epoch [2/2] | Step [20438/22538] | Loss: 0.2766 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20439/22538] | Loss: 0.3023 | Accuracy: 0.9219\n","Epoch [2/2] | Step [20440/22538] | Loss: 0.3376 | Accuracy: 0.9198\n","Epoch [2/2] | Step [20441/22538] | Loss: 0.2364 | Accuracy: 0.9324\n","Epoch [2/2] | Step [20442/22538] | Loss: 0.3944 | Accuracy: 0.8542\n","Epoch [2/2] | Step [20443/22538] | Loss: 0.2947 | Accuracy: 0.9235\n","Epoch [2/2] | Step [20444/22538] | Loss: 0.3294 | Accuracy: 0.8902\n","Epoch [2/2] | Step [20445/22538] | Loss: 0.2280 | Accuracy: 0.9398\n","Epoch [2/2] | Step [20446/22538] | Loss: 0.4156 | Accuracy: 0.8975\n","Epoch [2/2] | Step [20447/22538] | Loss: 0.2034 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20448/22538] | Loss: 0.2867 | Accuracy: 0.9256\n","Epoch [2/2] | Step [20449/22538] | Loss: 0.4569 | Accuracy: 0.8723\n","Epoch [2/2] | Step [20450/22538] | Loss: 0.4434 | Accuracy: 0.8870\n","Epoch [2/2] | Step [20451/22538] | Loss: 0.2806 | Accuracy: 0.9191\n","Epoch [2/2] | Step [20452/22538] | Loss: 0.3555 | Accuracy: 0.8929\n","Epoch [2/2] | Step [20453/22538] | Loss: 0.3919 | Accuracy: 0.8995\n","Epoch [2/2] | Step [20454/22538] | Loss: 0.3592 | Accuracy: 0.9159\n","Epoch [2/2] | Step [20455/22538] | Loss: 0.2227 | Accuracy: 0.9384\n","Epoch [2/2] | Step [20456/22538] | Loss: 0.2615 | Accuracy: 0.9205\n","Epoch [2/2] | Step [20457/22538] | Loss: 0.3458 | Accuracy: 0.9176\n","Epoch [2/2] | Step [20458/22538] | Loss: 0.3379 | Accuracy: 0.9113\n","Epoch [2/2] | Step [20459/22538] | Loss: 0.3721 | Accuracy: 0.9005\n","Epoch [2/2] | Step [20460/22538] | Loss: 0.4040 | Accuracy: 0.9152\n","Epoch [2/2] | Step [20461/22538] | Loss: 0.3696 | Accuracy: 0.8882\n","Epoch [2/2] | Step [20462/22538] | Loss: 0.1954 | Accuracy: 0.9443\n","Epoch [2/2] | Step [20463/22538] | Loss: 0.3204 | Accuracy: 0.9138\n","Epoch [2/2] | Step [20464/22538] | Loss: 0.3335 | Accuracy: 0.9180\n","Epoch [2/2] | Step [20465/22538] | Loss: 0.3652 | Accuracy: 0.8983\n","Epoch [2/2] | Step [20466/22538] | Loss: 0.1866 | Accuracy: 0.9435\n","Epoch [2/2] | Step [20467/22538] | Loss: 0.4416 | Accuracy: 0.8958\n","Epoch [2/2] | Step [20468/22538] | Loss: 0.2706 | Accuracy: 0.9189\n","Epoch [2/2] | Step [20469/22538] | Loss: 0.3686 | Accuracy: 0.8973\n","Epoch [2/2] | Step [20470/22538] | Loss: 0.2913 | Accuracy: 0.9180\n","Epoch [2/2] | Step [20471/22538] | Loss: 0.3271 | Accuracy: 0.9069\n","Epoch [2/2] | Step [20472/22538] | Loss: 0.2738 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20473/22538] | Loss: 0.2850 | Accuracy: 0.9040\n","Epoch [2/2] | Step [20474/22538] | Loss: 0.1800 | Accuracy: 0.9451\n","Epoch [2/2] | Step [20475/22538] | Loss: 0.2016 | Accuracy: 0.9418\n","Epoch [2/2] | Step [20476/22538] | Loss: 0.4892 | Accuracy: 0.8716\n","Epoch [2/2] | Step [20477/22538] | Loss: 0.2693 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20478/22538] | Loss: 0.3065 | Accuracy: 0.9153\n","Epoch [2/2] | Step [20479/22538] | Loss: 0.2283 | Accuracy: 0.9306\n","Epoch [2/2] | Step [20480/22538] | Loss: 0.2574 | Accuracy: 0.9222\n","Epoch [2/2] | Step [20481/22538] | Loss: 0.2230 | Accuracy: 0.9177\n","Epoch [2/2] | Step [20482/22538] | Loss: 0.3310 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20483/22538] | Loss: 0.2262 | Accuracy: 0.9415\n","Epoch [2/2] | Step [20484/22538] | Loss: 0.3405 | Accuracy: 0.9207\n","Epoch [2/2] | Step [20485/22538] | Loss: 0.2304 | Accuracy: 0.9320\n","Epoch [2/2] | Step [20486/22538] | Loss: 0.6416 | Accuracy: 0.8702\n","Epoch [2/2] | Step [20487/22538] | Loss: 0.2862 | Accuracy: 0.9209\n","Epoch [2/2] | Step [20488/22538] | Loss: 0.2575 | Accuracy: 0.9123\n","Epoch [2/2] | Step [20489/22538] | Loss: 0.3199 | Accuracy: 0.9130\n","Epoch [2/2] | Step [20490/22538] | Loss: 0.3058 | Accuracy: 0.9104\n","Epoch [2/2] | Step [20491/22538] | Loss: 0.3832 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20492/22538] | Loss: 0.3053 | Accuracy: 0.9146\n","Epoch [2/2] | Step [20493/22538] | Loss: 0.2947 | Accuracy: 0.9135\n","Epoch [2/2] | Step [20494/22538] | Loss: 0.2585 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20495/22538] | Loss: 0.2940 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20496/22538] | Loss: 0.3527 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20497/22538] | Loss: 0.4004 | Accuracy: 0.9023\n","Epoch [2/2] | Step [20498/22538] | Loss: 0.1867 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20499/22538] | Loss: 0.3760 | Accuracy: 0.9006\n","Epoch [2/2] | Step [20500/22538] | Loss: 0.3417 | Accuracy: 0.8944\n","Epoch [2/2] | Step [20501/22538] | Loss: 0.3912 | Accuracy: 0.8873\n","Epoch [2/2] | Step [20502/22538] | Loss: 0.4269 | Accuracy: 0.8873\n","Epoch [2/2] | Step [20503/22538] | Loss: 0.3579 | Accuracy: 0.8814\n","Epoch [2/2] | Step [20504/22538] | Loss: 0.3074 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20505/22538] | Loss: 0.3175 | Accuracy: 0.9294\n","Epoch [2/2] | Step [20506/22538] | Loss: 0.3327 | Accuracy: 0.8972\n","Epoch [2/2] | Step [20507/22538] | Loss: 0.3598 | Accuracy: 0.9034\n","Epoch [2/2] | Step [20508/22538] | Loss: 0.4283 | Accuracy: 0.8833\n","Epoch [2/2] | Step [20509/22538] | Loss: 0.4185 | Accuracy: 0.9012\n","Epoch [2/2] | Step [20510/22538] | Loss: 0.3106 | Accuracy: 0.8935\n","Epoch [2/2] | Step [20511/22538] | Loss: 0.2481 | Accuracy: 0.9219\n","Epoch [2/2] | Step [20512/22538] | Loss: 0.2994 | Accuracy: 0.9073\n","Epoch [2/2] | Step [20513/22538] | Loss: 0.2976 | Accuracy: 0.9352\n","Epoch [2/2] | Step [20514/22538] | Loss: 0.5032 | Accuracy: 0.8880\n","Epoch [2/2] | Step [20515/22538] | Loss: 0.3047 | Accuracy: 0.9219\n","Epoch [2/2] | Step [20516/22538] | Loss: 0.3755 | Accuracy: 0.8870\n","Epoch [2/2] | Step [20517/22538] | Loss: 0.5328 | Accuracy: 0.8692\n","Epoch [2/2] | Step [20518/22538] | Loss: 0.2227 | Accuracy: 0.9198\n","Epoch [2/2] | Step [20519/22538] | Loss: 0.3176 | Accuracy: 0.9131\n","Epoch [2/2] | Step [20520/22538] | Loss: 0.3001 | Accuracy: 0.9068\n","Epoch [2/2] | Step [20521/22538] | Loss: 0.3032 | Accuracy: 0.9050\n","Epoch [2/2] | Step [20522/22538] | Loss: 0.3446 | Accuracy: 0.9100\n","Epoch [2/2] | Step [20523/22538] | Loss: 0.3813 | Accuracy: 0.8825\n","Epoch [2/2] | Step [20524/22538] | Loss: 0.3447 | Accuracy: 0.9180\n","Epoch [2/2] | Step [20525/22538] | Loss: 0.2249 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20526/22538] | Loss: 0.2150 | Accuracy: 0.9359\n","Epoch [2/2] | Step [20527/22538] | Loss: 0.3141 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20528/22538] | Loss: 0.1816 | Accuracy: 0.9430\n","Epoch [2/2] | Step [20529/22538] | Loss: 0.3850 | Accuracy: 0.8996\n","Epoch [2/2] | Step [20530/22538] | Loss: 0.2950 | Accuracy: 0.9185\n","Epoch [2/2] | Step [20531/22538] | Loss: 0.3489 | Accuracy: 0.9009\n","Epoch [2/2] | Step [20532/22538] | Loss: 0.2817 | Accuracy: 0.9107\n","Epoch [2/2] | Step [20533/22538] | Loss: 0.4120 | Accuracy: 0.9038\n","Epoch [2/2] | Step [20534/22538] | Loss: 0.3602 | Accuracy: 0.9045\n","Epoch [2/2] | Step [20535/22538] | Loss: 0.2919 | Accuracy: 0.9112\n","Epoch [2/2] | Step [20536/22538] | Loss: 0.4142 | Accuracy: 0.8831\n","Epoch [2/2] | Step [20537/22538] | Loss: 0.1158 | Accuracy: 0.9695\n","Epoch [2/2] | Step [20538/22538] | Loss: 0.3497 | Accuracy: 0.9096\n","Epoch [2/2] | Step [20539/22538] | Loss: 0.4179 | Accuracy: 0.8954\n","Epoch [2/2] | Step [20540/22538] | Loss: 0.3519 | Accuracy: 0.9053\n","Epoch [2/2] | Step [20541/22538] | Loss: 0.4216 | Accuracy: 0.8838\n","Epoch [2/2] | Step [20542/22538] | Loss: 0.5554 | Accuracy: 0.8333\n","Epoch [2/2] | Step [20543/22538] | Loss: 0.3311 | Accuracy: 0.9069\n","Epoch [2/2] | Step [20544/22538] | Loss: 0.3302 | Accuracy: 0.9044\n","Epoch [2/2] | Step [20545/22538] | Loss: 0.2119 | Accuracy: 0.9338\n","Epoch [2/2] | Step [20546/22538] | Loss: 0.3270 | Accuracy: 0.9083\n","Epoch [2/2] | Step [20547/22538] | Loss: 0.3561 | Accuracy: 0.8856\n","Epoch [2/2] | Step [20548/22538] | Loss: 0.2210 | Accuracy: 0.9316\n","Epoch [2/2] | Step [20549/22538] | Loss: 0.2957 | Accuracy: 0.9189\n","Epoch [2/2] | Step [20550/22538] | Loss: 0.3356 | Accuracy: 0.9051\n","Epoch [2/2] | Step [20551/22538] | Loss: 0.2286 | Accuracy: 0.9333\n","Epoch [2/2] | Step [20552/22538] | Loss: 0.3597 | Accuracy: 0.9107\n","Epoch [2/2] | Step [20553/22538] | Loss: 0.3002 | Accuracy: 0.8988\n","Epoch [2/2] | Step [20554/22538] | Loss: 0.2277 | Accuracy: 0.9364\n","Epoch [2/2] | Step [20555/22538] | Loss: 0.3036 | Accuracy: 0.9144\n","Epoch [2/2] | Step [20556/22538] | Loss: 0.2501 | Accuracy: 0.9226\n","Epoch [2/2] | Step [20557/22538] | Loss: 0.2448 | Accuracy: 0.9364\n","Epoch [2/2] | Step [20558/22538] | Loss: 0.4441 | Accuracy: 0.8869\n","Epoch [2/2] | Step [20559/22538] | Loss: 0.2501 | Accuracy: 0.9241\n","Epoch [2/2] | Step [20560/22538] | Loss: 0.3183 | Accuracy: 0.9153\n","Epoch [2/2] | Step [20561/22538] | Loss: 0.3818 | Accuracy: 0.8958\n","Epoch [2/2] | Step [20562/22538] | Loss: 0.2525 | Accuracy: 0.9348\n","Epoch [2/2] | Step [20563/22538] | Loss: 0.3519 | Accuracy: 0.9009\n","Epoch [2/2] | Step [20564/22538] | Loss: 0.2760 | Accuracy: 0.9176\n","Epoch [2/2] | Step [20565/22538] | Loss: 0.2893 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20566/22538] | Loss: 0.2178 | Accuracy: 0.9426\n","Epoch [2/2] | Step [20567/22538] | Loss: 0.3304 | Accuracy: 0.9130\n","Epoch [2/2] | Step [20568/22538] | Loss: 0.3464 | Accuracy: 0.8979\n","Epoch [2/2] | Step [20569/22538] | Loss: 0.4829 | Accuracy: 0.8586\n","Epoch [2/2] | Step [20570/22538] | Loss: 0.4954 | Accuracy: 0.8687\n","Epoch [2/2] | Step [20571/22538] | Loss: 0.2812 | Accuracy: 0.9289\n","Epoch [2/2] | Step [20572/22538] | Loss: 0.2521 | Accuracy: 0.9303\n","Epoch [2/2] | Step [20573/22538] | Loss: 0.3478 | Accuracy: 0.8897\n","Epoch [2/2] | Step [20574/22538] | Loss: 0.2696 | Accuracy: 0.9156\n","Epoch [2/2] | Step [20575/22538] | Loss: 0.2010 | Accuracy: 0.9535\n","Epoch [2/2] | Step [20576/22538] | Loss: 0.4290 | Accuracy: 0.9120\n","Epoch [2/2] | Step [20577/22538] | Loss: 0.2631 | Accuracy: 0.9122\n","Epoch [2/2] | Step [20578/22538] | Loss: 0.3254 | Accuracy: 0.9097\n","Epoch [2/2] | Step [20579/22538] | Loss: 0.2249 | Accuracy: 0.9263\n","Epoch [2/2] | Step [20580/22538] | Loss: 0.3640 | Accuracy: 0.8929\n","Epoch [2/2] | Step [20581/22538] | Loss: 0.3617 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20582/22538] | Loss: 0.4055 | Accuracy: 0.9142\n","Epoch [2/2] | Step [20583/22538] | Loss: 0.2508 | Accuracy: 0.9057\n","Epoch [2/2] | Step [20584/22538] | Loss: 0.2831 | Accuracy: 0.9107\n","Epoch [2/2] | Step [20585/22538] | Loss: 0.3382 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20586/22538] | Loss: 0.3509 | Accuracy: 0.9101\n","Epoch [2/2] | Step [20587/22538] | Loss: 0.3530 | Accuracy: 0.8973\n","Epoch [2/2] | Step [20588/22538] | Loss: 0.3000 | Accuracy: 0.9147\n","Epoch [2/2] | Step [20589/22538] | Loss: 0.3912 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20590/22538] | Loss: 0.2048 | Accuracy: 0.9432\n","Epoch [2/2] | Step [20591/22538] | Loss: 0.2889 | Accuracy: 0.9098\n","Epoch [2/2] | Step [20592/22538] | Loss: 0.2314 | Accuracy: 0.9347\n","Epoch [2/2] | Step [20593/22538] | Loss: 0.3369 | Accuracy: 0.9004\n","Epoch [2/2] | Step [20594/22538] | Loss: 0.3404 | Accuracy: 0.9136\n","Epoch [2/2] | Step [20595/22538] | Loss: 0.2886 | Accuracy: 0.9160\n","Epoch [2/2] | Step [20596/22538] | Loss: 0.2363 | Accuracy: 0.9357\n","Epoch [2/2] | Step [20597/22538] | Loss: 0.4376 | Accuracy: 0.8817\n","Epoch [2/2] | Step [20598/22538] | Loss: 0.3483 | Accuracy: 0.9028\n","Epoch [2/2] | Step [20599/22538] | Loss: 0.3268 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20600/22538] | Loss: 0.2713 | Accuracy: 0.9208\n","Epoch [2/2] | Step [20601/22538] | Loss: 0.3457 | Accuracy: 0.9196\n","Epoch [2/2] | Step [20602/22538] | Loss: 0.3838 | Accuracy: 0.9052\n","Epoch [2/2] | Step [20603/22538] | Loss: 0.2297 | Accuracy: 0.9288\n","Epoch [2/2] | Step [20604/22538] | Loss: 0.2593 | Accuracy: 0.9311\n","Epoch [2/2] | Step [20605/22538] | Loss: 0.2844 | Accuracy: 0.9205\n","Epoch [2/2] | Step [20606/22538] | Loss: 0.4168 | Accuracy: 0.8971\n","Epoch [2/2] | Step [20607/22538] | Loss: 0.3209 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20608/22538] | Loss: 0.4398 | Accuracy: 0.8950\n","Epoch [2/2] | Step [20609/22538] | Loss: 0.4063 | Accuracy: 0.8889\n","Epoch [2/2] | Step [20610/22538] | Loss: 0.2610 | Accuracy: 0.9260\n","Epoch [2/2] | Step [20611/22538] | Loss: 0.4165 | Accuracy: 0.8824\n","Epoch [2/2] | Step [20612/22538] | Loss: 0.4288 | Accuracy: 0.8781\n","Epoch [2/2] | Step [20613/22538] | Loss: 0.3734 | Accuracy: 0.8817\n","Epoch [2/2] | Step [20614/22538] | Loss: 0.3447 | Accuracy: 0.9114\n","Epoch [2/2] | Step [20615/22538] | Loss: 0.3440 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20616/22538] | Loss: 0.3119 | Accuracy: 0.9159\n","Epoch [2/2] | Step [20617/22538] | Loss: 0.2378 | Accuracy: 0.9302\n","Epoch [2/2] | Step [20618/22538] | Loss: 0.3276 | Accuracy: 0.9201\n","Epoch [2/2] | Step [20619/22538] | Loss: 0.2488 | Accuracy: 0.9280\n","Epoch [2/2] | Step [20620/22538] | Loss: 0.5034 | Accuracy: 0.8523\n","Epoch [2/2] | Step [20621/22538] | Loss: 0.3273 | Accuracy: 0.9063\n","Epoch [2/2] | Step [20622/22538] | Loss: 0.3332 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20623/22538] | Loss: 0.3992 | Accuracy: 0.8983\n","Epoch [2/2] | Step [20624/22538] | Loss: 0.3322 | Accuracy: 0.9069\n","Epoch [2/2] | Step [20625/22538] | Loss: 0.2825 | Accuracy: 0.9229\n","Epoch [2/2] | Step [20626/22538] | Loss: 0.4212 | Accuracy: 0.8984\n","Epoch [2/2] | Step [20627/22538] | Loss: 0.3001 | Accuracy: 0.9160\n","Epoch [2/2] | Step [20628/22538] | Loss: 0.3687 | Accuracy: 0.8953\n","Epoch [2/2] | Step [20629/22538] | Loss: 0.4548 | Accuracy: 0.8918\n","Epoch [2/2] | Step [20630/22538] | Loss: 0.2784 | Accuracy: 0.9146\n","Epoch [2/2] | Step [20631/22538] | Loss: 0.3572 | Accuracy: 0.8934\n","Epoch [2/2] | Step [20632/22538] | Loss: 0.3289 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20633/22538] | Loss: 0.4189 | Accuracy: 0.8797\n","Epoch [2/2] | Step [20634/22538] | Loss: 0.1970 | Accuracy: 0.9548\n","Epoch [2/2] | Step [20635/22538] | Loss: 0.2145 | Accuracy: 0.9262\n","Epoch [2/2] | Step [20636/22538] | Loss: 0.2681 | Accuracy: 0.9224\n","Epoch [2/2] | Step [20637/22538] | Loss: 0.3081 | Accuracy: 0.9087\n","Epoch [2/2] | Step [20638/22538] | Loss: 0.3744 | Accuracy: 0.8967\n","Epoch [2/2] | Step [20639/22538] | Loss: 0.3628 | Accuracy: 0.9120\n","Epoch [2/2] | Step [20640/22538] | Loss: 0.3255 | Accuracy: 0.9031\n","Epoch [2/2] | Step [20641/22538] | Loss: 0.3691 | Accuracy: 0.9032\n","Epoch [2/2] | Step [20642/22538] | Loss: 0.3557 | Accuracy: 0.9020\n","Epoch [2/2] | Step [20643/22538] | Loss: 0.2084 | Accuracy: 0.9386\n","Epoch [2/2] | Step [20644/22538] | Loss: 0.4815 | Accuracy: 0.8816\n","Epoch [2/2] | Step [20645/22538] | Loss: 0.3633 | Accuracy: 0.9156\n","Epoch [2/2] | Step [20646/22538] | Loss: 0.3398 | Accuracy: 0.8915\n","Epoch [2/2] | Step [20647/22538] | Loss: 0.4388 | Accuracy: 0.8843\n","Epoch [2/2] | Step [20648/22538] | Loss: 0.3805 | Accuracy: 0.8884\n","Epoch [2/2] | Step [20649/22538] | Loss: 0.4067 | Accuracy: 0.8878\n","Epoch [2/2] | Step [20650/22538] | Loss: 0.5149 | Accuracy: 0.8724\n","Epoch [2/2] | Step [20651/22538] | Loss: 0.1899 | Accuracy: 0.9449\n","Epoch [2/2] | Step [20652/22538] | Loss: 0.2670 | Accuracy: 0.9231\n","Epoch [2/2] | Step [20653/22538] | Loss: 0.2605 | Accuracy: 0.9224\n","Epoch [2/2] | Step [20654/22538] | Loss: 0.2969 | Accuracy: 0.9358\n","Epoch [2/2] | Step [20655/22538] | Loss: 0.2557 | Accuracy: 0.9294\n","Epoch [2/2] | Step [20656/22538] | Loss: 0.4444 | Accuracy: 0.8904\n","Epoch [2/2] | Step [20657/22538] | Loss: 0.2418 | Accuracy: 0.9246\n","Epoch [2/2] | Step [20658/22538] | Loss: 0.2603 | Accuracy: 0.9246\n","Epoch [2/2] | Step [20659/22538] | Loss: 0.4003 | Accuracy: 0.9020\n","Epoch [2/2] | Step [20660/22538] | Loss: 0.3134 | Accuracy: 0.9191\n","Epoch [2/2] | Step [20661/22538] | Loss: 0.3454 | Accuracy: 0.9173\n","Epoch [2/2] | Step [20662/22538] | Loss: 0.3377 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20663/22538] | Loss: 0.3207 | Accuracy: 0.9050\n","Epoch [2/2] | Step [20664/22538] | Loss: 0.2237 | Accuracy: 0.9425\n","Epoch [2/2] | Step [20665/22538] | Loss: 0.3193 | Accuracy: 0.9226\n","Epoch [2/2] | Step [20666/22538] | Loss: 0.2822 | Accuracy: 0.9076\n","Epoch [2/2] | Step [20667/22538] | Loss: 0.3165 | Accuracy: 0.9097\n","Epoch [2/2] | Step [20668/22538] | Loss: 0.2408 | Accuracy: 0.9450\n","Epoch [2/2] | Step [20669/22538] | Loss: 0.4265 | Accuracy: 0.9176\n","Epoch [2/2] | Step [20670/22538] | Loss: 0.4067 | Accuracy: 0.8776\n","Epoch [2/2] | Step [20671/22538] | Loss: 0.3014 | Accuracy: 0.9271\n","Epoch [2/2] | Step [20672/22538] | Loss: 0.2045 | Accuracy: 0.9367\n","Epoch [2/2] | Step [20673/22538] | Loss: 0.2303 | Accuracy: 0.9383\n","Epoch [2/2] | Step [20674/22538] | Loss: 0.2311 | Accuracy: 0.9212\n","Epoch [2/2] | Step [20675/22538] | Loss: 0.2946 | Accuracy: 0.9253\n","Epoch [2/2] | Step [20676/22538] | Loss: 0.2500 | Accuracy: 0.9116\n","Epoch [2/2] | Step [20677/22538] | Loss: 0.4006 | Accuracy: 0.9036\n","Epoch [2/2] | Step [20678/22538] | Loss: 0.2641 | Accuracy: 0.9089\n","Epoch [2/2] | Step [20679/22538] | Loss: 0.3173 | Accuracy: 0.9063\n","Epoch [2/2] | Step [20680/22538] | Loss: 0.4555 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20681/22538] | Loss: 0.2463 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20682/22538] | Loss: 0.2476 | Accuracy: 0.9318\n","Epoch [2/2] | Step [20683/22538] | Loss: 0.2143 | Accuracy: 0.9193\n","Epoch [2/2] | Step [20684/22538] | Loss: 0.3387 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20685/22538] | Loss: 0.2561 | Accuracy: 0.9407\n","Epoch [2/2] | Step [20686/22538] | Loss: 0.3716 | Accuracy: 0.9057\n","Epoch [2/2] | Step [20687/22538] | Loss: 0.3654 | Accuracy: 0.9055\n","Epoch [2/2] | Step [20688/22538] | Loss: 0.2963 | Accuracy: 0.9105\n","Epoch [2/2] | Step [20689/22538] | Loss: 0.2739 | Accuracy: 0.9250\n","Epoch [2/2] | Step [20690/22538] | Loss: 0.2522 | Accuracy: 0.9243\n","Epoch [2/2] | Step [20691/22538] | Loss: 0.2626 | Accuracy: 0.9388\n","Epoch [2/2] | Step [20692/22538] | Loss: 0.2843 | Accuracy: 0.9231\n","Epoch [2/2] | Step [20693/22538] | Loss: 0.3411 | Accuracy: 0.9236\n","Epoch [2/2] | Step [20694/22538] | Loss: 0.3549 | Accuracy: 0.9005\n","Epoch [2/2] | Step [20695/22538] | Loss: 0.2403 | Accuracy: 0.9212\n","Epoch [2/2] | Step [20696/22538] | Loss: 0.5490 | Accuracy: 0.8702\n","Epoch [2/2] | Step [20697/22538] | Loss: 0.2433 | Accuracy: 0.9365\n","Epoch [2/2] | Step [20698/22538] | Loss: 0.2283 | Accuracy: 0.9288\n","Epoch [2/2] | Step [20699/22538] | Loss: 0.3584 | Accuracy: 0.8932\n","Epoch [2/2] | Step [20700/22538] | Loss: 0.2699 | Accuracy: 0.9189\n","Epoch [2/2] | Step [20701/22538] | Loss: 0.6362 | Accuracy: 0.8281\n","Epoch [2/2] | Step [20702/22538] | Loss: 0.2874 | Accuracy: 0.9159\n","Epoch [2/2] | Step [20703/22538] | Loss: 0.2706 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20704/22538] | Loss: 0.2218 | Accuracy: 0.9264\n","Epoch [2/2] | Step [20705/22538] | Loss: 0.3925 | Accuracy: 0.8981\n","Epoch [2/2] | Step [20706/22538] | Loss: 0.4095 | Accuracy: 0.9037\n","Epoch [2/2] | Step [20707/22538] | Loss: 0.3434 | Accuracy: 0.8838\n","Epoch [2/2] | Step [20708/22538] | Loss: 0.4754 | Accuracy: 0.8618\n","Epoch [2/2] | Step [20709/22538] | Loss: 0.2474 | Accuracy: 0.9267\n","Epoch [2/2] | Step [20710/22538] | Loss: 0.3610 | Accuracy: 0.8909\n","Epoch [2/2] | Step [20711/22538] | Loss: 0.1869 | Accuracy: 0.9474\n","Epoch [2/2] | Step [20712/22538] | Loss: 0.3136 | Accuracy: 0.9267\n","Epoch [2/2] | Step [20713/22538] | Loss: 0.2434 | Accuracy: 0.9255\n","Epoch [2/2] | Step [20714/22538] | Loss: 0.5574 | Accuracy: 0.8597\n","Epoch [2/2] | Step [20715/22538] | Loss: 0.3062 | Accuracy: 0.9263\n","Epoch [2/2] | Step [20716/22538] | Loss: 0.3667 | Accuracy: 0.9045\n","Epoch [2/2] | Step [20717/22538] | Loss: 0.3135 | Accuracy: 0.9198\n","Epoch [2/2] | Step [20718/22538] | Loss: 0.2826 | Accuracy: 0.9368\n","Epoch [2/2] | Step [20719/22538] | Loss: 0.2968 | Accuracy: 0.9275\n","Epoch [2/2] | Step [20720/22538] | Loss: 0.2565 | Accuracy: 0.9312\n","Epoch [2/2] | Step [20721/22538] | Loss: 0.4665 | Accuracy: 0.8818\n","Epoch [2/2] | Step [20722/22538] | Loss: 0.1949 | Accuracy: 0.9437\n","Epoch [2/2] | Step [20723/22538] | Loss: 0.4098 | Accuracy: 0.8873\n","Epoch [2/2] | Step [20724/22538] | Loss: 0.3068 | Accuracy: 0.9013\n","Epoch [2/2] | Step [20725/22538] | Loss: 0.4028 | Accuracy: 0.8939\n","Epoch [2/2] | Step [20726/22538] | Loss: 0.2783 | Accuracy: 0.9100\n","Epoch [2/2] | Step [20727/22538] | Loss: 0.3038 | Accuracy: 0.9129\n","Epoch [2/2] | Step [20728/22538] | Loss: 0.3156 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20729/22538] | Loss: 0.4146 | Accuracy: 0.9049\n","Epoch [2/2] | Step [20730/22538] | Loss: 0.3824 | Accuracy: 0.9133\n","Epoch [2/2] | Step [20731/22538] | Loss: 0.2559 | Accuracy: 0.9122\n","Epoch [2/2] | Step [20732/22538] | Loss: 0.3456 | Accuracy: 0.8846\n","Epoch [2/2] | Step [20733/22538] | Loss: 0.4320 | Accuracy: 0.9014\n","Epoch [2/2] | Step [20734/22538] | Loss: 0.4251 | Accuracy: 0.8837\n","Epoch [2/2] | Step [20735/22538] | Loss: 0.4493 | Accuracy: 0.8661\n","Epoch [2/2] | Step [20736/22538] | Loss: 0.2745 | Accuracy: 0.9187\n","Epoch [2/2] | Step [20737/22538] | Loss: 0.4491 | Accuracy: 0.8962\n","Epoch [2/2] | Step [20738/22538] | Loss: 0.3915 | Accuracy: 0.8817\n","Epoch [2/2] | Step [20739/22538] | Loss: 0.3001 | Accuracy: 0.9322\n","Epoch [2/2] | Step [20740/22538] | Loss: 0.3444 | Accuracy: 0.8996\n","Epoch [2/2] | Step [20741/22538] | Loss: 0.4504 | Accuracy: 0.8897\n","Epoch [2/2] | Step [20742/22538] | Loss: 0.2625 | Accuracy: 0.9226\n","Epoch [2/2] | Step [20743/22538] | Loss: 0.3834 | Accuracy: 0.9022\n","Epoch [2/2] | Step [20744/22538] | Loss: 0.3121 | Accuracy: 0.9310\n","Epoch [2/2] | Step [20745/22538] | Loss: 0.2746 | Accuracy: 0.9173\n","Epoch [2/2] | Step [20746/22538] | Loss: 0.2276 | Accuracy: 0.9343\n","Epoch [2/2] | Step [20747/22538] | Loss: 0.3558 | Accuracy: 0.8937\n","Epoch [2/2] | Step [20748/22538] | Loss: 0.3163 | Accuracy: 0.9174\n","Epoch [2/2] | Step [20749/22538] | Loss: 0.3299 | Accuracy: 0.9367\n","Epoch [2/2] | Step [20750/22538] | Loss: 0.2837 | Accuracy: 0.9158\n","Epoch [2/2] | Step [20751/22538] | Loss: 0.3690 | Accuracy: 0.8839\n","Epoch [2/2] | Step [20752/22538] | Loss: 0.3645 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20753/22538] | Loss: 0.3015 | Accuracy: 0.9314\n","Epoch [2/2] | Step [20754/22538] | Loss: 0.4632 | Accuracy: 0.8841\n","Epoch [2/2] | Step [20755/22538] | Loss: 0.2269 | Accuracy: 0.9293\n","Epoch [2/2] | Step [20756/22538] | Loss: 0.1514 | Accuracy: 0.9558\n","Epoch [2/2] | Step [20757/22538] | Loss: 0.2835 | Accuracy: 0.9293\n","Epoch [2/2] | Step [20758/22538] | Loss: 0.5060 | Accuracy: 0.8780\n","Epoch [2/2] | Step [20759/22538] | Loss: 0.4301 | Accuracy: 0.8722\n","Epoch [2/2] | Step [20760/22538] | Loss: 0.4590 | Accuracy: 0.8932\n","Epoch [2/2] | Step [20761/22538] | Loss: 0.2669 | Accuracy: 0.9181\n","Epoch [2/2] | Step [20762/22538] | Loss: 0.2240 | Accuracy: 0.9337\n","Epoch [2/2] | Step [20763/22538] | Loss: 0.2248 | Accuracy: 0.9397\n","Epoch [2/2] | Step [20764/22538] | Loss: 0.3453 | Accuracy: 0.8975\n","Epoch [2/2] | Step [20765/22538] | Loss: 0.4699 | Accuracy: 0.8875\n","Epoch [2/2] | Step [20766/22538] | Loss: 0.2533 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20767/22538] | Loss: 0.3557 | Accuracy: 0.9125\n","Epoch [2/2] | Step [20768/22538] | Loss: 0.2908 | Accuracy: 0.9025\n","Epoch [2/2] | Step [20769/22538] | Loss: 0.2354 | Accuracy: 0.9414\n","Epoch [2/2] | Step [20770/22538] | Loss: 0.4004 | Accuracy: 0.9071\n","Epoch [2/2] | Step [20771/22538] | Loss: 0.3874 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20772/22538] | Loss: 0.3603 | Accuracy: 0.9146\n","Epoch [2/2] | Step [20773/22538] | Loss: 0.4924 | Accuracy: 0.8333\n","Epoch [2/2] | Step [20774/22538] | Loss: 0.3981 | Accuracy: 0.9023\n","Epoch [2/2] | Step [20775/22538] | Loss: 0.2869 | Accuracy: 0.9131\n","Epoch [2/2] | Step [20776/22538] | Loss: 0.3252 | Accuracy: 0.9104\n","Epoch [2/2] | Step [20777/22538] | Loss: 0.2540 | Accuracy: 0.9315\n","Epoch [2/2] | Step [20778/22538] | Loss: 0.2975 | Accuracy: 0.9286\n","Epoch [2/2] | Step [20779/22538] | Loss: 0.2856 | Accuracy: 0.9223\n","Epoch [2/2] | Step [20780/22538] | Loss: 0.1915 | Accuracy: 0.9497\n","Epoch [2/2] | Step [20781/22538] | Loss: 0.2817 | Accuracy: 0.9148\n","Epoch [2/2] | Step [20782/22538] | Loss: 0.3207 | Accuracy: 0.8973\n","Epoch [2/2] | Step [20783/22538] | Loss: 0.2171 | Accuracy: 0.9407\n","Epoch [2/2] | Step [20784/22538] | Loss: 0.4713 | Accuracy: 0.8726\n","Epoch [2/2] | Step [20785/22538] | Loss: 0.2995 | Accuracy: 0.9152\n","Epoch [2/2] | Step [20786/22538] | Loss: 0.5145 | Accuracy: 0.8705\n","Epoch [2/2] | Step [20787/22538] | Loss: 0.2701 | Accuracy: 0.9187\n","Epoch [2/2] | Step [20788/22538] | Loss: 0.2554 | Accuracy: 0.9198\n","Epoch [2/2] | Step [20789/22538] | Loss: 0.2673 | Accuracy: 0.9221\n","Epoch [2/2] | Step [20790/22538] | Loss: 0.4019 | Accuracy: 0.9025\n","Epoch [2/2] | Step [20791/22538] | Loss: 0.3646 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20792/22538] | Loss: 0.2947 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20793/22538] | Loss: 0.3863 | Accuracy: 0.9007\n","Epoch [2/2] | Step [20794/22538] | Loss: 0.3191 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20795/22538] | Loss: 0.3139 | Accuracy: 0.8942\n","Epoch [2/2] | Step [20796/22538] | Loss: 0.3379 | Accuracy: 0.9116\n","Epoch [2/2] | Step [20797/22538] | Loss: 0.2757 | Accuracy: 0.9122\n","Epoch [2/2] | Step [20798/22538] | Loss: 0.2474 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20799/22538] | Loss: 0.3203 | Accuracy: 0.9214\n","Epoch [2/2] | Step [20800/22538] | Loss: 0.2153 | Accuracy: 0.9474\n","Epoch [2/2] | Step [20801/22538] | Loss: 0.6624 | Accuracy: 0.8393\n","Epoch [2/2] | Step [20802/22538] | Loss: 0.4961 | Accuracy: 0.8631\n","Epoch [2/2] | Step [20803/22538] | Loss: 0.4029 | Accuracy: 0.8818\n","Epoch [2/2] | Step [20804/22538] | Loss: 0.4738 | Accuracy: 0.8844\n","Epoch [2/2] | Step [20805/22538] | Loss: 0.3347 | Accuracy: 0.8979\n","Epoch [2/2] | Step [20806/22538] | Loss: 0.2005 | Accuracy: 0.9515\n","Epoch [2/2] | Step [20807/22538] | Loss: 0.2769 | Accuracy: 0.9229\n","Epoch [2/2] | Step [20808/22538] | Loss: 0.3512 | Accuracy: 0.8971\n","Epoch [2/2] | Step [20809/22538] | Loss: 0.3399 | Accuracy: 0.8988\n","Epoch [2/2] | Step [20810/22538] | Loss: 0.3092 | Accuracy: 0.9050\n","Epoch [2/2] | Step [20811/22538] | Loss: 0.5018 | Accuracy: 0.8750\n","Epoch [2/2] | Step [20812/22538] | Loss: 0.3223 | Accuracy: 0.9085\n","Epoch [2/2] | Step [20813/22538] | Loss: 0.2895 | Accuracy: 0.9089\n","Epoch [2/2] | Step [20814/22538] | Loss: 0.2998 | Accuracy: 0.9298\n","Epoch [2/2] | Step [20815/22538] | Loss: 0.3226 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20816/22538] | Loss: 0.2386 | Accuracy: 0.9428\n","Epoch [2/2] | Step [20817/22538] | Loss: 0.3127 | Accuracy: 0.9019\n","Epoch [2/2] | Step [20818/22538] | Loss: 0.2793 | Accuracy: 0.9318\n","Epoch [2/2] | Step [20819/22538] | Loss: 0.3198 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20820/22538] | Loss: 0.4985 | Accuracy: 0.8523\n","Epoch [2/2] | Step [20821/22538] | Loss: 0.3118 | Accuracy: 0.9093\n","Epoch [2/2] | Step [20822/22538] | Loss: 0.3472 | Accuracy: 0.9118\n","Epoch [2/2] | Step [20823/22538] | Loss: 0.2622 | Accuracy: 0.9207\n","Epoch [2/2] | Step [20824/22538] | Loss: 0.2755 | Accuracy: 0.9229\n","Epoch [2/2] | Step [20825/22538] | Loss: 0.2442 | Accuracy: 0.9338\n","Epoch [2/2] | Step [20826/22538] | Loss: 0.2172 | Accuracy: 0.9308\n","Epoch [2/2] | Step [20827/22538] | Loss: 0.3671 | Accuracy: 0.9010\n","Epoch [2/2] | Step [20828/22538] | Loss: 0.3985 | Accuracy: 0.8949\n","Epoch [2/2] | Step [20829/22538] | Loss: 0.3585 | Accuracy: 0.8984\n","Epoch [2/2] | Step [20830/22538] | Loss: 0.4224 | Accuracy: 0.8869\n","Epoch [2/2] | Step [20831/22538] | Loss: 0.2518 | Accuracy: 0.9253\n","Epoch [2/2] | Step [20832/22538] | Loss: 0.3260 | Accuracy: 0.9012\n","Epoch [2/2] | Step [20833/22538] | Loss: 0.2028 | Accuracy: 0.9442\n","Epoch [2/2] | Step [20834/22538] | Loss: 0.4501 | Accuracy: 0.8618\n","Epoch [2/2] | Step [20835/22538] | Loss: 0.1819 | Accuracy: 0.9508\n","Epoch [2/2] | Step [20836/22538] | Loss: 0.3529 | Accuracy: 0.8951\n","Epoch [2/2] | Step [20837/22538] | Loss: 0.2846 | Accuracy: 0.9125\n","Epoch [2/2] | Step [20838/22538] | Loss: 0.2584 | Accuracy: 0.9355\n","Epoch [2/2] | Step [20839/22538] | Loss: 0.3707 | Accuracy: 0.8892\n","Epoch [2/2] | Step [20840/22538] | Loss: 0.3751 | Accuracy: 0.9030\n","Epoch [2/2] | Step [20841/22538] | Loss: 0.1696 | Accuracy: 0.9425\n","Epoch [2/2] | Step [20842/22538] | Loss: 0.2765 | Accuracy: 0.9216\n","Epoch [2/2] | Step [20843/22538] | Loss: 0.3277 | Accuracy: 0.9082\n","Epoch [2/2] | Step [20844/22538] | Loss: 0.3359 | Accuracy: 0.8979\n","Epoch [2/2] | Step [20845/22538] | Loss: 0.2839 | Accuracy: 0.9193\n","Epoch [2/2] | Step [20846/22538] | Loss: 0.1946 | Accuracy: 0.9430\n","Epoch [2/2] | Step [20847/22538] | Loss: 0.3807 | Accuracy: 0.9153\n","Epoch [2/2] | Step [20848/22538] | Loss: 0.3211 | Accuracy: 0.9104\n","Epoch [2/2] | Step [20849/22538] | Loss: 0.5097 | Accuracy: 0.8590\n","Epoch [2/2] | Step [20850/22538] | Loss: 0.3555 | Accuracy: 0.9104\n","Epoch [2/2] | Step [20851/22538] | Loss: 0.2281 | Accuracy: 0.9358\n","Epoch [2/2] | Step [20852/22538] | Loss: 0.3056 | Accuracy: 0.9213\n","Epoch [2/2] | Step [20853/22538] | Loss: 0.3194 | Accuracy: 0.9131\n","Epoch [2/2] | Step [20854/22538] | Loss: 0.2919 | Accuracy: 0.9263\n","Epoch [2/2] | Step [20855/22538] | Loss: 0.3446 | Accuracy: 0.9184\n","Epoch [2/2] | Step [20856/22538] | Loss: 0.3500 | Accuracy: 0.9089\n","Epoch [2/2] | Step [20857/22538] | Loss: 0.3807 | Accuracy: 0.9062\n","Epoch [2/2] | Step [20858/22538] | Loss: 0.2205 | Accuracy: 0.9303\n","Epoch [2/2] | Step [20859/22538] | Loss: 0.3595 | Accuracy: 0.8937\n","Epoch [2/2] | Step [20860/22538] | Loss: 0.3465 | Accuracy: 0.8939\n","Epoch [2/2] | Step [20861/22538] | Loss: 0.2731 | Accuracy: 0.9421\n","Epoch [2/2] | Step [20862/22538] | Loss: 0.2573 | Accuracy: 0.9226\n","Epoch [2/2] | Step [20863/22538] | Loss: 0.4597 | Accuracy: 0.8615\n","Epoch [2/2] | Step [20864/22538] | Loss: 0.5347 | Accuracy: 0.8642\n","Epoch [2/2] | Step [20865/22538] | Loss: 0.2640 | Accuracy: 0.9255\n","Epoch [2/2] | Step [20866/22538] | Loss: 0.1949 | Accuracy: 0.9448\n","Epoch [2/2] | Step [20867/22538] | Loss: 0.3225 | Accuracy: 0.9100\n","Epoch [2/2] | Step [20868/22538] | Loss: 0.2495 | Accuracy: 0.9340\n","Epoch [2/2] | Step [20869/22538] | Loss: 0.3460 | Accuracy: 0.8906\n","Epoch [2/2] | Step [20870/22538] | Loss: 0.3175 | Accuracy: 0.8861\n","Epoch [2/2] | Step [20871/22538] | Loss: 0.3432 | Accuracy: 0.8899\n","Epoch [2/2] | Step [20872/22538] | Loss: 0.3113 | Accuracy: 0.9266\n","Epoch [2/2] | Step [20873/22538] | Loss: 0.4511 | Accuracy: 0.8806\n","Epoch [2/2] | Step [20874/22538] | Loss: 0.2783 | Accuracy: 0.9118\n","Epoch [2/2] | Step [20875/22538] | Loss: 0.2918 | Accuracy: 0.9091\n","Epoch [2/2] | Step [20876/22538] | Loss: 0.4258 | Accuracy: 0.8861\n","Epoch [2/2] | Step [20877/22538] | Loss: 0.2110 | Accuracy: 0.9398\n","Epoch [2/2] | Step [20878/22538] | Loss: 0.3388 | Accuracy: 0.9153\n","Epoch [2/2] | Step [20879/22538] | Loss: 0.3573 | Accuracy: 0.9139\n","Epoch [2/2] | Step [20880/22538] | Loss: 0.3342 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20881/22538] | Loss: 0.3540 | Accuracy: 0.9075\n","Epoch [2/2] | Step [20882/22538] | Loss: 0.2445 | Accuracy: 0.9303\n","Epoch [2/2] | Step [20883/22538] | Loss: 0.4006 | Accuracy: 0.9013\n","Epoch [2/2] | Step [20884/22538] | Loss: 0.2399 | Accuracy: 0.9308\n","Epoch [2/2] | Step [20885/22538] | Loss: 0.3043 | Accuracy: 0.9160\n","Epoch [2/2] | Step [20886/22538] | Loss: 0.3210 | Accuracy: 0.9085\n","Epoch [2/2] | Step [20887/22538] | Loss: 0.2899 | Accuracy: 0.9097\n","Epoch [2/2] | Step [20888/22538] | Loss: 0.6808 | Accuracy: 0.8258\n","Epoch [2/2] | Step [20889/22538] | Loss: 0.2460 | Accuracy: 0.9343\n","Epoch [2/2] | Step [20890/22538] | Loss: 0.3295 | Accuracy: 0.9048\n","Epoch [2/2] | Step [20891/22538] | Loss: 0.1789 | Accuracy: 0.9531\n","Epoch [2/2] | Step [20892/22538] | Loss: 0.1982 | Accuracy: 0.9391\n","Epoch [2/2] | Step [20893/22538] | Loss: 0.3172 | Accuracy: 0.9142\n","Epoch [2/2] | Step [20894/22538] | Loss: 0.2405 | Accuracy: 0.9283\n","Epoch [2/2] | Step [20895/22538] | Loss: 0.4226 | Accuracy: 0.8789\n","Epoch [2/2] | Step [20896/22538] | Loss: 0.2967 | Accuracy: 0.9213\n","Epoch [2/2] | Step [20897/22538] | Loss: 0.2898 | Accuracy: 0.9191\n","Epoch [2/2] | Step [20898/22538] | Loss: 0.2683 | Accuracy: 0.9325\n","Epoch [2/2] | Step [20899/22538] | Loss: 0.3726 | Accuracy: 0.9077\n","Epoch [2/2] | Step [20900/22538] | Loss: 0.3472 | Accuracy: 0.9057\n","Epoch [2/2] | Step [20901/22538] | Loss: 0.2407 | Accuracy: 0.9176\n","Epoch [2/2] | Step [20902/22538] | Loss: 0.3844 | Accuracy: 0.8775\n","Epoch [2/2] | Step [20903/22538] | Loss: 0.4002 | Accuracy: 0.8952\n","Epoch [2/2] | Step [20904/22538] | Loss: 0.3215 | Accuracy: 0.9116\n","Epoch [2/2] | Step [20905/22538] | Loss: 0.3241 | Accuracy: 0.9149\n","Epoch [2/2] | Step [20906/22538] | Loss: 0.2618 | Accuracy: 0.9123\n","Epoch [2/2] | Step [20907/22538] | Loss: 0.2482 | Accuracy: 0.9393\n","Epoch [2/2] | Step [20908/22538] | Loss: 0.3890 | Accuracy: 0.9004\n","Epoch [2/2] | Step [20909/22538] | Loss: 0.3416 | Accuracy: 0.9242\n","Epoch [2/2] | Step [20910/22538] | Loss: 0.3787 | Accuracy: 0.8892\n","Epoch [2/2] | Step [20911/22538] | Loss: 0.2648 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20912/22538] | Loss: 0.4498 | Accuracy: 0.8817\n","Epoch [2/2] | Step [20913/22538] | Loss: 0.2966 | Accuracy: 0.9223\n","Epoch [2/2] | Step [20914/22538] | Loss: 0.3262 | Accuracy: 0.9095\n","Epoch [2/2] | Step [20915/22538] | Loss: 0.3725 | Accuracy: 0.8799\n","Epoch [2/2] | Step [20916/22538] | Loss: 0.2615 | Accuracy: 0.9211\n","Epoch [2/2] | Step [20917/22538] | Loss: 0.3056 | Accuracy: 0.9114\n","Epoch [2/2] | Step [20918/22538] | Loss: 0.3184 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20919/22538] | Loss: 0.2626 | Accuracy: 0.9194\n","Epoch [2/2] | Step [20920/22538] | Loss: 0.3608 | Accuracy: 0.8979\n","Epoch [2/2] | Step [20921/22538] | Loss: 0.4368 | Accuracy: 0.8815\n","Epoch [2/2] | Step [20922/22538] | Loss: 0.2871 | Accuracy: 0.9155\n","Epoch [2/2] | Step [20923/22538] | Loss: 0.3908 | Accuracy: 0.8992\n","Epoch [2/2] | Step [20924/22538] | Loss: 0.2875 | Accuracy: 0.9192\n","Epoch [2/2] | Step [20925/22538] | Loss: 0.3392 | Accuracy: 0.9036\n","Epoch [2/2] | Step [20926/22538] | Loss: 0.2453 | Accuracy: 0.9336\n","Epoch [2/2] | Step [20927/22538] | Loss: 0.2327 | Accuracy: 0.9131\n","Epoch [2/2] | Step [20928/22538] | Loss: 0.3534 | Accuracy: 0.8977\n","Epoch [2/2] | Step [20929/22538] | Loss: 0.3665 | Accuracy: 0.8750\n","Epoch [2/2] | Step [20930/22538] | Loss: 0.3533 | Accuracy: 0.8873\n","Epoch [2/2] | Step [20931/22538] | Loss: 0.3147 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20932/22538] | Loss: 0.4292 | Accuracy: 0.8932\n","Epoch [2/2] | Step [20933/22538] | Loss: 0.3536 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20934/22538] | Loss: 0.3816 | Accuracy: 0.8884\n","Epoch [2/2] | Step [20935/22538] | Loss: 0.3769 | Accuracy: 0.9041\n","Epoch [2/2] | Step [20936/22538] | Loss: 0.2318 | Accuracy: 0.9293\n","Epoch [2/2] | Step [20937/22538] | Loss: 0.2872 | Accuracy: 0.9266\n","Epoch [2/2] | Step [20938/22538] | Loss: 0.2855 | Accuracy: 0.9213\n","Epoch [2/2] | Step [20939/22538] | Loss: 0.3996 | Accuracy: 0.8830\n","Epoch [2/2] | Step [20940/22538] | Loss: 0.2975 | Accuracy: 0.9205\n","Epoch [2/2] | Step [20941/22538] | Loss: 0.4944 | Accuracy: 0.8884\n","Epoch [2/2] | Step [20942/22538] | Loss: 0.2880 | Accuracy: 0.9155\n","Epoch [2/2] | Step [20943/22538] | Loss: 0.4112 | Accuracy: 0.8828\n","Epoch [2/2] | Step [20944/22538] | Loss: 0.1926 | Accuracy: 0.9429\n","Epoch [2/2] | Step [20945/22538] | Loss: 0.2591 | Accuracy: 0.9273\n","Epoch [2/2] | Step [20946/22538] | Loss: 0.3366 | Accuracy: 0.9049\n","Epoch [2/2] | Step [20947/22538] | Loss: 0.4043 | Accuracy: 0.8913\n","Epoch [2/2] | Step [20948/22538] | Loss: 0.3972 | Accuracy: 0.8973\n","Epoch [2/2] | Step [20949/22538] | Loss: 0.3285 | Accuracy: 0.8948\n","Epoch [2/2] | Step [20950/22538] | Loss: 0.3429 | Accuracy: 0.9201\n","Epoch [2/2] | Step [20951/22538] | Loss: 0.2628 | Accuracy: 0.9297\n","Epoch [2/2] | Step [20952/22538] | Loss: 0.2589 | Accuracy: 0.9089\n","Epoch [2/2] | Step [20953/22538] | Loss: 0.3526 | Accuracy: 0.9063\n","Epoch [2/2] | Step [20954/22538] | Loss: 0.3206 | Accuracy: 0.9221\n","Epoch [2/2] | Step [20955/22538] | Loss: 0.3038 | Accuracy: 0.9073\n","Epoch [2/2] | Step [20956/22538] | Loss: 0.3451 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20957/22538] | Loss: 0.4931 | Accuracy: 0.8791\n","Epoch [2/2] | Step [20958/22538] | Loss: 0.3541 | Accuracy: 0.8991\n","Epoch [2/2] | Step [20959/22538] | Loss: 0.4474 | Accuracy: 0.8832\n","Epoch [2/2] | Step [20960/22538] | Loss: 0.2589 | Accuracy: 0.9255\n","Epoch [2/2] | Step [20961/22538] | Loss: 0.2305 | Accuracy: 0.9254\n","Epoch [2/2] | Step [20962/22538] | Loss: 0.2789 | Accuracy: 0.9195\n","Epoch [2/2] | Step [20963/22538] | Loss: 0.4859 | Accuracy: 0.8672\n","Epoch [2/2] | Step [20964/22538] | Loss: 0.3124 | Accuracy: 0.9176\n","Epoch [2/2] | Step [20965/22538] | Loss: 0.3270 | Accuracy: 0.9057\n","Epoch [2/2] | Step [20966/22538] | Loss: 0.4304 | Accuracy: 0.8727\n","Epoch [2/2] | Step [20967/22538] | Loss: 0.3115 | Accuracy: 0.9139\n","Epoch [2/2] | Step [20968/22538] | Loss: 0.3026 | Accuracy: 0.9167\n","Epoch [2/2] | Step [20969/22538] | Loss: 0.3215 | Accuracy: 0.8966\n","Epoch [2/2] | Step [20970/22538] | Loss: 0.3033 | Accuracy: 0.9235\n","Epoch [2/2] | Step [20971/22538] | Loss: 0.3370 | Accuracy: 0.9181\n","Epoch [2/2] | Step [20972/22538] | Loss: 0.3719 | Accuracy: 0.9115\n","Epoch [2/2] | Step [20973/22538] | Loss: 0.3328 | Accuracy: 0.9154\n","Epoch [2/2] | Step [20974/22538] | Loss: 0.2236 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20975/22538] | Loss: 0.3625 | Accuracy: 0.9000\n","Epoch [2/2] | Step [20976/22538] | Loss: 0.4380 | Accuracy: 0.8719\n","Epoch [2/2] | Step [20977/22538] | Loss: 0.3589 | Accuracy: 0.9235\n","Epoch [2/2] | Step [20978/22538] | Loss: 0.4929 | Accuracy: 0.8709\n","Epoch [2/2] | Step [20979/22538] | Loss: 0.4113 | Accuracy: 0.8694\n","Epoch [2/2] | Step [20980/22538] | Loss: 0.5531 | Accuracy: 0.8603\n","Epoch [2/2] | Step [20981/22538] | Loss: 0.2817 | Accuracy: 0.9306\n","Epoch [2/2] | Step [20982/22538] | Loss: 0.3628 | Accuracy: 0.9024\n","Epoch [2/2] | Step [20983/22538] | Loss: 0.4287 | Accuracy: 0.8912\n","Epoch [2/2] | Step [20984/22538] | Loss: 0.4627 | Accuracy: 0.8586\n","Epoch [2/2] | Step [20985/22538] | Loss: 0.3646 | Accuracy: 0.9020\n","Epoch [2/2] | Step [20986/22538] | Loss: 0.2864 | Accuracy: 0.9110\n","Epoch [2/2] | Step [20987/22538] | Loss: 0.2426 | Accuracy: 0.9308\n","Epoch [2/2] | Step [20988/22538] | Loss: 0.3988 | Accuracy: 0.8942\n","Epoch [2/2] | Step [20989/22538] | Loss: 0.2853 | Accuracy: 0.9186\n","Epoch [2/2] | Step [20990/22538] | Loss: 0.2195 | Accuracy: 0.9313\n","Epoch [2/2] | Step [20991/22538] | Loss: 0.2837 | Accuracy: 0.9160\n","Epoch [2/2] | Step [20992/22538] | Loss: 0.2903 | Accuracy: 0.9202\n","Epoch [2/2] | Step [20993/22538] | Loss: 0.3851 | Accuracy: 0.8947\n","Epoch [2/2] | Step [20994/22538] | Loss: 0.2179 | Accuracy: 0.9375\n","Epoch [2/2] | Step [20995/22538] | Loss: 0.1985 | Accuracy: 0.9451\n","Epoch [2/2] | Step [20996/22538] | Loss: 0.4258 | Accuracy: 0.8901\n","Epoch [2/2] | Step [20997/22538] | Loss: 0.2832 | Accuracy: 0.9011\n","Epoch [2/2] | Step [20998/22538] | Loss: 0.1533 | Accuracy: 0.9432\n","Epoch [2/2] | Step [20999/22538] | Loss: 0.2444 | Accuracy: 0.9301\n","Epoch [2/2] | Step [21000/22538] | Loss: 0.2497 | Accuracy: 0.9185\n","Epoch [2/2] | Step [21001/22538] | Loss: 0.2629 | Accuracy: 0.9180\n","Epoch [2/2] | Step [21002/22538] | Loss: 0.3210 | Accuracy: 0.9182\n","Epoch [2/2] | Step [21003/22538] | Loss: 0.3229 | Accuracy: 0.9208\n","Epoch [2/2] | Step [21004/22538] | Loss: 0.2589 | Accuracy: 0.9235\n","Epoch [2/2] | Step [21005/22538] | Loss: 0.3996 | Accuracy: 0.8958\n","Epoch [2/2] | Step [21006/22538] | Loss: 0.4400 | Accuracy: 0.8843\n","Epoch [2/2] | Step [21007/22538] | Loss: 0.4444 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21008/22538] | Loss: 0.4432 | Accuracy: 0.8931\n","Epoch [2/2] | Step [21009/22538] | Loss: 0.2353 | Accuracy: 0.9122\n","Epoch [2/2] | Step [21010/22538] | Loss: 0.3472 | Accuracy: 0.9051\n","Epoch [2/2] | Step [21011/22538] | Loss: 0.3648 | Accuracy: 0.8889\n","Epoch [2/2] | Step [21012/22538] | Loss: 0.3968 | Accuracy: 0.8777\n","Epoch [2/2] | Step [21013/22538] | Loss: 0.5686 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21014/22538] | Loss: 0.2714 | Accuracy: 0.9238\n","Epoch [2/2] | Step [21015/22538] | Loss: 0.4502 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21016/22538] | Loss: 0.3123 | Accuracy: 0.9111\n","Epoch [2/2] | Step [21017/22538] | Loss: 0.3388 | Accuracy: 0.8990\n","Epoch [2/2] | Step [21018/22538] | Loss: 0.3465 | Accuracy: 0.9093\n","Epoch [2/2] | Step [21019/22538] | Loss: 0.2905 | Accuracy: 0.9123\n","Epoch [2/2] | Step [21020/22538] | Loss: 0.3595 | Accuracy: 0.8879\n","Epoch [2/2] | Step [21021/22538] | Loss: 0.2290 | Accuracy: 0.9365\n","Epoch [2/2] | Step [21022/22538] | Loss: 0.2591 | Accuracy: 0.9235\n","Epoch [2/2] | Step [21023/22538] | Loss: 0.3182 | Accuracy: 0.9056\n","Epoch [2/2] | Step [21024/22538] | Loss: 0.3640 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21025/22538] | Loss: 0.3361 | Accuracy: 0.9114\n","Epoch [2/2] | Step [21026/22538] | Loss: 0.2891 | Accuracy: 0.9216\n","Epoch [2/2] | Step [21027/22538] | Loss: 0.3637 | Accuracy: 0.8940\n","Epoch [2/2] | Step [21028/22538] | Loss: 0.4736 | Accuracy: 0.8777\n","Epoch [2/2] | Step [21029/22538] | Loss: 0.3284 | Accuracy: 0.9151\n","Epoch [2/2] | Step [21030/22538] | Loss: 0.3185 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21031/22538] | Loss: 0.3302 | Accuracy: 0.8986\n","Epoch [2/2] | Step [21032/22538] | Loss: 0.2668 | Accuracy: 0.9227\n","Epoch [2/2] | Step [21033/22538] | Loss: 0.3190 | Accuracy: 0.9177\n","Epoch [2/2] | Step [21034/22538] | Loss: 0.2175 | Accuracy: 0.9289\n","Epoch [2/2] | Step [21035/22538] | Loss: 0.3854 | Accuracy: 0.8984\n","Epoch [2/2] | Step [21036/22538] | Loss: 0.2772 | Accuracy: 0.9033\n","Epoch [2/2] | Step [21037/22538] | Loss: 0.3825 | Accuracy: 0.8969\n","Epoch [2/2] | Step [21038/22538] | Loss: 0.3080 | Accuracy: 0.9189\n","Epoch [2/2] | Step [21039/22538] | Loss: 0.2600 | Accuracy: 0.9035\n","Epoch [2/2] | Step [21040/22538] | Loss: 0.3768 | Accuracy: 0.9018\n","Epoch [2/2] | Step [21041/22538] | Loss: 0.2628 | Accuracy: 0.9224\n","Epoch [2/2] | Step [21042/22538] | Loss: 0.3095 | Accuracy: 0.9076\n","Epoch [2/2] | Step [21043/22538] | Loss: 0.3113 | Accuracy: 0.9054\n","Epoch [2/2] | Step [21044/22538] | Loss: 0.2992 | Accuracy: 0.8904\n","Epoch [2/2] | Step [21045/22538] | Loss: 0.4799 | Accuracy: 0.8611\n","Epoch [2/2] | Step [21046/22538] | Loss: 0.3252 | Accuracy: 0.9146\n","Epoch [2/2] | Step [21047/22538] | Loss: 0.2228 | Accuracy: 0.9442\n","Epoch [2/2] | Step [21048/22538] | Loss: 0.2786 | Accuracy: 0.9088\n","Epoch [2/2] | Step [21049/22538] | Loss: 0.2511 | Accuracy: 0.9213\n","Epoch [2/2] | Step [21050/22538] | Loss: 0.3726 | Accuracy: 0.9139\n","Epoch [2/2] | Step [21051/22538] | Loss: 0.3251 | Accuracy: 0.9075\n","Epoch [2/2] | Step [21052/22538] | Loss: 0.3580 | Accuracy: 0.9006\n","Epoch [2/2] | Step [21053/22538] | Loss: 0.2217 | Accuracy: 0.9321\n","Epoch [2/2] | Step [21054/22538] | Loss: 0.3086 | Accuracy: 0.9052\n","Epoch [2/2] | Step [21055/22538] | Loss: 0.3180 | Accuracy: 0.9142\n","Epoch [2/2] | Step [21056/22538] | Loss: 0.4316 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21057/22538] | Loss: 0.3195 | Accuracy: 0.9099\n","Epoch [2/2] | Step [21058/22538] | Loss: 0.3760 | Accuracy: 0.8897\n","Epoch [2/2] | Step [21059/22538] | Loss: 0.2068 | Accuracy: 0.9385\n","Epoch [2/2] | Step [21060/22538] | Loss: 0.3138 | Accuracy: 0.9187\n","Epoch [2/2] | Step [21061/22538] | Loss: 0.4266 | Accuracy: 0.8942\n","Epoch [2/2] | Step [21062/22538] | Loss: 0.3139 | Accuracy: 0.9040\n","Epoch [2/2] | Step [21063/22538] | Loss: 0.3859 | Accuracy: 0.9025\n","Epoch [2/2] | Step [21064/22538] | Loss: 0.3126 | Accuracy: 0.9004\n","Epoch [2/2] | Step [21065/22538] | Loss: 0.2826 | Accuracy: 0.9267\n","Epoch [2/2] | Step [21066/22538] | Loss: 0.3826 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21067/22538] | Loss: 0.3899 | Accuracy: 0.9110\n","Epoch [2/2] | Step [21068/22538] | Loss: 0.2155 | Accuracy: 0.9365\n","Epoch [2/2] | Step [21069/22538] | Loss: 0.2386 | Accuracy: 0.9282\n","Epoch [2/2] | Step [21070/22538] | Loss: 0.2648 | Accuracy: 0.9270\n","Epoch [2/2] | Step [21071/22538] | Loss: 0.3712 | Accuracy: 0.8984\n","Epoch [2/2] | Step [21072/22538] | Loss: 0.4148 | Accuracy: 0.8923\n","Epoch [2/2] | Step [21073/22538] | Loss: 0.3739 | Accuracy: 0.9081\n","Epoch [2/2] | Step [21074/22538] | Loss: 0.4359 | Accuracy: 0.8537\n","Epoch [2/2] | Step [21075/22538] | Loss: 0.2334 | Accuracy: 0.9320\n","Epoch [2/2] | Step [21076/22538] | Loss: 0.3086 | Accuracy: 0.9079\n","Epoch [2/2] | Step [21077/22538] | Loss: 0.2127 | Accuracy: 0.9484\n","Epoch [2/2] | Step [21078/22538] | Loss: 0.2870 | Accuracy: 0.9272\n","Epoch [2/2] | Step [21079/22538] | Loss: 0.3680 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21080/22538] | Loss: 0.2801 | Accuracy: 0.9148\n","Epoch [2/2] | Step [21081/22538] | Loss: 0.3019 | Accuracy: 0.9265\n","Epoch [2/2] | Step [21082/22538] | Loss: 0.2818 | Accuracy: 0.9127\n","Epoch [2/2] | Step [21083/22538] | Loss: 0.3811 | Accuracy: 0.8848\n","Epoch [2/2] | Step [21084/22538] | Loss: 0.4166 | Accuracy: 0.9018\n","Epoch [2/2] | Step [21085/22538] | Loss: 0.2048 | Accuracy: 0.9415\n","Epoch [2/2] | Step [21086/22538] | Loss: 0.3517 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21087/22538] | Loss: 0.2436 | Accuracy: 0.9205\n","Epoch [2/2] | Step [21088/22538] | Loss: 0.2820 | Accuracy: 0.9241\n","Epoch [2/2] | Step [21089/22538] | Loss: 0.3752 | Accuracy: 0.8830\n","Epoch [2/2] | Step [21090/22538] | Loss: 0.2413 | Accuracy: 0.9331\n","Epoch [2/2] | Step [21091/22538] | Loss: 0.2509 | Accuracy: 0.9262\n","Epoch [2/2] | Step [21092/22538] | Loss: 0.2929 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21093/22538] | Loss: 0.2158 | Accuracy: 0.9342\n","Epoch [2/2] | Step [21094/22538] | Loss: 0.3465 | Accuracy: 0.8950\n","Epoch [2/2] | Step [21095/22538] | Loss: 0.2628 | Accuracy: 0.9315\n","Epoch [2/2] | Step [21096/22538] | Loss: 0.3959 | Accuracy: 0.8869\n","Epoch [2/2] | Step [21097/22538] | Loss: 0.3014 | Accuracy: 0.9091\n","Epoch [2/2] | Step [21098/22538] | Loss: 0.3817 | Accuracy: 0.9073\n","Epoch [2/2] | Step [21099/22538] | Loss: 0.2712 | Accuracy: 0.9216\n","Epoch [2/2] | Step [21100/22538] | Loss: 0.2848 | Accuracy: 0.9375\n","Epoch [2/2] | Step [21101/22538] | Loss: 0.3358 | Accuracy: 0.9028\n","Epoch [2/2] | Step [21102/22538] | Loss: 0.3672 | Accuracy: 0.9011\n","Epoch [2/2] | Step [21103/22538] | Loss: 0.3805 | Accuracy: 0.9083\n","Epoch [2/2] | Step [21104/22538] | Loss: 0.4473 | Accuracy: 0.8906\n","Epoch [2/2] | Step [21105/22538] | Loss: 0.2808 | Accuracy: 0.9216\n","Epoch [2/2] | Step [21106/22538] | Loss: 0.2377 | Accuracy: 0.9271\n","Epoch [2/2] | Step [21107/22538] | Loss: 0.3648 | Accuracy: 0.9058\n","Epoch [2/2] | Step [21108/22538] | Loss: 0.2296 | Accuracy: 0.9160\n","Epoch [2/2] | Step [21109/22538] | Loss: 0.1950 | Accuracy: 0.9441\n","Epoch [2/2] | Step [21110/22538] | Loss: 0.2277 | Accuracy: 0.9161\n","Epoch [2/2] | Step [21111/22538] | Loss: 0.3752 | Accuracy: 0.8990\n","Epoch [2/2] | Step [21112/22538] | Loss: 0.3313 | Accuracy: 0.9142\n","Epoch [2/2] | Step [21113/22538] | Loss: 0.4706 | Accuracy: 0.8851\n","Epoch [2/2] | Step [21114/22538] | Loss: 0.2574 | Accuracy: 0.9335\n","Epoch [2/2] | Step [21115/22538] | Loss: 0.2284 | Accuracy: 0.9283\n","Epoch [2/2] | Step [21116/22538] | Loss: 0.2809 | Accuracy: 0.9258\n","Epoch [2/2] | Step [21117/22538] | Loss: 0.3602 | Accuracy: 0.8919\n","Epoch [2/2] | Step [21118/22538] | Loss: 0.3008 | Accuracy: 0.9213\n","Epoch [2/2] | Step [21119/22538] | Loss: 0.3275 | Accuracy: 0.9010\n","Epoch [2/2] | Step [21120/22538] | Loss: 0.3082 | Accuracy: 0.9269\n","Epoch [2/2] | Step [21121/22538] | Loss: 0.3233 | Accuracy: 0.9186\n","Epoch [2/2] | Step [21122/22538] | Loss: 0.3661 | Accuracy: 0.8920\n","Epoch [2/2] | Step [21123/22538] | Loss: 0.2459 | Accuracy: 0.9269\n","Epoch [2/2] | Step [21124/22538] | Loss: 0.2600 | Accuracy: 0.9242\n","Epoch [2/2] | Step [21125/22538] | Loss: 0.4179 | Accuracy: 0.8640\n","Epoch [2/2] | Step [21126/22538] | Loss: 0.3736 | Accuracy: 0.8962\n","Epoch [2/2] | Step [21127/22538] | Loss: 0.2554 | Accuracy: 0.9145\n","Epoch [2/2] | Step [21128/22538] | Loss: 0.2528 | Accuracy: 0.9219\n","Epoch [2/2] | Step [21129/22538] | Loss: 0.3861 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21130/22538] | Loss: 0.3680 | Accuracy: 0.8892\n","Epoch [2/2] | Step [21131/22538] | Loss: 0.2980 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21132/22538] | Loss: 0.4229 | Accuracy: 0.8993\n","Epoch [2/2] | Step [21133/22538] | Loss: 0.1920 | Accuracy: 0.9478\n","Epoch [2/2] | Step [21134/22538] | Loss: 0.3372 | Accuracy: 0.9055\n","Epoch [2/2] | Step [21135/22538] | Loss: 0.3920 | Accuracy: 0.8815\n","Epoch [2/2] | Step [21136/22538] | Loss: 0.3975 | Accuracy: 0.8808\n","Epoch [2/2] | Step [21137/22538] | Loss: 0.3177 | Accuracy: 0.9130\n","Epoch [2/2] | Step [21138/22538] | Loss: 0.3107 | Accuracy: 0.9071\n","Epoch [2/2] | Step [21139/22538] | Loss: 0.2102 | Accuracy: 0.9427\n","Epoch [2/2] | Step [21140/22538] | Loss: 0.3650 | Accuracy: 0.9045\n","Epoch [2/2] | Step [21141/22538] | Loss: 0.1731 | Accuracy: 0.9493\n","Epoch [2/2] | Step [21142/22538] | Loss: 0.3275 | Accuracy: 0.8926\n","Epoch [2/2] | Step [21143/22538] | Loss: 0.2299 | Accuracy: 0.9330\n","Epoch [2/2] | Step [21144/22538] | Loss: 0.2313 | Accuracy: 0.9420\n","Epoch [2/2] | Step [21145/22538] | Loss: 0.4246 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21146/22538] | Loss: 0.1740 | Accuracy: 0.9529\n","Epoch [2/2] | Step [21147/22538] | Loss: 0.3330 | Accuracy: 0.8977\n","Epoch [2/2] | Step [21148/22538] | Loss: 0.3847 | Accuracy: 0.9068\n","Epoch [2/2] | Step [21149/22538] | Loss: 0.2649 | Accuracy: 0.9289\n","Epoch [2/2] | Step [21150/22538] | Loss: 0.3327 | Accuracy: 0.9160\n","Epoch [2/2] | Step [21151/22538] | Loss: 0.4030 | Accuracy: 0.8958\n","Epoch [2/2] | Step [21152/22538] | Loss: 0.3696 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21153/22538] | Loss: 0.4090 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21154/22538] | Loss: 0.2680 | Accuracy: 0.9246\n","Epoch [2/2] | Step [21155/22538] | Loss: 0.4355 | Accuracy: 0.8771\n","Epoch [2/2] | Step [21156/22538] | Loss: 0.2968 | Accuracy: 0.9238\n","Epoch [2/2] | Step [21157/22538] | Loss: 0.3193 | Accuracy: 0.9205\n","Epoch [2/2] | Step [21158/22538] | Loss: 0.3007 | Accuracy: 0.9183\n","Epoch [2/2] | Step [21159/22538] | Loss: 0.3376 | Accuracy: 0.8989\n","Epoch [2/2] | Step [21160/22538] | Loss: 0.3844 | Accuracy: 0.8958\n","Epoch [2/2] | Step [21161/22538] | Loss: 0.3394 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21162/22538] | Loss: 0.3556 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21163/22538] | Loss: 0.4581 | Accuracy: 0.8824\n","Epoch [2/2] | Step [21164/22538] | Loss: 0.1914 | Accuracy: 0.9427\n","Epoch [2/2] | Step [21165/22538] | Loss: 0.3228 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21166/22538] | Loss: 0.3222 | Accuracy: 0.9077\n","Epoch [2/2] | Step [21167/22538] | Loss: 0.2798 | Accuracy: 0.9207\n","Epoch [2/2] | Step [21168/22538] | Loss: 0.2730 | Accuracy: 0.9192\n","Epoch [2/2] | Step [21169/22538] | Loss: 0.3793 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21170/22538] | Loss: 0.3237 | Accuracy: 0.8832\n","Epoch [2/2] | Step [21171/22538] | Loss: 0.3919 | Accuracy: 0.9021\n","Epoch [2/2] | Step [21172/22538] | Loss: 0.1840 | Accuracy: 0.9414\n","Epoch [2/2] | Step [21173/22538] | Loss: 0.2258 | Accuracy: 0.9430\n","Epoch [2/2] | Step [21174/22538] | Loss: 0.3350 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21175/22538] | Loss: 0.5009 | Accuracy: 0.8611\n","Epoch [2/2] | Step [21176/22538] | Loss: 0.2779 | Accuracy: 0.9233\n","Epoch [2/2] | Step [21177/22538] | Loss: 0.5478 | Accuracy: 0.8720\n","Epoch [2/2] | Step [21178/22538] | Loss: 0.3287 | Accuracy: 0.9256\n","Epoch [2/2] | Step [21179/22538] | Loss: 0.2474 | Accuracy: 0.9214\n","Epoch [2/2] | Step [21180/22538] | Loss: 0.2907 | Accuracy: 0.9247\n","Epoch [2/2] | Step [21181/22538] | Loss: 0.2527 | Accuracy: 0.9345\n","Epoch [2/2] | Step [21182/22538] | Loss: 0.4338 | Accuracy: 0.8901\n","Epoch [2/2] | Step [21183/22538] | Loss: 0.2279 | Accuracy: 0.9298\n","Epoch [2/2] | Step [21184/22538] | Loss: 0.2200 | Accuracy: 0.9368\n","Epoch [2/2] | Step [21185/22538] | Loss: 0.2935 | Accuracy: 0.9004\n","Epoch [2/2] | Step [21186/22538] | Loss: 0.2519 | Accuracy: 0.9241\n","Epoch [2/2] | Step [21187/22538] | Loss: 0.3067 | Accuracy: 0.9273\n","Epoch [2/2] | Step [21188/22538] | Loss: 0.4298 | Accuracy: 0.8810\n","Epoch [2/2] | Step [21189/22538] | Loss: 0.2982 | Accuracy: 0.9068\n","Epoch [2/2] | Step [21190/22538] | Loss: 0.5507 | Accuracy: 0.8696\n","Epoch [2/2] | Step [21191/22538] | Loss: 0.3316 | Accuracy: 0.9005\n","Epoch [2/2] | Step [21192/22538] | Loss: 0.2465 | Accuracy: 0.9340\n","Epoch [2/2] | Step [21193/22538] | Loss: 0.2664 | Accuracy: 0.9343\n","Epoch [2/2] | Step [21194/22538] | Loss: 0.2447 | Accuracy: 0.9304\n","Epoch [2/2] | Step [21195/22538] | Loss: 0.2793 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21196/22538] | Loss: 0.2937 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21197/22538] | Loss: 0.3553 | Accuracy: 0.8825\n","Epoch [2/2] | Step [21198/22538] | Loss: 0.2981 | Accuracy: 0.9183\n","Epoch [2/2] | Step [21199/22538] | Loss: 0.2376 | Accuracy: 0.9316\n","Epoch [2/2] | Step [21200/22538] | Loss: 0.2568 | Accuracy: 0.9196\n","Epoch [2/2] | Step [21201/22538] | Loss: 0.2153 | Accuracy: 0.9363\n","Epoch [2/2] | Step [21202/22538] | Loss: 0.3468 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21203/22538] | Loss: 0.3324 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21204/22538] | Loss: 0.3949 | Accuracy: 0.9114\n","Epoch [2/2] | Step [21205/22538] | Loss: 0.1895 | Accuracy: 0.9531\n","Epoch [2/2] | Step [21206/22538] | Loss: 0.3337 | Accuracy: 0.9051\n","Epoch [2/2] | Step [21207/22538] | Loss: 0.3166 | Accuracy: 0.9112\n","Epoch [2/2] | Step [21208/22538] | Loss: 0.2575 | Accuracy: 0.9239\n","Epoch [2/2] | Step [21209/22538] | Loss: 0.1666 | Accuracy: 0.9531\n","Epoch [2/2] | Step [21210/22538] | Loss: 0.3543 | Accuracy: 0.8973\n","Epoch [2/2] | Step [21211/22538] | Loss: 0.3536 | Accuracy: 0.8903\n","Epoch [2/2] | Step [21212/22538] | Loss: 0.3998 | Accuracy: 0.8790\n","Epoch [2/2] | Step [21213/22538] | Loss: 0.3202 | Accuracy: 0.8993\n","Epoch [2/2] | Step [21214/22538] | Loss: 0.2678 | Accuracy: 0.9250\n","Epoch [2/2] | Step [21215/22538] | Loss: 0.2646 | Accuracy: 0.9194\n","Epoch [2/2] | Step [21216/22538] | Loss: 0.3688 | Accuracy: 0.9018\n","Epoch [2/2] | Step [21217/22538] | Loss: 0.3288 | Accuracy: 0.9159\n","Epoch [2/2] | Step [21218/22538] | Loss: 0.3535 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21219/22538] | Loss: 0.2918 | Accuracy: 0.9044\n","Epoch [2/2] | Step [21220/22538] | Loss: 0.2660 | Accuracy: 0.9254\n","Epoch [2/2] | Step [21221/22538] | Loss: 0.2150 | Accuracy: 0.9318\n","Epoch [2/2] | Step [21222/22538] | Loss: 0.2844 | Accuracy: 0.9231\n","Epoch [2/2] | Step [21223/22538] | Loss: 0.2292 | Accuracy: 0.9276\n","Epoch [2/2] | Step [21224/22538] | Loss: 0.2921 | Accuracy: 0.9419\n","Epoch [2/2] | Step [21225/22538] | Loss: 0.3279 | Accuracy: 0.9139\n","Epoch [2/2] | Step [21226/22538] | Loss: 0.3264 | Accuracy: 0.9125\n","Epoch [2/2] | Step [21227/22538] | Loss: 0.3350 | Accuracy: 0.9161\n","Epoch [2/2] | Step [21228/22538] | Loss: 0.2905 | Accuracy: 0.9231\n","Epoch [2/2] | Step [21229/22538] | Loss: 0.3549 | Accuracy: 0.8879\n","Epoch [2/2] | Step [21230/22538] | Loss: 0.3127 | Accuracy: 0.9050\n","Epoch [2/2] | Step [21231/22538] | Loss: 0.3481 | Accuracy: 0.8963\n","Epoch [2/2] | Step [21232/22538] | Loss: 0.3239 | Accuracy: 0.8983\n","Epoch [2/2] | Step [21233/22538] | Loss: 0.3002 | Accuracy: 0.9260\n","Epoch [2/2] | Step [21234/22538] | Loss: 0.2886 | Accuracy: 0.9052\n","Epoch [2/2] | Step [21235/22538] | Loss: 0.2883 | Accuracy: 0.9068\n","Epoch [2/2] | Step [21236/22538] | Loss: 0.3267 | Accuracy: 0.9131\n","Epoch [2/2] | Step [21237/22538] | Loss: 0.3414 | Accuracy: 0.9198\n","Epoch [2/2] | Step [21238/22538] | Loss: 0.3746 | Accuracy: 0.9033\n","Epoch [2/2] | Step [21239/22538] | Loss: 0.2879 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21240/22538] | Loss: 0.4351 | Accuracy: 0.8723\n","Epoch [2/2] | Step [21241/22538] | Loss: 0.3399 | Accuracy: 0.9205\n","Epoch [2/2] | Step [21242/22538] | Loss: 0.3036 | Accuracy: 0.9231\n","Epoch [2/2] | Step [21243/22538] | Loss: 0.2110 | Accuracy: 0.9276\n","Epoch [2/2] | Step [21244/22538] | Loss: 0.3722 | Accuracy: 0.8981\n","Epoch [2/2] | Step [21245/22538] | Loss: 0.5200 | Accuracy: 0.8639\n","Epoch [2/2] | Step [21246/22538] | Loss: 0.3524 | Accuracy: 0.8981\n","Epoch [2/2] | Step [21247/22538] | Loss: 0.3306 | Accuracy: 0.8886\n","Epoch [2/2] | Step [21248/22538] | Loss: 0.3536 | Accuracy: 0.9146\n","Epoch [2/2] | Step [21249/22538] | Loss: 0.4851 | Accuracy: 0.8686\n","Epoch [2/2] | Step [21250/22538] | Loss: 0.2870 | Accuracy: 0.9159\n","Epoch [2/2] | Step [21251/22538] | Loss: 0.2223 | Accuracy: 0.9360\n","Epoch [2/2] | Step [21252/22538] | Loss: 0.3988 | Accuracy: 0.9008\n","Epoch [2/2] | Step [21253/22538] | Loss: 0.3797 | Accuracy: 0.9042\n","Epoch [2/2] | Step [21254/22538] | Loss: 0.2278 | Accuracy: 0.9284\n","Epoch [2/2] | Step [21255/22538] | Loss: 0.3510 | Accuracy: 0.8839\n","Epoch [2/2] | Step [21256/22538] | Loss: 0.3084 | Accuracy: 0.9041\n","Epoch [2/2] | Step [21257/22538] | Loss: 0.3768 | Accuracy: 0.9058\n","Epoch [2/2] | Step [21258/22538] | Loss: 0.3810 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21259/22538] | Loss: 0.2662 | Accuracy: 0.9120\n","Epoch [2/2] | Step [21260/22538] | Loss: 0.2856 | Accuracy: 0.9308\n","Epoch [2/2] | Step [21261/22538] | Loss: 0.3116 | Accuracy: 0.9129\n","Epoch [2/2] | Step [21262/22538] | Loss: 0.3341 | Accuracy: 0.9080\n","Epoch [2/2] | Step [21263/22538] | Loss: 0.3268 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21264/22538] | Loss: 0.4595 | Accuracy: 0.9034\n","Epoch [2/2] | Step [21265/22538] | Loss: 0.3344 | Accuracy: 0.8955\n","Epoch [2/2] | Step [21266/22538] | Loss: 0.4915 | Accuracy: 0.8721\n","Epoch [2/2] | Step [21267/22538] | Loss: 0.3591 | Accuracy: 0.8923\n","Epoch [2/2] | Step [21268/22538] | Loss: 0.2752 | Accuracy: 0.9276\n","Epoch [2/2] | Step [21269/22538] | Loss: 0.3092 | Accuracy: 0.9142\n","Epoch [2/2] | Step [21270/22538] | Loss: 0.4392 | Accuracy: 0.8846\n","Epoch [2/2] | Step [21271/22538] | Loss: 0.2587 | Accuracy: 0.9269\n","Epoch [2/2] | Step [21272/22538] | Loss: 0.3257 | Accuracy: 0.8996\n","Epoch [2/2] | Step [21273/22538] | Loss: 0.4091 | Accuracy: 0.9004\n","Epoch [2/2] | Step [21274/22538] | Loss: 0.4416 | Accuracy: 0.8806\n","Epoch [2/2] | Step [21275/22538] | Loss: 0.2929 | Accuracy: 0.9182\n","Epoch [2/2] | Step [21276/22538] | Loss: 0.3405 | Accuracy: 0.9082\n","Epoch [2/2] | Step [21277/22538] | Loss: 0.4225 | Accuracy: 0.8819\n","Epoch [2/2] | Step [21278/22538] | Loss: 0.4571 | Accuracy: 0.8831\n","Epoch [2/2] | Step [21279/22538] | Loss: 0.3059 | Accuracy: 0.9213\n","Epoch [2/2] | Step [21280/22538] | Loss: 0.3926 | Accuracy: 0.8975\n","Epoch [2/2] | Step [21281/22538] | Loss: 0.2758 | Accuracy: 0.9223\n","Epoch [2/2] | Step [21282/22538] | Loss: 0.4465 | Accuracy: 0.8779\n","Epoch [2/2] | Step [21283/22538] | Loss: 0.1856 | Accuracy: 0.9457\n","Epoch [2/2] | Step [21284/22538] | Loss: 0.3959 | Accuracy: 0.8843\n","Epoch [2/2] | Step [21285/22538] | Loss: 0.3179 | Accuracy: 0.9030\n","Epoch [2/2] | Step [21286/22538] | Loss: 0.3107 | Accuracy: 0.9130\n","Epoch [2/2] | Step [21287/22538] | Loss: 0.4523 | Accuracy: 0.8821\n","Epoch [2/2] | Step [21288/22538] | Loss: 0.2499 | Accuracy: 0.9258\n","Epoch [2/2] | Step [21289/22538] | Loss: 0.2674 | Accuracy: 0.9189\n","Epoch [2/2] | Step [21290/22538] | Loss: 0.3342 | Accuracy: 0.9087\n","Epoch [2/2] | Step [21291/22538] | Loss: 0.3167 | Accuracy: 0.9199\n","Epoch [2/2] | Step [21292/22538] | Loss: 0.3232 | Accuracy: 0.9127\n","Epoch [2/2] | Step [21293/22538] | Loss: 0.2567 | Accuracy: 0.9174\n","Epoch [2/2] | Step [21294/22538] | Loss: 0.3306 | Accuracy: 0.9100\n","Epoch [2/2] | Step [21295/22538] | Loss: 0.2750 | Accuracy: 0.9283\n","Epoch [2/2] | Step [21296/22538] | Loss: 0.3399 | Accuracy: 0.9087\n","Epoch [2/2] | Step [21297/22538] | Loss: 0.4583 | Accuracy: 0.8693\n","Epoch [2/2] | Step [21298/22538] | Loss: 0.3901 | Accuracy: 0.8720\n","Epoch [2/2] | Step [21299/22538] | Loss: 0.3207 | Accuracy: 0.9121\n","Epoch [2/2] | Step [21300/22538] | Loss: 0.2745 | Accuracy: 0.9229\n","Epoch [2/2] | Step [21301/22538] | Loss: 0.3196 | Accuracy: 0.9021\n","Epoch [2/2] | Step [21302/22538] | Loss: 0.3655 | Accuracy: 0.8980\n","Epoch [2/2] | Step [21303/22538] | Loss: 0.3163 | Accuracy: 0.8980\n","Epoch [2/2] | Step [21304/22538] | Loss: 0.4762 | Accuracy: 0.8924\n","Epoch [2/2] | Step [21305/22538] | Loss: 0.2309 | Accuracy: 0.9286\n","Epoch [2/2] | Step [21306/22538] | Loss: 0.3517 | Accuracy: 0.8977\n","Epoch [2/2] | Step [21307/22538] | Loss: 0.3167 | Accuracy: 0.9118\n","Epoch [2/2] | Step [21308/22538] | Loss: 0.3194 | Accuracy: 0.9127\n","Epoch [2/2] | Step [21309/22538] | Loss: 0.2223 | Accuracy: 0.9260\n","Epoch [2/2] | Step [21310/22538] | Loss: 0.3715 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21311/22538] | Loss: 0.3127 | Accuracy: 0.9161\n","Epoch [2/2] | Step [21312/22538] | Loss: 0.3197 | Accuracy: 0.9028\n","Epoch [2/2] | Step [21313/22538] | Loss: 0.5161 | Accuracy: 0.8693\n","Epoch [2/2] | Step [21314/22538] | Loss: 0.3994 | Accuracy: 0.8935\n","Epoch [2/2] | Step [21315/22538] | Loss: 0.3209 | Accuracy: 0.9087\n","Epoch [2/2] | Step [21316/22538] | Loss: 0.3769 | Accuracy: 0.8813\n","Epoch [2/2] | Step [21317/22538] | Loss: 0.2901 | Accuracy: 0.9189\n","Epoch [2/2] | Step [21318/22538] | Loss: 0.2995 | Accuracy: 0.9095\n","Epoch [2/2] | Step [21319/22538] | Loss: 0.2974 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21320/22538] | Loss: 0.3243 | Accuracy: 0.9191\n","Epoch [2/2] | Step [21321/22538] | Loss: 0.3608 | Accuracy: 0.8777\n","Epoch [2/2] | Step [21322/22538] | Loss: 0.4551 | Accuracy: 0.8646\n","Epoch [2/2] | Step [21323/22538] | Loss: 0.3098 | Accuracy: 0.9145\n","Epoch [2/2] | Step [21324/22538] | Loss: 0.3652 | Accuracy: 0.8915\n","Epoch [2/2] | Step [21325/22538] | Loss: 0.2536 | Accuracy: 0.9375\n","Epoch [2/2] | Step [21326/22538] | Loss: 0.4043 | Accuracy: 0.9017\n","Epoch [2/2] | Step [21327/22538] | Loss: 0.2523 | Accuracy: 0.9293\n","Epoch [2/2] | Step [21328/22538] | Loss: 0.4015 | Accuracy: 0.8790\n","Epoch [2/2] | Step [21329/22538] | Loss: 0.3596 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21330/22538] | Loss: 0.3129 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21331/22538] | Loss: 0.3898 | Accuracy: 0.8996\n","Epoch [2/2] | Step [21332/22538] | Loss: 0.4200 | Accuracy: 0.8925\n","Epoch [2/2] | Step [21333/22538] | Loss: 0.3016 | Accuracy: 0.9176\n","Epoch [2/2] | Step [21334/22538] | Loss: 0.3332 | Accuracy: 0.9120\n","Epoch [2/2] | Step [21335/22538] | Loss: 0.3486 | Accuracy: 0.8935\n","Epoch [2/2] | Step [21336/22538] | Loss: 0.3776 | Accuracy: 0.9009\n","Epoch [2/2] | Step [21337/22538] | Loss: 0.3116 | Accuracy: 0.9243\n","Epoch [2/2] | Step [21338/22538] | Loss: 0.2682 | Accuracy: 0.9275\n","Epoch [2/2] | Step [21339/22538] | Loss: 0.3511 | Accuracy: 0.9243\n","Epoch [2/2] | Step [21340/22538] | Loss: 0.3274 | Accuracy: 0.9240\n","Epoch [2/2] | Step [21341/22538] | Loss: 0.3217 | Accuracy: 0.9089\n","Epoch [2/2] | Step [21342/22538] | Loss: 0.2076 | Accuracy: 0.9357\n","Epoch [2/2] | Step [21343/22538] | Loss: 0.4068 | Accuracy: 0.8994\n","Epoch [2/2] | Step [21344/22538] | Loss: 0.3808 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21345/22538] | Loss: 0.3778 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21346/22538] | Loss: 0.2598 | Accuracy: 0.9268\n","Epoch [2/2] | Step [21347/22538] | Loss: 0.4207 | Accuracy: 0.9028\n","Epoch [2/2] | Step [21348/22538] | Loss: 0.3972 | Accuracy: 0.8993\n","Epoch [2/2] | Step [21349/22538] | Loss: 0.2211 | Accuracy: 0.9473\n","Epoch [2/2] | Step [21350/22538] | Loss: 0.3105 | Accuracy: 0.9215\n","Epoch [2/2] | Step [21351/22538] | Loss: 0.3590 | Accuracy: 0.8935\n","Epoch [2/2] | Step [21352/22538] | Loss: 0.3798 | Accuracy: 0.8995\n","Epoch [2/2] | Step [21353/22538] | Loss: 0.2325 | Accuracy: 0.9286\n","Epoch [2/2] | Step [21354/22538] | Loss: 0.3614 | Accuracy: 0.8869\n","Epoch [2/2] | Step [21355/22538] | Loss: 0.4301 | Accuracy: 0.8798\n","Epoch [2/2] | Step [21356/22538] | Loss: 0.4546 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21357/22538] | Loss: 0.5265 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21358/22538] | Loss: 0.3053 | Accuracy: 0.9181\n","Epoch [2/2] | Step [21359/22538] | Loss: 0.4043 | Accuracy: 0.8897\n","Epoch [2/2] | Step [21360/22538] | Loss: 0.3746 | Accuracy: 0.8795\n","Epoch [2/2] | Step [21361/22538] | Loss: 0.2532 | Accuracy: 0.9181\n","Epoch [2/2] | Step [21362/22538] | Loss: 0.1705 | Accuracy: 0.9497\n","Epoch [2/2] | Step [21363/22538] | Loss: 0.2361 | Accuracy: 0.9320\n","Epoch [2/2] | Step [21364/22538] | Loss: 0.3566 | Accuracy: 0.9075\n","Epoch [2/2] | Step [21365/22538] | Loss: 0.2226 | Accuracy: 0.9267\n","Epoch [2/2] | Step [21366/22538] | Loss: 0.2447 | Accuracy: 0.9219\n","Epoch [2/2] | Step [21367/22538] | Loss: 0.3420 | Accuracy: 0.9153\n","Epoch [2/2] | Step [21368/22538] | Loss: 0.3366 | Accuracy: 0.9054\n","Epoch [2/2] | Step [21369/22538] | Loss: 0.3951 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21370/22538] | Loss: 0.3180 | Accuracy: 0.9082\n","Epoch [2/2] | Step [21371/22538] | Loss: 0.2911 | Accuracy: 0.9116\n","Epoch [2/2] | Step [21372/22538] | Loss: 0.3204 | Accuracy: 0.9213\n","Epoch [2/2] | Step [21373/22538] | Loss: 0.3102 | Accuracy: 0.9303\n","Epoch [2/2] | Step [21374/22538] | Loss: 0.2871 | Accuracy: 0.9127\n","Epoch [2/2] | Step [21375/22538] | Loss: 0.2323 | Accuracy: 0.9278\n","Epoch [2/2] | Step [21376/22538] | Loss: 0.3660 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21377/22538] | Loss: 0.3524 | Accuracy: 0.9089\n","Epoch [2/2] | Step [21378/22538] | Loss: 0.3237 | Accuracy: 0.9125\n","Epoch [2/2] | Step [21379/22538] | Loss: 0.2526 | Accuracy: 0.9226\n","Epoch [2/2] | Step [21380/22538] | Loss: 0.3003 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21381/22538] | Loss: 0.3054 | Accuracy: 0.9133\n","Epoch [2/2] | Step [21382/22538] | Loss: 0.2795 | Accuracy: 0.9194\n","Epoch [2/2] | Step [21383/22538] | Loss: 0.3218 | Accuracy: 0.9327\n","Epoch [2/2] | Step [21384/22538] | Loss: 0.4272 | Accuracy: 0.8958\n","Epoch [2/2] | Step [21385/22538] | Loss: 0.2556 | Accuracy: 0.9227\n","Epoch [2/2] | Step [21386/22538] | Loss: 0.3383 | Accuracy: 0.9127\n","Epoch [2/2] | Step [21387/22538] | Loss: 0.2229 | Accuracy: 0.9408\n","Epoch [2/2] | Step [21388/22538] | Loss: 0.4480 | Accuracy: 0.8859\n","Epoch [2/2] | Step [21389/22538] | Loss: 0.2940 | Accuracy: 0.9150\n","Epoch [2/2] | Step [21390/22538] | Loss: 0.2239 | Accuracy: 0.9513\n","Epoch [2/2] | Step [21391/22538] | Loss: 0.4249 | Accuracy: 0.8875\n","Epoch [2/2] | Step [21392/22538] | Loss: 0.1947 | Accuracy: 0.9454\n","Epoch [2/2] | Step [21393/22538] | Loss: 0.3792 | Accuracy: 0.9069\n","Epoch [2/2] | Step [21394/22538] | Loss: 0.2491 | Accuracy: 0.9291\n","Epoch [2/2] | Step [21395/22538] | Loss: 0.3039 | Accuracy: 0.9035\n","Epoch [2/2] | Step [21396/22538] | Loss: 0.2877 | Accuracy: 0.9219\n","Epoch [2/2] | Step [21397/22538] | Loss: 0.2236 | Accuracy: 0.9398\n","Epoch [2/2] | Step [21398/22538] | Loss: 0.3458 | Accuracy: 0.8832\n","Epoch [2/2] | Step [21399/22538] | Loss: 0.1943 | Accuracy: 0.9457\n","Epoch [2/2] | Step [21400/22538] | Loss: 0.2663 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21401/22538] | Loss: 0.3079 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21402/22538] | Loss: 0.3841 | Accuracy: 0.9149\n","Epoch [2/2] | Step [21403/22538] | Loss: 0.3246 | Accuracy: 0.8935\n","Epoch [2/2] | Step [21404/22538] | Loss: 0.2236 | Accuracy: 0.9325\n","Epoch [2/2] | Step [21405/22538] | Loss: 0.4676 | Accuracy: 0.8862\n","Epoch [2/2] | Step [21406/22538] | Loss: 0.3573 | Accuracy: 0.9018\n","Epoch [2/2] | Step [21407/22538] | Loss: 0.4555 | Accuracy: 0.8778\n","Epoch [2/2] | Step [21408/22538] | Loss: 0.3347 | Accuracy: 0.8972\n","Epoch [2/2] | Step [21409/22538] | Loss: 0.2294 | Accuracy: 0.9304\n","Epoch [2/2] | Step [21410/22538] | Loss: 0.2465 | Accuracy: 0.9280\n","Epoch [2/2] | Step [21411/22538] | Loss: 0.3094 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21412/22538] | Loss: 0.2873 | Accuracy: 0.9191\n","Epoch [2/2] | Step [21413/22538] | Loss: 0.3820 | Accuracy: 0.8906\n","Epoch [2/2] | Step [21414/22538] | Loss: 0.3050 | Accuracy: 0.9191\n","Epoch [2/2] | Step [21415/22538] | Loss: 0.4584 | Accuracy: 0.8676\n","Epoch [2/2] | Step [21416/22538] | Loss: 0.4151 | Accuracy: 0.8775\n","Epoch [2/2] | Step [21417/22538] | Loss: 0.2544 | Accuracy: 0.9286\n","Epoch [2/2] | Step [21418/22538] | Loss: 0.3415 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21419/22538] | Loss: 0.2776 | Accuracy: 0.9269\n","Epoch [2/2] | Step [21420/22538] | Loss: 0.4537 | Accuracy: 0.8933\n","Epoch [2/2] | Step [21421/22538] | Loss: 0.2823 | Accuracy: 0.9078\n","Epoch [2/2] | Step [21422/22538] | Loss: 0.3123 | Accuracy: 0.9052\n","Epoch [2/2] | Step [21423/22538] | Loss: 0.4474 | Accuracy: 0.8944\n","Epoch [2/2] | Step [21424/22538] | Loss: 0.3234 | Accuracy: 0.9279\n","Epoch [2/2] | Step [21425/22538] | Loss: 0.2836 | Accuracy: 0.9228\n","Epoch [2/2] | Step [21426/22538] | Loss: 0.3226 | Accuracy: 0.9153\n","Epoch [2/2] | Step [21427/22538] | Loss: 0.2016 | Accuracy: 0.9486\n","Epoch [2/2] | Step [21428/22538] | Loss: 0.3328 | Accuracy: 0.8995\n","Epoch [2/2] | Step [21429/22538] | Loss: 0.3142 | Accuracy: 0.9225\n","Epoch [2/2] | Step [21430/22538] | Loss: 0.3195 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21431/22538] | Loss: 0.3387 | Accuracy: 0.9083\n","Epoch [2/2] | Step [21432/22538] | Loss: 0.3673 | Accuracy: 0.8859\n","Epoch [2/2] | Step [21433/22538] | Loss: 0.2625 | Accuracy: 0.9183\n","Epoch [2/2] | Step [21434/22538] | Loss: 0.2392 | Accuracy: 0.9327\n","Epoch [2/2] | Step [21435/22538] | Loss: 0.3281 | Accuracy: 0.8955\n","Epoch [2/2] | Step [21436/22538] | Loss: 0.3784 | Accuracy: 0.8947\n","Epoch [2/2] | Step [21437/22538] | Loss: 0.2885 | Accuracy: 0.9265\n","Epoch [2/2] | Step [21438/22538] | Loss: 0.4614 | Accuracy: 0.8806\n","Epoch [2/2] | Step [21439/22538] | Loss: 0.4338 | Accuracy: 0.8802\n","Epoch [2/2] | Step [21440/22538] | Loss: 0.3456 | Accuracy: 0.8990\n","Epoch [2/2] | Step [21441/22538] | Loss: 0.3668 | Accuracy: 0.8953\n","Epoch [2/2] | Step [21442/22538] | Loss: 0.3519 | Accuracy: 0.9104\n","Epoch [2/2] | Step [21443/22538] | Loss: 0.3204 | Accuracy: 0.8953\n","Epoch [2/2] | Step [21444/22538] | Loss: 0.2811 | Accuracy: 0.9148\n","Epoch [2/2] | Step [21445/22538] | Loss: 0.2904 | Accuracy: 0.9315\n","Epoch [2/2] | Step [21446/22538] | Loss: 0.2571 | Accuracy: 0.9143\n","Epoch [2/2] | Step [21447/22538] | Loss: 0.1927 | Accuracy: 0.9383\n","Epoch [2/2] | Step [21448/22538] | Loss: 0.2487 | Accuracy: 0.9367\n","Epoch [2/2] | Step [21449/22538] | Loss: 0.2926 | Accuracy: 0.9279\n","Epoch [2/2] | Step [21450/22538] | Loss: 0.3585 | Accuracy: 0.9004\n","Epoch [2/2] | Step [21451/22538] | Loss: 0.2454 | Accuracy: 0.9340\n","Epoch [2/2] | Step [21452/22538] | Loss: 0.2451 | Accuracy: 0.9295\n","Epoch [2/2] | Step [21453/22538] | Loss: 0.3278 | Accuracy: 0.8910\n","Epoch [2/2] | Step [21454/22538] | Loss: 0.2703 | Accuracy: 0.9292\n","Epoch [2/2] | Step [21455/22538] | Loss: 0.3534 | Accuracy: 0.9022\n","Epoch [2/2] | Step [21456/22538] | Loss: 0.2730 | Accuracy: 0.9063\n","Epoch [2/2] | Step [21457/22538] | Loss: 0.4283 | Accuracy: 0.8698\n","Epoch [2/2] | Step [21458/22538] | Loss: 0.5181 | Accuracy: 0.8775\n","Epoch [2/2] | Step [21459/22538] | Loss: 0.5670 | Accuracy: 0.8825\n","Epoch [2/2] | Step [21460/22538] | Loss: 0.1758 | Accuracy: 0.9455\n","Epoch [2/2] | Step [21461/22538] | Loss: 0.3249 | Accuracy: 0.9030\n","Epoch [2/2] | Step [21462/22538] | Loss: 0.4625 | Accuracy: 0.8773\n","Epoch [2/2] | Step [21463/22538] | Loss: 0.2344 | Accuracy: 0.9368\n","Epoch [2/2] | Step [21464/22538] | Loss: 0.4009 | Accuracy: 0.8995\n","Epoch [2/2] | Step [21465/22538] | Loss: 0.3638 | Accuracy: 0.9076\n","Epoch [2/2] | Step [21466/22538] | Loss: 0.2163 | Accuracy: 0.9394\n","Epoch [2/2] | Step [21467/22538] | Loss: 0.2850 | Accuracy: 0.9173\n","Epoch [2/2] | Step [21468/22538] | Loss: 0.4276 | Accuracy: 0.8802\n","Epoch [2/2] | Step [21469/22538] | Loss: 0.3469 | Accuracy: 0.8992\n","Epoch [2/2] | Step [21470/22538] | Loss: 0.4093 | Accuracy: 0.8889\n","Epoch [2/2] | Step [21471/22538] | Loss: 0.3396 | Accuracy: 0.9104\n","Epoch [2/2] | Step [21472/22538] | Loss: 0.3116 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21473/22538] | Loss: 0.3032 | Accuracy: 0.9176\n","Epoch [2/2] | Step [21474/22538] | Loss: 0.2505 | Accuracy: 0.9301\n","Epoch [2/2] | Step [21475/22538] | Loss: 0.1800 | Accuracy: 0.9456\n","Epoch [2/2] | Step [21476/22538] | Loss: 0.2553 | Accuracy: 0.9391\n","Epoch [2/2] | Step [21477/22538] | Loss: 0.3902 | Accuracy: 0.9052\n","Epoch [2/2] | Step [21478/22538] | Loss: 0.2708 | Accuracy: 0.9332\n","Epoch [2/2] | Step [21479/22538] | Loss: 0.3010 | Accuracy: 0.9142\n","Epoch [2/2] | Step [21480/22538] | Loss: 0.3129 | Accuracy: 0.9309\n","Epoch [2/2] | Step [21481/22538] | Loss: 0.3533 | Accuracy: 0.9099\n","Epoch [2/2] | Step [21482/22538] | Loss: 0.3389 | Accuracy: 0.8983\n","Epoch [2/2] | Step [21483/22538] | Loss: 0.3111 | Accuracy: 0.9021\n","Epoch [2/2] | Step [21484/22538] | Loss: 0.3121 | Accuracy: 0.9044\n","Epoch [2/2] | Step [21485/22538] | Loss: 0.3952 | Accuracy: 0.8992\n","Epoch [2/2] | Step [21486/22538] | Loss: 0.3319 | Accuracy: 0.9073\n","Epoch [2/2] | Step [21487/22538] | Loss: 0.2368 | Accuracy: 0.9283\n","Epoch [2/2] | Step [21488/22538] | Loss: 0.2813 | Accuracy: 0.9363\n","Epoch [2/2] | Step [21489/22538] | Loss: 0.2472 | Accuracy: 0.9203\n","Epoch [2/2] | Step [21490/22538] | Loss: 0.2799 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21491/22538] | Loss: 0.3153 | Accuracy: 0.9127\n","Epoch [2/2] | Step [21492/22538] | Loss: 0.3571 | Accuracy: 0.8873\n","Epoch [2/2] | Step [21493/22538] | Loss: 0.3199 | Accuracy: 0.9181\n","Epoch [2/2] | Step [21494/22538] | Loss: 0.2685 | Accuracy: 0.9159\n","Epoch [2/2] | Step [21495/22538] | Loss: 0.3740 | Accuracy: 0.9013\n","Epoch [2/2] | Step [21496/22538] | Loss: 0.2642 | Accuracy: 0.9324\n","Epoch [2/2] | Step [21497/22538] | Loss: 0.3080 | Accuracy: 0.9129\n","Epoch [2/2] | Step [21498/22538] | Loss: 0.2096 | Accuracy: 0.9365\n","Epoch [2/2] | Step [21499/22538] | Loss: 0.2573 | Accuracy: 0.9242\n","Epoch [2/2] | Step [21500/22538] | Loss: 0.2158 | Accuracy: 0.9418\n","Epoch [2/2] | Step [21501/22538] | Loss: 0.4498 | Accuracy: 0.8919\n","Epoch [2/2] | Step [21502/22538] | Loss: 0.3021 | Accuracy: 0.9297\n","Epoch [2/2] | Step [21503/22538] | Loss: 0.3435 | Accuracy: 0.9056\n","Epoch [2/2] | Step [21504/22538] | Loss: 0.4455 | Accuracy: 0.8828\n","Epoch [2/2] | Step [21505/22538] | Loss: 0.4305 | Accuracy: 0.9111\n","Epoch [2/2] | Step [21506/22538] | Loss: 0.2842 | Accuracy: 0.9203\n","Epoch [2/2] | Step [21507/22538] | Loss: 0.2547 | Accuracy: 0.9297\n","Epoch [2/2] | Step [21508/22538] | Loss: 0.2894 | Accuracy: 0.9110\n","Epoch [2/2] | Step [21509/22538] | Loss: 0.3421 | Accuracy: 0.8886\n","Epoch [2/2] | Step [21510/22538] | Loss: 0.2983 | Accuracy: 0.9016\n","Epoch [2/2] | Step [21511/22538] | Loss: 0.3157 | Accuracy: 0.9129\n","Epoch [2/2] | Step [21512/22538] | Loss: 0.4092 | Accuracy: 0.8947\n","Epoch [2/2] | Step [21513/22538] | Loss: 0.3104 | Accuracy: 0.9098\n","Epoch [2/2] | Step [21514/22538] | Loss: 0.3166 | Accuracy: 0.9074\n","Epoch [2/2] | Step [21515/22538] | Loss: 0.2158 | Accuracy: 0.9439\n","Epoch [2/2] | Step [21516/22538] | Loss: 0.2848 | Accuracy: 0.9229\n","Epoch [2/2] | Step [21517/22538] | Loss: 0.3260 | Accuracy: 0.9159\n","Epoch [2/2] | Step [21518/22538] | Loss: 0.2690 | Accuracy: 0.9239\n","Epoch [2/2] | Step [21519/22538] | Loss: 0.2736 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21520/22538] | Loss: 0.2824 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21521/22538] | Loss: 0.2179 | Accuracy: 0.9328\n","Epoch [2/2] | Step [21522/22538] | Loss: 0.3487 | Accuracy: 0.8973\n","Epoch [2/2] | Step [21523/22538] | Loss: 0.2425 | Accuracy: 0.9271\n","Epoch [2/2] | Step [21524/22538] | Loss: 0.3086 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21525/22538] | Loss: 0.2753 | Accuracy: 0.9253\n","Epoch [2/2] | Step [21526/22538] | Loss: 0.3027 | Accuracy: 0.9028\n","Epoch [2/2] | Step [21527/22538] | Loss: 0.2641 | Accuracy: 0.9129\n","Epoch [2/2] | Step [21528/22538] | Loss: 0.3919 | Accuracy: 0.8958\n","Epoch [2/2] | Step [21529/22538] | Loss: 0.1467 | Accuracy: 0.9574\n","Epoch [2/2] | Step [21530/22538] | Loss: 0.3423 | Accuracy: 0.9087\n","Epoch [2/2] | Step [21531/22538] | Loss: 0.2717 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21532/22538] | Loss: 0.5250 | Accuracy: 0.8701\n","Epoch [2/2] | Step [21533/22538] | Loss: 0.3369 | Accuracy: 0.8954\n","Epoch [2/2] | Step [21534/22538] | Loss: 0.4514 | Accuracy: 0.8689\n","Epoch [2/2] | Step [21535/22538] | Loss: 0.2463 | Accuracy: 0.9397\n","Epoch [2/2] | Step [21536/22538] | Loss: 0.2761 | Accuracy: 0.9250\n","Epoch [2/2] | Step [21537/22538] | Loss: 0.3567 | Accuracy: 0.8900\n","Epoch [2/2] | Step [21538/22538] | Loss: 0.2798 | Accuracy: 0.9140\n","Epoch [2/2] | Step [21539/22538] | Loss: 0.2671 | Accuracy: 0.9192\n","Epoch [2/2] | Step [21540/22538] | Loss: 0.2263 | Accuracy: 0.9367\n","Epoch [2/2] | Step [21541/22538] | Loss: 0.3323 | Accuracy: 0.9098\n","Epoch [2/2] | Step [21542/22538] | Loss: 0.3850 | Accuracy: 0.8726\n","Epoch [2/2] | Step [21543/22538] | Loss: 0.3321 | Accuracy: 0.9162\n","Epoch [2/2] | Step [21544/22538] | Loss: 0.3299 | Accuracy: 0.9196\n","Epoch [2/2] | Step [21545/22538] | Loss: 0.2516 | Accuracy: 0.9263\n","Epoch [2/2] | Step [21546/22538] | Loss: 0.2930 | Accuracy: 0.9225\n","Epoch [2/2] | Step [21547/22538] | Loss: 0.3213 | Accuracy: 0.9211\n","Epoch [2/2] | Step [21548/22538] | Loss: 0.3677 | Accuracy: 0.9104\n","Epoch [2/2] | Step [21549/22538] | Loss: 0.2853 | Accuracy: 0.9161\n","Epoch [2/2] | Step [21550/22538] | Loss: 0.4176 | Accuracy: 0.8869\n","Epoch [2/2] | Step [21551/22538] | Loss: 0.3112 | Accuracy: 0.9068\n","Epoch [2/2] | Step [21552/22538] | Loss: 0.3492 | Accuracy: 0.8945\n","Epoch [2/2] | Step [21553/22538] | Loss: 0.3138 | Accuracy: 0.9149\n","Epoch [2/2] | Step [21554/22538] | Loss: 0.6384 | Accuracy: 0.8459\n","Epoch [2/2] | Step [21555/22538] | Loss: 0.3885 | Accuracy: 0.8818\n","Epoch [2/2] | Step [21556/22538] | Loss: 0.3103 | Accuracy: 0.9121\n","Epoch [2/2] | Step [21557/22538] | Loss: 0.5039 | Accuracy: 0.8692\n","Epoch [2/2] | Step [21558/22538] | Loss: 0.3505 | Accuracy: 0.9010\n","Epoch [2/2] | Step [21559/22538] | Loss: 0.3529 | Accuracy: 0.8966\n","Epoch [2/2] | Step [21560/22538] | Loss: 0.3880 | Accuracy: 0.8931\n","Epoch [2/2] | Step [21561/22538] | Loss: 0.4141 | Accuracy: 0.8776\n","Epoch [2/2] | Step [21562/22538] | Loss: 0.3887 | Accuracy: 0.8699\n","Epoch [2/2] | Step [21563/22538] | Loss: 0.2452 | Accuracy: 0.9119\n","Epoch [2/2] | Step [21564/22538] | Loss: 0.3226 | Accuracy: 0.9093\n","Epoch [2/2] | Step [21565/22538] | Loss: 0.3532 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21566/22538] | Loss: 0.2549 | Accuracy: 0.9327\n","Epoch [2/2] | Step [21567/22538] | Loss: 0.4708 | Accuracy: 0.8605\n","Epoch [2/2] | Step [21568/22538] | Loss: 0.3892 | Accuracy: 0.8882\n","Epoch [2/2] | Step [21569/22538] | Loss: 0.2947 | Accuracy: 0.9175\n","Epoch [2/2] | Step [21570/22538] | Loss: 0.4853 | Accuracy: 0.8833\n","Epoch [2/2] | Step [21571/22538] | Loss: 0.4139 | Accuracy: 0.8889\n","Epoch [2/2] | Step [21572/22538] | Loss: 0.2958 | Accuracy: 0.9183\n","Epoch [2/2] | Step [21573/22538] | Loss: 0.4385 | Accuracy: 0.8864\n","Epoch [2/2] | Step [21574/22538] | Loss: 0.3290 | Accuracy: 0.8969\n","Epoch [2/2] | Step [21575/22538] | Loss: 0.3398 | Accuracy: 0.9082\n","Epoch [2/2] | Step [21576/22538] | Loss: 0.1752 | Accuracy: 0.9557\n","Epoch [2/2] | Step [21577/22538] | Loss: 0.3345 | Accuracy: 0.9036\n","Epoch [2/2] | Step [21578/22538] | Loss: 0.3068 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21579/22538] | Loss: 0.3099 | Accuracy: 0.8967\n","Epoch [2/2] | Step [21580/22538] | Loss: 0.3350 | Accuracy: 0.9068\n","Epoch [2/2] | Step [21581/22538] | Loss: 0.2356 | Accuracy: 0.9294\n","Epoch [2/2] | Step [21582/22538] | Loss: 0.2329 | Accuracy: 0.9247\n","Epoch [2/2] | Step [21583/22538] | Loss: 0.3082 | Accuracy: 0.9038\n","Epoch [2/2] | Step [21584/22538] | Loss: 0.2024 | Accuracy: 0.9402\n","Epoch [2/2] | Step [21585/22538] | Loss: 0.2512 | Accuracy: 0.9241\n","Epoch [2/2] | Step [21586/22538] | Loss: 0.2672 | Accuracy: 0.9201\n","Epoch [2/2] | Step [21587/22538] | Loss: 0.3777 | Accuracy: 0.8990\n","Epoch [2/2] | Step [21588/22538] | Loss: 0.2758 | Accuracy: 0.9173\n","Epoch [2/2] | Step [21589/22538] | Loss: 0.5606 | Accuracy: 0.8667\n","Epoch [2/2] | Step [21590/22538] | Loss: 0.3626 | Accuracy: 0.9046\n","Epoch [2/2] | Step [21591/22538] | Loss: 0.3227 | Accuracy: 0.9097\n","Epoch [2/2] | Step [21592/22538] | Loss: 0.3483 | Accuracy: 0.9020\n","Epoch [2/2] | Step [21593/22538] | Loss: 0.4134 | Accuracy: 0.8954\n","Epoch [2/2] | Step [21594/22538] | Loss: 0.3655 | Accuracy: 0.8984\n","Epoch [2/2] | Step [21595/22538] | Loss: 0.2597 | Accuracy: 0.9308\n","Epoch [2/2] | Step [21596/22538] | Loss: 0.3059 | Accuracy: 0.9148\n","Epoch [2/2] | Step [21597/22538] | Loss: 0.2939 | Accuracy: 0.9025\n","Epoch [2/2] | Step [21598/22538] | Loss: 0.3945 | Accuracy: 0.8906\n","Epoch [2/2] | Step [21599/22538] | Loss: 0.3156 | Accuracy: 0.9308\n","Epoch [2/2] | Step [21600/22538] | Loss: 0.2318 | Accuracy: 0.9283\n","Epoch [2/2] | Step [21601/22538] | Loss: 0.2674 | Accuracy: 0.9390\n","Epoch [2/2] | Step [21602/22538] | Loss: 0.3128 | Accuracy: 0.9025\n","Epoch [2/2] | Step [21603/22538] | Loss: 0.2857 | Accuracy: 0.9131\n","Epoch [2/2] | Step [21604/22538] | Loss: 0.4040 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21605/22538] | Loss: 0.2572 | Accuracy: 0.9189\n","Epoch [2/2] | Step [21606/22538] | Loss: 0.3147 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21607/22538] | Loss: 0.2326 | Accuracy: 0.9393\n","Epoch [2/2] | Step [21608/22538] | Loss: 0.5127 | Accuracy: 0.8526\n","Epoch [2/2] | Step [21609/22538] | Loss: 0.1891 | Accuracy: 0.9427\n","Epoch [2/2] | Step [21610/22538] | Loss: 0.3685 | Accuracy: 0.9035\n","Epoch [2/2] | Step [21611/22538] | Loss: 0.3288 | Accuracy: 0.8915\n","Epoch [2/2] | Step [21612/22538] | Loss: 0.4330 | Accuracy: 0.8721\n","Epoch [2/2] | Step [21613/22538] | Loss: 0.2459 | Accuracy: 0.9356\n","Epoch [2/2] | Step [21614/22538] | Loss: 0.4227 | Accuracy: 0.8882\n","Epoch [2/2] | Step [21615/22538] | Loss: 0.2566 | Accuracy: 0.9198\n","Epoch [2/2] | Step [21616/22538] | Loss: 0.2943 | Accuracy: 0.9135\n","Epoch [2/2] | Step [21617/22538] | Loss: 0.3782 | Accuracy: 0.8904\n","Epoch [2/2] | Step [21618/22538] | Loss: 0.2843 | Accuracy: 0.9200\n","Epoch [2/2] | Step [21619/22538] | Loss: 0.3165 | Accuracy: 0.9006\n","Epoch [2/2] | Step [21620/22538] | Loss: 0.2471 | Accuracy: 0.9222\n","Epoch [2/2] | Step [21621/22538] | Loss: 0.5795 | Accuracy: 0.8258\n","Epoch [2/2] | Step [21622/22538] | Loss: 0.4877 | Accuracy: 0.8841\n","Epoch [2/2] | Step [21623/22538] | Loss: 0.3801 | Accuracy: 0.9030\n","Epoch [2/2] | Step [21624/22538] | Loss: 0.3322 | Accuracy: 0.9186\n","Epoch [2/2] | Step [21625/22538] | Loss: 0.3408 | Accuracy: 0.8947\n","Epoch [2/2] | Step [21626/22538] | Loss: 0.4737 | Accuracy: 0.8814\n","Epoch [2/2] | Step [21627/22538] | Loss: 0.3254 | Accuracy: 0.9187\n","Epoch [2/2] | Step [21628/22538] | Loss: 0.2223 | Accuracy: 0.9417\n","Epoch [2/2] | Step [21629/22538] | Loss: 0.2577 | Accuracy: 0.9246\n","Epoch [2/2] | Step [21630/22538] | Loss: 0.2361 | Accuracy: 0.9301\n","Epoch [2/2] | Step [21631/22538] | Loss: 0.4677 | Accuracy: 0.9041\n","Epoch [2/2] | Step [21632/22538] | Loss: 0.3727 | Accuracy: 0.9005\n","Epoch [2/2] | Step [21633/22538] | Loss: 0.2036 | Accuracy: 0.9375\n","Epoch [2/2] | Step [21634/22538] | Loss: 0.3933 | Accuracy: 0.9075\n","Epoch [2/2] | Step [21635/22538] | Loss: 0.2437 | Accuracy: 0.9286\n","Epoch [2/2] | Step [21636/22538] | Loss: 0.3820 | Accuracy: 0.8914\n","Epoch [2/2] | Step [21637/22538] | Loss: 0.2862 | Accuracy: 0.9172\n","Epoch [2/2] | Step [21638/22538] | Loss: 0.2540 | Accuracy: 0.9272\n","Epoch [2/2] | Step [21639/22538] | Loss: 0.3810 | Accuracy: 0.8903\n","Epoch [2/2] | Step [21640/22538] | Loss: 0.3753 | Accuracy: 0.8962\n","Epoch [2/2] | Step [21641/22538] | Loss: 0.4352 | Accuracy: 0.8850\n","Epoch [2/2] | Step [21642/22538] | Loss: 0.2520 | Accuracy: 0.9367\n","Epoch [2/2] | Step [21643/22538] | Loss: 0.2246 | Accuracy: 0.9351\n","Epoch [2/2] | Step [21644/22538] | Loss: 0.3076 | Accuracy: 0.9125\n","Epoch [2/2] | Step [21645/22538] | Loss: 0.3962 | Accuracy: 0.8725\n","Epoch [2/2] | Step [21646/22538] | Loss: 0.2752 | Accuracy: 0.9338\n","Epoch [2/2] | Step [21647/22538] | Loss: 0.2833 | Accuracy: 0.9028\n","Epoch [2/2] | Step [21648/22538] | Loss: 0.2739 | Accuracy: 0.9203\n","Epoch [2/2] | Step [21649/22538] | Loss: 0.2835 | Accuracy: 0.9209\n","Epoch [2/2] | Step [21650/22538] | Loss: 0.3604 | Accuracy: 0.8858\n","Epoch [2/2] | Step [21651/22538] | Loss: 0.4490 | Accuracy: 0.8608\n","Epoch [2/2] | Step [21652/22538] | Loss: 0.2909 | Accuracy: 0.9091\n","Epoch [2/2] | Step [21653/22538] | Loss: 0.2856 | Accuracy: 0.9191\n","Epoch [2/2] | Step [21654/22538] | Loss: 0.2920 | Accuracy: 0.9100\n","Epoch [2/2] | Step [21655/22538] | Loss: 0.3215 | Accuracy: 0.9181\n","Epoch [2/2] | Step [21656/22538] | Loss: 0.3077 | Accuracy: 0.9141\n","Epoch [2/2] | Step [21657/22538] | Loss: 0.3969 | Accuracy: 0.9004\n","Epoch [2/2] | Step [21658/22538] | Loss: 0.4753 | Accuracy: 0.8906\n","Epoch [2/2] | Step [21659/22538] | Loss: 0.3551 | Accuracy: 0.9041\n","Epoch [2/2] | Step [21660/22538] | Loss: 0.2512 | Accuracy: 0.9280\n","Epoch [2/2] | Step [21661/22538] | Loss: 0.2898 | Accuracy: 0.9216\n","Epoch [2/2] | Step [21662/22538] | Loss: 0.4397 | Accuracy: 0.8684\n","Epoch [2/2] | Step [21663/22538] | Loss: 0.2691 | Accuracy: 0.9267\n","Epoch [2/2] | Step [21664/22538] | Loss: 0.3379 | Accuracy: 0.9115\n","Epoch [2/2] | Step [21665/22538] | Loss: 0.3596 | Accuracy: 0.9098\n","Epoch [2/2] | Step [21666/22538] | Loss: 0.4799 | Accuracy: 0.8942\n","Epoch [2/2] | Step [21667/22538] | Loss: 0.4890 | Accuracy: 0.8810\n","Epoch [2/2] | Step [21668/22538] | Loss: 0.2839 | Accuracy: 0.9219\n","Epoch [2/2] | Step [21669/22538] | Loss: 0.2748 | Accuracy: 0.9236\n","Epoch [2/2] | Step [21670/22538] | Loss: 0.5806 | Accuracy: 0.8783\n","Epoch [2/2] | Step [21671/22538] | Loss: 0.3757 | Accuracy: 0.8800\n","Epoch [2/2] | Step [21672/22538] | Loss: 0.2113 | Accuracy: 0.9289\n","Epoch [2/2] | Step [21673/22538] | Loss: 0.3918 | Accuracy: 0.8902\n","Epoch [2/2] | Step [21674/22538] | Loss: 0.1962 | Accuracy: 0.9605\n","Epoch [2/2] | Step [21675/22538] | Loss: 0.4177 | Accuracy: 0.8830\n","Epoch [2/2] | Step [21676/22538] | Loss: 0.3320 | Accuracy: 0.9198\n","Epoch [2/2] | Step [21677/22538] | Loss: 0.2463 | Accuracy: 0.9229\n","Epoch [2/2] | Step [21678/22538] | Loss: 0.5439 | Accuracy: 0.8586\n","Epoch [2/2] | Step [21679/22538] | Loss: 0.5531 | Accuracy: 0.8659\n","Epoch [2/2] | Step [21680/22538] | Loss: 0.3064 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21681/22538] | Loss: 0.2233 | Accuracy: 0.9318\n","Epoch [2/2] | Step [21682/22538] | Loss: 0.2267 | Accuracy: 0.9286\n","Epoch [2/2] | Step [21683/22538] | Loss: 0.3277 | Accuracy: 0.8977\n","Epoch [2/2] | Step [21684/22538] | Loss: 0.3037 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21685/22538] | Loss: 0.3430 | Accuracy: 0.9058\n","Epoch [2/2] | Step [21686/22538] | Loss: 0.4248 | Accuracy: 0.8839\n","Epoch [2/2] | Step [21687/22538] | Loss: 0.3417 | Accuracy: 0.9104\n","Epoch [2/2] | Step [21688/22538] | Loss: 0.3431 | Accuracy: 0.8851\n","Epoch [2/2] | Step [21689/22538] | Loss: 0.3173 | Accuracy: 0.9085\n","Epoch [2/2] | Step [21690/22538] | Loss: 0.2819 | Accuracy: 0.9214\n","Epoch [2/2] | Step [21691/22538] | Loss: 0.3424 | Accuracy: 0.9023\n","Epoch [2/2] | Step [21692/22538] | Loss: 0.3362 | Accuracy: 0.9094\n","Epoch [2/2] | Step [21693/22538] | Loss: 0.3899 | Accuracy: 0.8986\n","Epoch [2/2] | Step [21694/22538] | Loss: 0.4004 | Accuracy: 0.8906\n","Epoch [2/2] | Step [21695/22538] | Loss: 0.3348 | Accuracy: 0.9014\n","Epoch [2/2] | Step [21696/22538] | Loss: 0.2701 | Accuracy: 0.9191\n","Epoch [2/2] | Step [21697/22538] | Loss: 0.1980 | Accuracy: 0.9336\n","Epoch [2/2] | Step [21698/22538] | Loss: 0.3030 | Accuracy: 0.9214\n","Epoch [2/2] | Step [21699/22538] | Loss: 0.3791 | Accuracy: 0.8884\n","Epoch [2/2] | Step [21700/22538] | Loss: 0.4382 | Accuracy: 0.8825\n","Epoch [2/2] | Step [21701/22538] | Loss: 0.1559 | Accuracy: 0.9545\n","Epoch [2/2] | Step [21702/22538] | Loss: 0.2283 | Accuracy: 0.9250\n","Epoch [2/2] | Step [21703/22538] | Loss: 0.2146 | Accuracy: 0.9339\n","Epoch [2/2] | Step [21704/22538] | Loss: 0.3494 | Accuracy: 0.9033\n","Epoch [2/2] | Step [21705/22538] | Loss: 0.3241 | Accuracy: 0.9047\n","Epoch [2/2] | Step [21706/22538] | Loss: 0.3500 | Accuracy: 0.9052\n","Epoch [2/2] | Step [21707/22538] | Loss: 0.3677 | Accuracy: 0.9196\n","Epoch [2/2] | Step [21708/22538] | Loss: 0.2288 | Accuracy: 0.9355\n","Epoch [2/2] | Step [21709/22538] | Loss: 0.2877 | Accuracy: 0.9209\n","Epoch [2/2] | Step [21710/22538] | Loss: 0.2885 | Accuracy: 0.9135\n","Epoch [2/2] | Step [21711/22538] | Loss: 0.2546 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21712/22538] | Loss: 0.3513 | Accuracy: 0.8932\n","Epoch [2/2] | Step [21713/22538] | Loss: 0.2544 | Accuracy: 0.9196\n","Epoch [2/2] | Step [21714/22538] | Loss: 0.2761 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21715/22538] | Loss: 0.1704 | Accuracy: 0.9503\n","Epoch [2/2] | Step [21716/22538] | Loss: 0.3312 | Accuracy: 0.9125\n","Epoch [2/2] | Step [21717/22538] | Loss: 0.2233 | Accuracy: 0.9295\n","Epoch [2/2] | Step [21718/22538] | Loss: 0.3908 | Accuracy: 0.9007\n","Epoch [2/2] | Step [21719/22538] | Loss: 0.2670 | Accuracy: 0.9223\n","Epoch [2/2] | Step [21720/22538] | Loss: 0.3130 | Accuracy: 0.9100\n","Epoch [2/2] | Step [21721/22538] | Loss: 0.5685 | Accuracy: 0.8415\n","Epoch [2/2] | Step [21722/22538] | Loss: 0.2149 | Accuracy: 0.9482\n","Epoch [2/2] | Step [21723/22538] | Loss: 0.3319 | Accuracy: 0.9232\n","Epoch [2/2] | Step [21724/22538] | Loss: 0.2494 | Accuracy: 0.9203\n","Epoch [2/2] | Step [21725/22538] | Loss: 0.2404 | Accuracy: 0.9396\n","Epoch [2/2] | Step [21726/22538] | Loss: 0.3246 | Accuracy: 0.8933\n","Epoch [2/2] | Step [21727/22538] | Loss: 0.5587 | Accuracy: 0.8125\n","Epoch [2/2] | Step [21728/22538] | Loss: 0.2233 | Accuracy: 0.9347\n","Epoch [2/2] | Step [21729/22538] | Loss: 0.2806 | Accuracy: 0.9180\n","Epoch [2/2] | Step [21730/22538] | Loss: 0.2444 | Accuracy: 0.9386\n","Epoch [2/2] | Step [21731/22538] | Loss: 0.3719 | Accuracy: 0.8866\n","Epoch [2/2] | Step [21732/22538] | Loss: 0.2444 | Accuracy: 0.9360\n","Epoch [2/2] | Step [21733/22538] | Loss: 0.3019 | Accuracy: 0.9053\n","Epoch [2/2] | Step [21734/22538] | Loss: 0.2120 | Accuracy: 0.9391\n","Epoch [2/2] | Step [21735/22538] | Loss: 0.2963 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21736/22538] | Loss: 0.4030 | Accuracy: 0.8918\n","Epoch [2/2] | Step [21737/22538] | Loss: 0.3483 | Accuracy: 0.8868\n","Epoch [2/2] | Step [21738/22538] | Loss: 0.2295 | Accuracy: 0.9359\n","Epoch [2/2] | Step [21739/22538] | Loss: 0.2346 | Accuracy: 0.9207\n","Epoch [2/2] | Step [21740/22538] | Loss: 0.1968 | Accuracy: 0.9494\n","Epoch [2/2] | Step [21741/22538] | Loss: 0.2620 | Accuracy: 0.9245\n","Epoch [2/2] | Step [21742/22538] | Loss: 0.6474 | Accuracy: 0.8514\n","Epoch [2/2] | Step [21743/22538] | Loss: 0.1896 | Accuracy: 0.9522\n","Epoch [2/2] | Step [21744/22538] | Loss: 0.2796 | Accuracy: 0.9226\n","Epoch [2/2] | Step [21745/22538] | Loss: 0.3176 | Accuracy: 0.9210\n","Epoch [2/2] | Step [21746/22538] | Loss: 0.3447 | Accuracy: 0.9067\n","Epoch [2/2] | Step [21747/22538] | Loss: 0.2507 | Accuracy: 0.9350\n","Epoch [2/2] | Step [21748/22538] | Loss: 0.4128 | Accuracy: 0.8851\n","Epoch [2/2] | Step [21749/22538] | Loss: 0.3058 | Accuracy: 0.9179\n","Epoch [2/2] | Step [21750/22538] | Loss: 0.3845 | Accuracy: 0.8981\n","Epoch [2/2] | Step [21751/22538] | Loss: 0.2983 | Accuracy: 0.9036\n","Epoch [2/2] | Step [21752/22538] | Loss: 0.5105 | Accuracy: 0.8672\n","Epoch [2/2] | Step [21753/22538] | Loss: 0.3441 | Accuracy: 0.9208\n","Epoch [2/2] | Step [21754/22538] | Loss: 0.4234 | Accuracy: 0.8720\n","Epoch [2/2] | Step [21755/22538] | Loss: 0.4570 | Accuracy: 0.8858\n","Epoch [2/2] | Step [21756/22538] | Loss: 0.3973 | Accuracy: 0.8886\n","Epoch [2/2] | Step [21757/22538] | Loss: 0.3567 | Accuracy: 0.8966\n","Epoch [2/2] | Step [21758/22538] | Loss: 0.4202 | Accuracy: 0.8776\n","Epoch [2/2] | Step [21759/22538] | Loss: 0.3820 | Accuracy: 0.8932\n","Epoch [2/2] | Step [21760/22538] | Loss: 0.1949 | Accuracy: 0.9417\n","Epoch [2/2] | Step [21761/22538] | Loss: 0.3112 | Accuracy: 0.9095\n","Epoch [2/2] | Step [21762/22538] | Loss: 0.2675 | Accuracy: 0.9253\n","Epoch [2/2] | Step [21763/22538] | Loss: 0.2282 | Accuracy: 0.9322\n","Epoch [2/2] | Step [21764/22538] | Loss: 0.3348 | Accuracy: 0.9216\n","Epoch [2/2] | Step [21765/22538] | Loss: 0.2816 | Accuracy: 0.9245\n","Epoch [2/2] | Step [21766/22538] | Loss: 0.2592 | Accuracy: 0.9086\n","Epoch [2/2] | Step [21767/22538] | Loss: 0.3784 | Accuracy: 0.8889\n","Epoch [2/2] | Step [21768/22538] | Loss: 0.3316 | Accuracy: 0.8841\n","Epoch [2/2] | Step [21769/22538] | Loss: 0.3942 | Accuracy: 0.9036\n","Epoch [2/2] | Step [21770/22538] | Loss: 0.4299 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21771/22538] | Loss: 0.3930 | Accuracy: 0.8808\n","Epoch [2/2] | Step [21772/22538] | Loss: 0.3581 | Accuracy: 0.9010\n","Epoch [2/2] | Step [21773/22538] | Loss: 0.3105 | Accuracy: 0.9074\n","Epoch [2/2] | Step [21774/22538] | Loss: 0.4548 | Accuracy: 0.8807\n","Epoch [2/2] | Step [21775/22538] | Loss: 0.3528 | Accuracy: 0.9007\n","Epoch [2/2] | Step [21776/22538] | Loss: 0.2618 | Accuracy: 0.9418\n","Epoch [2/2] | Step [21777/22538] | Loss: 0.3610 | Accuracy: 0.9069\n","Epoch [2/2] | Step [21778/22538] | Loss: 0.2404 | Accuracy: 0.9253\n","Epoch [2/2] | Step [21779/22538] | Loss: 0.2054 | Accuracy: 0.9332\n","Epoch [2/2] | Step [21780/22538] | Loss: 0.2750 | Accuracy: 0.9384\n","Epoch [2/2] | Step [21781/22538] | Loss: 0.2834 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21782/22538] | Loss: 0.3048 | Accuracy: 0.9178\n","Epoch [2/2] | Step [21783/22538] | Loss: 0.3134 | Accuracy: 0.9211\n","Epoch [2/2] | Step [21784/22538] | Loss: 0.4205 | Accuracy: 0.8777\n","Epoch [2/2] | Step [21785/22538] | Loss: 0.2871 | Accuracy: 0.9102\n","Epoch [2/2] | Step [21786/22538] | Loss: 0.2279 | Accuracy: 0.9315\n","Epoch [2/2] | Step [21787/22538] | Loss: 0.2687 | Accuracy: 0.9349\n","Epoch [2/2] | Step [21788/22538] | Loss: 0.2369 | Accuracy: 0.9301\n","Epoch [2/2] | Step [21789/22538] | Loss: 0.2578 | Accuracy: 0.9258\n","Epoch [2/2] | Step [21790/22538] | Loss: 0.2485 | Accuracy: 0.9250\n","Epoch [2/2] | Step [21791/22538] | Loss: 0.2336 | Accuracy: 0.9286\n","Epoch [2/2] | Step [21792/22538] | Loss: 0.2550 | Accuracy: 0.9269\n","Epoch [2/2] | Step [21793/22538] | Loss: 0.3498 | Accuracy: 0.8922\n","Epoch [2/2] | Step [21794/22538] | Loss: 0.1903 | Accuracy: 0.9407\n","Epoch [2/2] | Step [21795/22538] | Loss: 0.2716 | Accuracy: 0.9276\n","Epoch [2/2] | Step [21796/22538] | Loss: 0.2930 | Accuracy: 0.9203\n","Epoch [2/2] | Step [21797/22538] | Loss: 0.2626 | Accuracy: 0.9316\n","Epoch [2/2] | Step [21798/22538] | Loss: 0.3297 | Accuracy: 0.9052\n","Epoch [2/2] | Step [21799/22538] | Loss: 0.3188 | Accuracy: 0.9010\n","Epoch [2/2] | Step [21800/22538] | Loss: 0.2787 | Accuracy: 0.9190\n","Epoch [2/2] | Step [21801/22538] | Loss: 0.4134 | Accuracy: 0.8900\n","Epoch [2/2] | Step [21802/22538] | Loss: 0.2891 | Accuracy: 0.9182\n","Epoch [2/2] | Step [21803/22538] | Loss: 0.2607 | Accuracy: 0.9292\n","Epoch [2/2] | Step [21804/22538] | Loss: 0.3554 | Accuracy: 0.9110\n","Epoch [2/2] | Step [21805/22538] | Loss: 0.4430 | Accuracy: 0.8886\n","Epoch [2/2] | Step [21806/22538] | Loss: 0.2633 | Accuracy: 0.9301\n","Epoch [2/2] | Step [21807/22538] | Loss: 0.2931 | Accuracy: 0.9097\n","Epoch [2/2] | Step [21808/22538] | Loss: 0.4806 | Accuracy: 0.8702\n","Epoch [2/2] | Step [21809/22538] | Loss: 0.3900 | Accuracy: 0.8872\n","Epoch [2/2] | Step [21810/22538] | Loss: 0.2878 | Accuracy: 0.9195\n","Epoch [2/2] | Step [21811/22538] | Loss: 0.3784 | Accuracy: 0.8909\n","Epoch [2/2] | Step [21812/22538] | Loss: 0.3672 | Accuracy: 0.8949\n","Epoch [2/2] | Step [21813/22538] | Loss: 0.2679 | Accuracy: 0.9271\n","Epoch [2/2] | Step [21814/22538] | Loss: 0.3538 | Accuracy: 0.9048\n","Epoch [2/2] | Step [21815/22538] | Loss: 0.2445 | Accuracy: 0.9399\n","Epoch [2/2] | Step [21816/22538] | Loss: 0.2130 | Accuracy: 0.9429\n","Epoch [2/2] | Step [21817/22538] | Loss: 0.3443 | Accuracy: 0.9063\n","Epoch [2/2] | Step [21818/22538] | Loss: 0.2769 | Accuracy: 0.9212\n","Epoch [2/2] | Step [21819/22538] | Loss: 0.2735 | Accuracy: 0.9089\n","Epoch [2/2] | Step [21820/22538] | Loss: 0.3297 | Accuracy: 0.8926\n","Epoch [2/2] | Step [21821/22538] | Loss: 0.3681 | Accuracy: 0.9009\n","Epoch [2/2] | Step [21822/22538] | Loss: 0.4037 | Accuracy: 0.8922\n","Epoch [2/2] | Step [21823/22538] | Loss: 0.3370 | Accuracy: 0.9130\n","Epoch [2/2] | Step [21824/22538] | Loss: 0.3750 | Accuracy: 0.8936\n","Epoch [2/2] | Step [21825/22538] | Loss: 0.4162 | Accuracy: 0.8750\n","Epoch [2/2] | Step [21826/22538] | Loss: 0.2637 | Accuracy: 0.9292\n","Epoch [2/2] | Step [21827/22538] | Loss: 0.4587 | Accuracy: 0.8808\n","Epoch [2/2] | Step [21828/22538] | Loss: 0.2790 | Accuracy: 0.9235\n","Epoch [2/2] | Step [21829/22538] | Loss: 0.2927 | Accuracy: 0.8996\n","Epoch [2/2] | Step [21830/22538] | Loss: 0.2987 | Accuracy: 0.9037\n","Epoch [2/2] | Step [21831/22538] | Loss: 0.4576 | Accuracy: 0.8797\n","Epoch [2/2] | Step [21832/22538] | Loss: 0.3988 | Accuracy: 0.9082\n","Epoch [2/2] | Step [21833/22538] | Loss: 0.2763 | Accuracy: 0.9250\n","Epoch [2/2] | Step [21834/22538] | Loss: 0.4305 | Accuracy: 0.8828\n","Epoch [2/2] | Step [21835/22538] | Loss: 0.2709 | Accuracy: 0.9365\n","Epoch [2/2] | Step [21836/22538] | Loss: 0.2922 | Accuracy: 0.9068\n","Epoch [2/2] | Step [21837/22538] | Loss: 0.2817 | Accuracy: 0.9193\n","Epoch [2/2] | Step [21838/22538] | Loss: 0.4038 | Accuracy: 0.9094\n","Epoch [2/2] | Step [21839/22538] | Loss: 0.2714 | Accuracy: 0.9344\n","Epoch [2/2] | Step [21840/22538] | Loss: 0.2673 | Accuracy: 0.9214\n","Epoch [2/2] | Step [21841/22538] | Loss: 0.3124 | Accuracy: 0.9056\n","Epoch [2/2] | Step [21842/22538] | Loss: 0.2984 | Accuracy: 0.9224\n","Epoch [2/2] | Step [21843/22538] | Loss: 0.3685 | Accuracy: 0.9203\n","Epoch [2/2] | Step [21844/22538] | Loss: 0.5712 | Accuracy: 0.8531\n","Epoch [2/2] | Step [21845/22538] | Loss: 0.3620 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21846/22538] | Loss: 0.3550 | Accuracy: 0.8953\n","Epoch [2/2] | Step [21847/22538] | Loss: 0.2711 | Accuracy: 0.9366\n","Epoch [2/2] | Step [21848/22538] | Loss: 0.4005 | Accuracy: 0.8868\n","Epoch [2/2] | Step [21849/22538] | Loss: 0.3575 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21850/22538] | Loss: 0.2819 | Accuracy: 0.9296\n","Epoch [2/2] | Step [21851/22538] | Loss: 0.2543 | Accuracy: 0.9282\n","Epoch [2/2] | Step [21852/22538] | Loss: 0.2505 | Accuracy: 0.9321\n","Epoch [2/2] | Step [21853/22538] | Loss: 0.3980 | Accuracy: 0.8969\n","Epoch [2/2] | Step [21854/22538] | Loss: 0.2639 | Accuracy: 0.9314\n","Epoch [2/2] | Step [21855/22538] | Loss: 0.3417 | Accuracy: 0.9092\n","Epoch [2/2] | Step [21856/22538] | Loss: 0.2797 | Accuracy: 0.9258\n","Epoch [2/2] | Step [21857/22538] | Loss: 0.3576 | Accuracy: 0.8969\n","Epoch [2/2] | Step [21858/22538] | Loss: 0.1496 | Accuracy: 0.9559\n","Epoch [2/2] | Step [21859/22538] | Loss: 0.2485 | Accuracy: 0.9332\n","Epoch [2/2] | Step [21860/22538] | Loss: 0.3985 | Accuracy: 0.8986\n","Epoch [2/2] | Step [21861/22538] | Loss: 0.4095 | Accuracy: 0.8776\n","Epoch [2/2] | Step [21862/22538] | Loss: 0.1908 | Accuracy: 0.9385\n","Epoch [2/2] | Step [21863/22538] | Loss: 0.2907 | Accuracy: 0.9073\n","Epoch [2/2] | Step [21864/22538] | Loss: 0.2604 | Accuracy: 0.9352\n","Epoch [2/2] | Step [21865/22538] | Loss: 0.2985 | Accuracy: 0.9159\n","Epoch [2/2] | Step [21866/22538] | Loss: 0.4995 | Accuracy: 0.8627\n","Epoch [2/2] | Step [21867/22538] | Loss: 0.2410 | Accuracy: 0.9315\n","Epoch [2/2] | Step [21868/22538] | Loss: 0.4650 | Accuracy: 0.8780\n","Epoch [2/2] | Step [21869/22538] | Loss: 0.4959 | Accuracy: 0.8728\n","Epoch [2/2] | Step [21870/22538] | Loss: 0.3002 | Accuracy: 0.9081\n","Epoch [2/2] | Step [21871/22538] | Loss: 0.1961 | Accuracy: 0.9456\n","Epoch [2/2] | Step [21872/22538] | Loss: 0.2168 | Accuracy: 0.9412\n","Epoch [2/2] | Step [21873/22538] | Loss: 0.1988 | Accuracy: 0.9306\n","Epoch [2/2] | Step [21874/22538] | Loss: 0.3769 | Accuracy: 0.8983\n","Epoch [2/2] | Step [21875/22538] | Loss: 0.1867 | Accuracy: 0.9356\n","Epoch [2/2] | Step [21876/22538] | Loss: 0.3740 | Accuracy: 0.9044\n","Epoch [2/2] | Step [21877/22538] | Loss: 0.3908 | Accuracy: 0.8993\n","Epoch [2/2] | Step [21878/22538] | Loss: 0.2190 | Accuracy: 0.9375\n","Epoch [2/2] | Step [21879/22538] | Loss: 0.4289 | Accuracy: 0.8926\n","Epoch [2/2] | Step [21880/22538] | Loss: 0.4004 | Accuracy: 0.8726\n","Epoch [2/2] | Step [21881/22538] | Loss: 0.4545 | Accuracy: 0.8877\n","Epoch [2/2] | Step [21882/22538] | Loss: 0.2660 | Accuracy: 0.9312\n","Epoch [2/2] | Step [21883/22538] | Loss: 0.2169 | Accuracy: 0.9324\n","Epoch [2/2] | Step [21884/22538] | Loss: 0.2788 | Accuracy: 0.9103\n","Epoch [2/2] | Step [21885/22538] | Loss: 0.3679 | Accuracy: 0.8983\n","Epoch [2/2] | Step [21886/22538] | Loss: 0.3873 | Accuracy: 0.9057\n","Epoch [2/2] | Step [21887/22538] | Loss: 0.3636 | Accuracy: 0.9093\n","Epoch [2/2] | Step [21888/22538] | Loss: 0.2351 | Accuracy: 0.9375\n","Epoch [2/2] | Step [21889/22538] | Loss: 0.4169 | Accuracy: 0.9000\n","Epoch [2/2] | Step [21890/22538] | Loss: 0.2340 | Accuracy: 0.9266\n","Epoch [2/2] | Step [21891/22538] | Loss: 0.3080 | Accuracy: 0.9235\n","Epoch [2/2] | Step [21892/22538] | Loss: 0.3293 | Accuracy: 0.9085\n","Epoch [2/2] | Step [21893/22538] | Loss: 0.3803 | Accuracy: 0.8968\n","Epoch [2/2] | Step [21894/22538] | Loss: 0.3574 | Accuracy: 0.8915\n","Epoch [2/2] | Step [21895/22538] | Loss: 0.2142 | Accuracy: 0.9328\n","Epoch [2/2] | Step [21896/22538] | Loss: 0.2879 | Accuracy: 0.9063\n","Epoch [2/2] | Step [21897/22538] | Loss: 0.4196 | Accuracy: 0.8929\n","Epoch [2/2] | Step [21898/22538] | Loss: 0.5046 | Accuracy: 0.8467\n","Epoch [2/2] | Step [21899/22538] | Loss: 0.4736 | Accuracy: 0.8899\n","Epoch [2/2] | Step [21900/22538] | Loss: 0.2741 | Accuracy: 0.9336\n","Epoch [2/2] | Step [21901/22538] | Loss: 0.2784 | Accuracy: 0.9101\n","Epoch [2/2] | Step [21902/22538] | Loss: 0.2598 | Accuracy: 0.9288\n","Epoch [2/2] | Step [21903/22538] | Loss: 0.3613 | Accuracy: 0.8995\n","Epoch [2/2] | Step [21904/22538] | Loss: 0.3951 | Accuracy: 0.8870\n","Epoch [2/2] | Step [21905/22538] | Loss: 0.2316 | Accuracy: 0.9250\n","Epoch [2/2] | Step [21906/22538] | Loss: 0.2998 | Accuracy: 0.9206\n","Epoch [2/2] | Step [21907/22538] | Loss: 0.3428 | Accuracy: 0.8995\n","Epoch [2/2] | Step [21908/22538] | Loss: 0.4047 | Accuracy: 0.8941\n","Epoch [2/2] | Step [21909/22538] | Loss: 0.3022 | Accuracy: 0.9236\n","Epoch [2/2] | Step [21910/22538] | Loss: 0.3623 | Accuracy: 0.8969\n","Epoch [2/2] | Step [21911/22538] | Loss: 0.3210 | Accuracy: 0.9135\n","Epoch [2/2] | Step [21912/22538] | Loss: 0.2992 | Accuracy: 0.9133\n","Epoch [2/2] | Step [21913/22538] | Loss: 0.3882 | Accuracy: 0.8973\n","Epoch [2/2] | Step [21914/22538] | Loss: 0.2607 | Accuracy: 0.9236\n","Epoch [2/2] | Step [21915/22538] | Loss: 0.3947 | Accuracy: 0.8947\n","Epoch [2/2] | Step [21916/22538] | Loss: 0.2905 | Accuracy: 0.9141\n","Epoch [2/2] | Step [21917/22538] | Loss: 0.3680 | Accuracy: 0.8895\n","Epoch [2/2] | Step [21918/22538] | Loss: 0.2172 | Accuracy: 0.9397\n","Epoch [2/2] | Step [21919/22538] | Loss: 0.3037 | Accuracy: 0.9102\n","Epoch [2/2] | Step [21920/22538] | Loss: 0.2259 | Accuracy: 0.9338\n","Epoch [2/2] | Step [21921/22538] | Loss: 0.3076 | Accuracy: 0.9051\n","Epoch [2/2] | Step [21922/22538] | Loss: 0.2943 | Accuracy: 0.9238\n","Epoch [2/2] | Step [21923/22538] | Loss: 0.2154 | Accuracy: 0.9242\n","Epoch [2/2] | Step [21924/22538] | Loss: 0.3036 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21925/22538] | Loss: 0.4053 | Accuracy: 0.9034\n","Epoch [2/2] | Step [21926/22538] | Loss: 0.2962 | Accuracy: 0.9094\n","Epoch [2/2] | Step [21927/22538] | Loss: 0.2129 | Accuracy: 0.9375\n","Epoch [2/2] | Step [21928/22538] | Loss: 0.4027 | Accuracy: 0.8945\n","Epoch [2/2] | Step [21929/22538] | Loss: 0.4825 | Accuracy: 0.8917\n","Epoch [2/2] | Step [21930/22538] | Loss: 0.3815 | Accuracy: 0.8869\n","Epoch [2/2] | Step [21931/22538] | Loss: 0.4337 | Accuracy: 0.8835\n","Epoch [2/2] | Step [21932/22538] | Loss: 0.3256 | Accuracy: 0.9130\n","Epoch [2/2] | Step [21933/22538] | Loss: 0.3735 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21934/22538] | Loss: 0.2707 | Accuracy: 0.9291\n","Epoch [2/2] | Step [21935/22538] | Loss: 0.3715 | Accuracy: 0.9077\n","Epoch [2/2] | Step [21936/22538] | Loss: 0.3928 | Accuracy: 0.8947\n","Epoch [2/2] | Step [21937/22538] | Loss: 0.3077 | Accuracy: 0.8925\n","Epoch [2/2] | Step [21938/22538] | Loss: 0.4025 | Accuracy: 0.8968\n","Epoch [2/2] | Step [21939/22538] | Loss: 0.3224 | Accuracy: 0.9223\n","Epoch [2/2] | Step [21940/22538] | Loss: 0.2574 | Accuracy: 0.9225\n","Epoch [2/2] | Step [21941/22538] | Loss: 0.4160 | Accuracy: 0.8886\n","Epoch [2/2] | Step [21942/22538] | Loss: 0.3316 | Accuracy: 0.9018\n","Epoch [2/2] | Step [21943/22538] | Loss: 0.1529 | Accuracy: 0.9491\n","Epoch [2/2] | Step [21944/22538] | Loss: 0.2863 | Accuracy: 0.9135\n","Epoch [2/2] | Step [21945/22538] | Loss: 0.3750 | Accuracy: 0.9031\n","Epoch [2/2] | Step [21946/22538] | Loss: 0.4125 | Accuracy: 0.8886\n","Epoch [2/2] | Step [21947/22538] | Loss: 0.3330 | Accuracy: 0.9123\n","Epoch [2/2] | Step [21948/22538] | Loss: 0.4914 | Accuracy: 0.8708\n","Epoch [2/2] | Step [21949/22538] | Loss: 0.3598 | Accuracy: 0.9009\n","Epoch [2/2] | Step [21950/22538] | Loss: 0.2346 | Accuracy: 0.9353\n","Epoch [2/2] | Step [21951/22538] | Loss: 0.2221 | Accuracy: 0.9253\n","Epoch [2/2] | Step [21952/22538] | Loss: 0.2408 | Accuracy: 0.9364\n","Epoch [2/2] | Step [21953/22538] | Loss: 0.3437 | Accuracy: 0.9121\n","Epoch [2/2] | Step [21954/22538] | Loss: 0.2312 | Accuracy: 0.9418\n","Epoch [2/2] | Step [21955/22538] | Loss: 0.1726 | Accuracy: 0.9475\n","Epoch [2/2] | Step [21956/22538] | Loss: 0.2475 | Accuracy: 0.9235\n","Epoch [2/2] | Step [21957/22538] | Loss: 0.2859 | Accuracy: 0.9131\n","Epoch [2/2] | Step [21958/22538] | Loss: 0.2548 | Accuracy: 0.9210\n","Epoch [2/2] | Step [21959/22538] | Loss: 0.3508 | Accuracy: 0.9063\n","Epoch [2/2] | Step [21960/22538] | Loss: 0.3181 | Accuracy: 0.9102\n","Epoch [2/2] | Step [21961/22538] | Loss: 0.2804 | Accuracy: 0.9246\n","Epoch [2/2] | Step [21962/22538] | Loss: 0.3824 | Accuracy: 0.8913\n","Epoch [2/2] | Step [21963/22538] | Loss: 0.4371 | Accuracy: 0.8846\n","Epoch [2/2] | Step [21964/22538] | Loss: 0.4211 | Accuracy: 0.8932\n","Epoch [2/2] | Step [21965/22538] | Loss: 0.3239 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21966/22538] | Loss: 0.4015 | Accuracy: 0.8828\n","Epoch [2/2] | Step [21967/22538] | Loss: 0.5277 | Accuracy: 0.8622\n","Epoch [2/2] | Step [21968/22538] | Loss: 0.3359 | Accuracy: 0.9062\n","Epoch [2/2] | Step [21969/22538] | Loss: 0.2567 | Accuracy: 0.9278\n","Epoch [2/2] | Step [21970/22538] | Loss: 0.2713 | Accuracy: 0.9353\n","Epoch [2/2] | Step [21971/22538] | Loss: 0.2544 | Accuracy: 0.9283\n","Epoch [2/2] | Step [21972/22538] | Loss: 0.2306 | Accuracy: 0.9259\n","Epoch [2/2] | Step [21973/22538] | Loss: 0.4145 | Accuracy: 0.8778\n","Epoch [2/2] | Step [21974/22538] | Loss: 0.3718 | Accuracy: 0.9023\n","Epoch [2/2] | Step [21975/22538] | Loss: 0.3836 | Accuracy: 0.9107\n","Epoch [2/2] | Step [21976/22538] | Loss: 0.2535 | Accuracy: 0.9212\n","Epoch [2/2] | Step [21977/22538] | Loss: 0.2556 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21978/22538] | Loss: 0.3671 | Accuracy: 0.9030\n","Epoch [2/2] | Step [21979/22538] | Loss: 0.2471 | Accuracy: 0.9214\n","Epoch [2/2] | Step [21980/22538] | Loss: 0.2636 | Accuracy: 0.9258\n","Epoch [2/2] | Step [21981/22538] | Loss: 0.3475 | Accuracy: 0.9045\n","Epoch [2/2] | Step [21982/22538] | Loss: 0.3110 | Accuracy: 0.9103\n","Epoch [2/2] | Step [21983/22538] | Loss: 0.3441 | Accuracy: 0.8971\n","Epoch [2/2] | Step [21984/22538] | Loss: 0.3293 | Accuracy: 0.8995\n","Epoch [2/2] | Step [21985/22538] | Loss: 0.2717 | Accuracy: 0.9300\n","Epoch [2/2] | Step [21986/22538] | Loss: 0.3567 | Accuracy: 0.9075\n","Epoch [2/2] | Step [21987/22538] | Loss: 0.4308 | Accuracy: 0.8716\n","Epoch [2/2] | Step [21988/22538] | Loss: 0.3594 | Accuracy: 0.9040\n","Epoch [2/2] | Step [21989/22538] | Loss: 0.3738 | Accuracy: 0.9207\n","Epoch [2/2] | Step [21990/22538] | Loss: 0.3312 | Accuracy: 0.8932\n","Epoch [2/2] | Step [21991/22538] | Loss: 0.4006 | Accuracy: 0.9074\n","Epoch [2/2] | Step [21992/22538] | Loss: 0.3566 | Accuracy: 0.9195\n","Epoch [2/2] | Step [21993/22538] | Loss: 0.2899 | Accuracy: 0.9167\n","Epoch [2/2] | Step [21994/22538] | Loss: 0.3383 | Accuracy: 0.9149\n","Epoch [2/2] | Step [21995/22538] | Loss: 0.3167 | Accuracy: 0.9123\n","Epoch [2/2] | Step [21996/22538] | Loss: 0.2962 | Accuracy: 0.9196\n","Epoch [2/2] | Step [21997/22538] | Loss: 0.4583 | Accuracy: 0.8846\n","Epoch [2/2] | Step [21998/22538] | Loss: 0.4502 | Accuracy: 0.8868\n","Epoch [2/2] | Step [21999/22538] | Loss: 0.2251 | Accuracy: 0.9355\n","Epoch [2/2] | Step [22000/22538] | Loss: 0.4612 | Accuracy: 0.8818\n","Epoch [2/2] | Step [22001/22538] | Loss: 0.5761 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22002/22538] | Loss: 0.4667 | Accuracy: 0.8913\n","Epoch [2/2] | Step [22003/22538] | Loss: 0.4035 | Accuracy: 0.8785\n","Epoch [2/2] | Step [22004/22538] | Loss: 0.3620 | Accuracy: 0.8947\n","Epoch [2/2] | Step [22005/22538] | Loss: 0.2531 | Accuracy: 0.9226\n","Epoch [2/2] | Step [22006/22538] | Loss: 0.2212 | Accuracy: 0.9435\n","Epoch [2/2] | Step [22007/22538] | Loss: 0.2405 | Accuracy: 0.9357\n","Epoch [2/2] | Step [22008/22538] | Loss: 0.2200 | Accuracy: 0.9328\n","Epoch [2/2] | Step [22009/22538] | Loss: 0.5922 | Accuracy: 0.8537\n","Epoch [2/2] | Step [22010/22538] | Loss: 0.2281 | Accuracy: 0.9327\n","Epoch [2/2] | Step [22011/22538] | Loss: 0.1808 | Accuracy: 0.9395\n","Epoch [2/2] | Step [22012/22538] | Loss: 0.3114 | Accuracy: 0.9203\n","Epoch [2/2] | Step [22013/22538] | Loss: 0.4485 | Accuracy: 0.8839\n","Epoch [2/2] | Step [22014/22538] | Loss: 0.3663 | Accuracy: 0.9023\n","Epoch [2/2] | Step [22015/22538] | Loss: 0.4456 | Accuracy: 0.8984\n","Epoch [2/2] | Step [22016/22538] | Loss: 0.4530 | Accuracy: 0.8800\n","Epoch [2/2] | Step [22017/22538] | Loss: 0.3202 | Accuracy: 0.9216\n","Epoch [2/2] | Step [22018/22538] | Loss: 0.1990 | Accuracy: 0.9301\n","Epoch [2/2] | Step [22019/22538] | Loss: 0.3221 | Accuracy: 0.9200\n","Epoch [2/2] | Step [22020/22538] | Loss: 0.2880 | Accuracy: 0.9130\n","Epoch [2/2] | Step [22021/22538] | Loss: 0.2681 | Accuracy: 0.9225\n","Epoch [2/2] | Step [22022/22538] | Loss: 0.2977 | Accuracy: 0.9153\n","Epoch [2/2] | Step [22023/22538] | Loss: 0.3102 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22024/22538] | Loss: 0.4298 | Accuracy: 0.8942\n","Epoch [2/2] | Step [22025/22538] | Loss: 0.2989 | Accuracy: 0.9145\n","Epoch [2/2] | Step [22026/22538] | Loss: 0.4557 | Accuracy: 0.8886\n","Epoch [2/2] | Step [22027/22538] | Loss: 0.2465 | Accuracy: 0.9277\n","Epoch [2/2] | Step [22028/22538] | Loss: 0.2850 | Accuracy: 0.9339\n","Epoch [2/2] | Step [22029/22538] | Loss: 0.4082 | Accuracy: 0.8837\n","Epoch [2/2] | Step [22030/22538] | Loss: 0.2675 | Accuracy: 0.9139\n","Epoch [2/2] | Step [22031/22538] | Loss: 0.4090 | Accuracy: 0.8889\n","Epoch [2/2] | Step [22032/22538] | Loss: 0.4568 | Accuracy: 0.8813\n","Epoch [2/2] | Step [22033/22538] | Loss: 0.3201 | Accuracy: 0.9072\n","Epoch [2/2] | Step [22034/22538] | Loss: 0.2370 | Accuracy: 0.9325\n","Epoch [2/2] | Step [22035/22538] | Loss: 0.2661 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22036/22538] | Loss: 0.2942 | Accuracy: 0.9211\n","Epoch [2/2] | Step [22037/22538] | Loss: 0.4229 | Accuracy: 0.8682\n","Epoch [2/2] | Step [22038/22538] | Loss: 0.3164 | Accuracy: 0.9138\n","Epoch [2/2] | Step [22039/22538] | Loss: 0.3188 | Accuracy: 0.9286\n","Epoch [2/2] | Step [22040/22538] | Loss: 0.2863 | Accuracy: 0.9101\n","Epoch [2/2] | Step [22041/22538] | Loss: 0.2454 | Accuracy: 0.9276\n","Epoch [2/2] | Step [22042/22538] | Loss: 0.2435 | Accuracy: 0.9299\n","Epoch [2/2] | Step [22043/22538] | Loss: 0.3799 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22044/22538] | Loss: 0.2851 | Accuracy: 0.9274\n","Epoch [2/2] | Step [22045/22538] | Loss: 0.2941 | Accuracy: 0.9077\n","Epoch [2/2] | Step [22046/22538] | Loss: 0.2798 | Accuracy: 0.9240\n","Epoch [2/2] | Step [22047/22538] | Loss: 0.3953 | Accuracy: 0.8879\n","Epoch [2/2] | Step [22048/22538] | Loss: 0.2352 | Accuracy: 0.9338\n","Epoch [2/2] | Step [22049/22538] | Loss: 0.2833 | Accuracy: 0.9183\n","Epoch [2/2] | Step [22050/22538] | Loss: 0.2397 | Accuracy: 0.9357\n","Epoch [2/2] | Step [22051/22538] | Loss: 0.3895 | Accuracy: 0.8966\n","Epoch [2/2] | Step [22052/22538] | Loss: 0.2647 | Accuracy: 0.9203\n","Epoch [2/2] | Step [22053/22538] | Loss: 0.3044 | Accuracy: 0.9153\n","Epoch [2/2] | Step [22054/22538] | Loss: 0.2770 | Accuracy: 0.9208\n","Epoch [2/2] | Step [22055/22538] | Loss: 0.4131 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22056/22538] | Loss: 0.3048 | Accuracy: 0.9183\n","Epoch [2/2] | Step [22057/22538] | Loss: 0.2838 | Accuracy: 0.9213\n","Epoch [2/2] | Step [22058/22538] | Loss: 0.1578 | Accuracy: 0.9492\n","Epoch [2/2] | Step [22059/22538] | Loss: 0.3450 | Accuracy: 0.8973\n","Epoch [2/2] | Step [22060/22538] | Loss: 0.2890 | Accuracy: 0.9231\n","Epoch [2/2] | Step [22061/22538] | Loss: 0.3279 | Accuracy: 0.9036\n","Epoch [2/2] | Step [22062/22538] | Loss: 0.3771 | Accuracy: 0.8854\n","Epoch [2/2] | Step [22063/22538] | Loss: 0.1972 | Accuracy: 0.9342\n","Epoch [2/2] | Step [22064/22538] | Loss: 0.2069 | Accuracy: 0.9479\n","Epoch [2/2] | Step [22065/22538] | Loss: 0.3935 | Accuracy: 0.9005\n","Epoch [2/2] | Step [22066/22538] | Loss: 0.3934 | Accuracy: 0.8811\n","Epoch [2/2] | Step [22067/22538] | Loss: 0.2617 | Accuracy: 0.9187\n","Epoch [2/2] | Step [22068/22538] | Loss: 0.2161 | Accuracy: 0.9396\n","Epoch [2/2] | Step [22069/22538] | Loss: 0.2693 | Accuracy: 0.9176\n","Epoch [2/2] | Step [22070/22538] | Loss: 0.2659 | Accuracy: 0.9102\n","Epoch [2/2] | Step [22071/22538] | Loss: 0.3572 | Accuracy: 0.8895\n","Epoch [2/2] | Step [22072/22538] | Loss: 0.3308 | Accuracy: 0.9111\n","Epoch [2/2] | Step [22073/22538] | Loss: 0.3238 | Accuracy: 0.9009\n","Epoch [2/2] | Step [22074/22538] | Loss: 0.3448 | Accuracy: 0.8891\n","Epoch [2/2] | Step [22075/22538] | Loss: 0.3789 | Accuracy: 0.8667\n","Epoch [2/2] | Step [22076/22538] | Loss: 0.3454 | Accuracy: 0.8981\n","Epoch [2/2] | Step [22077/22538] | Loss: 0.2626 | Accuracy: 0.9138\n","Epoch [2/2] | Step [22078/22538] | Loss: 0.3981 | Accuracy: 0.9000\n","Epoch [2/2] | Step [22079/22538] | Loss: 0.2855 | Accuracy: 0.9032\n","Epoch [2/2] | Step [22080/22538] | Loss: 0.4491 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22081/22538] | Loss: 0.2697 | Accuracy: 0.9279\n","Epoch [2/2] | Step [22082/22538] | Loss: 0.2895 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22083/22538] | Loss: 0.2770 | Accuracy: 0.9110\n","Epoch [2/2] | Step [22084/22538] | Loss: 0.2572 | Accuracy: 0.9306\n","Epoch [2/2] | Step [22085/22538] | Loss: 0.3219 | Accuracy: 0.9013\n","Epoch [2/2] | Step [22086/22538] | Loss: 0.3372 | Accuracy: 0.8987\n","Epoch [2/2] | Step [22087/22538] | Loss: 0.4764 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22088/22538] | Loss: 0.3599 | Accuracy: 0.9107\n","Epoch [2/2] | Step [22089/22538] | Loss: 0.3142 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22090/22538] | Loss: 0.2678 | Accuracy: 0.9297\n","Epoch [2/2] | Step [22091/22538] | Loss: 0.2066 | Accuracy: 0.9386\n","Epoch [2/2] | Step [22092/22538] | Loss: 0.3305 | Accuracy: 0.9043\n","Epoch [2/2] | Step [22093/22538] | Loss: 0.4797 | Accuracy: 0.8797\n","Epoch [2/2] | Step [22094/22538] | Loss: 0.3696 | Accuracy: 0.8986\n","Epoch [2/2] | Step [22095/22538] | Loss: 0.3696 | Accuracy: 0.9057\n","Epoch [2/2] | Step [22096/22538] | Loss: 0.3172 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22097/22538] | Loss: 0.2111 | Accuracy: 0.9375\n","Epoch [2/2] | Step [22098/22538] | Loss: 0.3633 | Accuracy: 0.9144\n","Epoch [2/2] | Step [22099/22538] | Loss: 0.3549 | Accuracy: 0.8990\n","Epoch [2/2] | Step [22100/22538] | Loss: 0.3200 | Accuracy: 0.9195\n","Epoch [2/2] | Step [22101/22538] | Loss: 0.3110 | Accuracy: 0.9336\n","Epoch [2/2] | Step [22102/22538] | Loss: 0.2955 | Accuracy: 0.9183\n","Epoch [2/2] | Step [22103/22538] | Loss: 0.2820 | Accuracy: 0.9325\n","Epoch [2/2] | Step [22104/22538] | Loss: 0.2289 | Accuracy: 0.9313\n","Epoch [2/2] | Step [22105/22538] | Loss: 0.2552 | Accuracy: 0.9332\n","Epoch [2/2] | Step [22106/22538] | Loss: 0.4762 | Accuracy: 0.8687\n","Epoch [2/2] | Step [22107/22538] | Loss: 0.4343 | Accuracy: 0.8810\n","Epoch [2/2] | Step [22108/22538] | Loss: 0.2812 | Accuracy: 0.9153\n","Epoch [2/2] | Step [22109/22538] | Loss: 0.4063 | Accuracy: 0.8796\n","Epoch [2/2] | Step [22110/22538] | Loss: 0.2152 | Accuracy: 0.9449\n","Epoch [2/2] | Step [22111/22538] | Loss: 0.2913 | Accuracy: 0.8990\n","Epoch [2/2] | Step [22112/22538] | Loss: 0.5238 | Accuracy: 0.8517\n","Epoch [2/2] | Step [22113/22538] | Loss: 0.3757 | Accuracy: 0.9000\n","Epoch [2/2] | Step [22114/22538] | Loss: 0.4112 | Accuracy: 0.8924\n","Epoch [2/2] | Step [22115/22538] | Loss: 0.3933 | Accuracy: 0.9101\n","Epoch [2/2] | Step [22116/22538] | Loss: 0.3039 | Accuracy: 0.9078\n","Epoch [2/2] | Step [22117/22538] | Loss: 0.3307 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22118/22538] | Loss: 0.3706 | Accuracy: 0.9000\n","Epoch [2/2] | Step [22119/22538] | Loss: 0.4165 | Accuracy: 0.8913\n","Epoch [2/2] | Step [22120/22538] | Loss: 0.2584 | Accuracy: 0.9413\n","Epoch [2/2] | Step [22121/22538] | Loss: 0.4056 | Accuracy: 0.8918\n","Epoch [2/2] | Step [22122/22538] | Loss: 0.2530 | Accuracy: 0.9330\n","Epoch [2/2] | Step [22123/22538] | Loss: 0.2271 | Accuracy: 0.9446\n","Epoch [2/2] | Step [22124/22538] | Loss: 0.3095 | Accuracy: 0.9100\n","Epoch [2/2] | Step [22125/22538] | Loss: 0.4072 | Accuracy: 0.8900\n","Epoch [2/2] | Step [22126/22538] | Loss: 0.3859 | Accuracy: 0.8966\n","Epoch [2/2] | Step [22127/22538] | Loss: 0.3829 | Accuracy: 0.8933\n","Epoch [2/2] | Step [22128/22538] | Loss: 0.4704 | Accuracy: 0.8727\n","Epoch [2/2] | Step [22129/22538] | Loss: 0.3770 | Accuracy: 0.8955\n","Epoch [2/2] | Step [22130/22538] | Loss: 0.3518 | Accuracy: 0.9133\n","Epoch [2/2] | Step [22131/22538] | Loss: 0.4969 | Accuracy: 0.8646\n","Epoch [2/2] | Step [22132/22538] | Loss: 0.2825 | Accuracy: 0.9214\n","Epoch [2/2] | Step [22133/22538] | Loss: 0.2413 | Accuracy: 0.9316\n","Epoch [2/2] | Step [22134/22538] | Loss: 0.2928 | Accuracy: 0.9366\n","Epoch [2/2] | Step [22135/22538] | Loss: 0.2647 | Accuracy: 0.9296\n","Epoch [2/2] | Step [22136/22538] | Loss: 0.2879 | Accuracy: 0.9191\n","Epoch [2/2] | Step [22137/22538] | Loss: 0.3121 | Accuracy: 0.9009\n","Epoch [2/2] | Step [22138/22538] | Loss: 0.3101 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22139/22538] | Loss: 0.2772 | Accuracy: 0.9315\n","Epoch [2/2] | Step [22140/22538] | Loss: 0.2962 | Accuracy: 0.9153\n","Epoch [2/2] | Step [22141/22538] | Loss: 0.4760 | Accuracy: 0.8800\n","Epoch [2/2] | Step [22142/22538] | Loss: 0.3529 | Accuracy: 0.9040\n","Epoch [2/2] | Step [22143/22538] | Loss: 0.2090 | Accuracy: 0.9504\n","Epoch [2/2] | Step [22144/22538] | Loss: 0.5270 | Accuracy: 0.8580\n","Epoch [2/2] | Step [22145/22538] | Loss: 0.2464 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22146/22538] | Loss: 0.3626 | Accuracy: 0.8901\n","Epoch [2/2] | Step [22147/22538] | Loss: 0.3519 | Accuracy: 0.9009\n","Epoch [2/2] | Step [22148/22538] | Loss: 0.4574 | Accuracy: 0.8810\n","Epoch [2/2] | Step [22149/22538] | Loss: 0.2806 | Accuracy: 0.9310\n","Epoch [2/2] | Step [22150/22538] | Loss: 0.2717 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22151/22538] | Loss: 0.3853 | Accuracy: 0.9006\n","Epoch [2/2] | Step [22152/22538] | Loss: 0.3899 | Accuracy: 0.8996\n","Epoch [2/2] | Step [22153/22538] | Loss: 0.2357 | Accuracy: 0.9286\n","Epoch [2/2] | Step [22154/22538] | Loss: 0.3493 | Accuracy: 0.9087\n","Epoch [2/2] | Step [22155/22538] | Loss: 0.3265 | Accuracy: 0.8996\n","Epoch [2/2] | Step [22156/22538] | Loss: 0.2729 | Accuracy: 0.9290\n","Epoch [2/2] | Step [22157/22538] | Loss: 0.2808 | Accuracy: 0.9048\n","Epoch [2/2] | Step [22158/22538] | Loss: 0.3978 | Accuracy: 0.8850\n","Epoch [2/2] | Step [22159/22538] | Loss: 0.2579 | Accuracy: 0.9238\n","Epoch [2/2] | Step [22160/22538] | Loss: 0.2930 | Accuracy: 0.9174\n","Epoch [2/2] | Step [22161/22538] | Loss: 0.2082 | Accuracy: 0.9418\n","Epoch [2/2] | Step [22162/22538] | Loss: 0.3699 | Accuracy: 0.9014\n","Epoch [2/2] | Step [22163/22538] | Loss: 0.4447 | Accuracy: 0.8995\n","Epoch [2/2] | Step [22164/22538] | Loss: 0.2977 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22165/22538] | Loss: 0.3599 | Accuracy: 0.9011\n","Epoch [2/2] | Step [22166/22538] | Loss: 0.3265 | Accuracy: 0.9127\n","Epoch [2/2] | Step [22167/22538] | Loss: 0.2480 | Accuracy: 0.9286\n","Epoch [2/2] | Step [22168/22538] | Loss: 0.2923 | Accuracy: 0.9246\n","Epoch [2/2] | Step [22169/22538] | Loss: 0.3825 | Accuracy: 0.9034\n","Epoch [2/2] | Step [22170/22538] | Loss: 0.3576 | Accuracy: 0.9286\n","Epoch [2/2] | Step [22171/22538] | Loss: 0.1995 | Accuracy: 0.9500\n","Epoch [2/2] | Step [22172/22538] | Loss: 0.2791 | Accuracy: 0.9174\n","Epoch [2/2] | Step [22173/22538] | Loss: 0.3537 | Accuracy: 0.9079\n","Epoch [2/2] | Step [22174/22538] | Loss: 0.3319 | Accuracy: 0.9192\n","Epoch [2/2] | Step [22175/22538] | Loss: 0.2932 | Accuracy: 0.9057\n","Epoch [2/2] | Step [22176/22538] | Loss: 0.4032 | Accuracy: 0.8808\n","Epoch [2/2] | Step [22177/22538] | Loss: 0.3808 | Accuracy: 0.8942\n","Epoch [2/2] | Step [22178/22538] | Loss: 0.4156 | Accuracy: 0.9051\n","Epoch [2/2] | Step [22179/22538] | Loss: 0.2907 | Accuracy: 0.9116\n","Epoch [2/2] | Step [22180/22538] | Loss: 0.2000 | Accuracy: 0.9450\n","Epoch [2/2] | Step [22181/22538] | Loss: 0.2484 | Accuracy: 0.9273\n","Epoch [2/2] | Step [22182/22538] | Loss: 0.2531 | Accuracy: 0.9364\n","Epoch [2/2] | Step [22183/22538] | Loss: 0.4015 | Accuracy: 0.8875\n","Epoch [2/2] | Step [22184/22538] | Loss: 0.4329 | Accuracy: 0.8843\n","Epoch [2/2] | Step [22185/22538] | Loss: 0.3210 | Accuracy: 0.9045\n","Epoch [2/2] | Step [22186/22538] | Loss: 0.3387 | Accuracy: 0.9000\n","Epoch [2/2] | Step [22187/22538] | Loss: 0.2279 | Accuracy: 0.9435\n","Epoch [2/2] | Step [22188/22538] | Loss: 0.2076 | Accuracy: 0.9221\n","Epoch [2/2] | Step [22189/22538] | Loss: 0.2925 | Accuracy: 0.9089\n","Epoch [2/2] | Step [22190/22538] | Loss: 0.3383 | Accuracy: 0.8944\n","Epoch [2/2] | Step [22191/22538] | Loss: 0.2257 | Accuracy: 0.9467\n","Epoch [2/2] | Step [22192/22538] | Loss: 0.2753 | Accuracy: 0.9115\n","Epoch [2/2] | Step [22193/22538] | Loss: 0.3160 | Accuracy: 0.9138\n","Epoch [2/2] | Step [22194/22538] | Loss: 0.3577 | Accuracy: 0.9221\n","Epoch [2/2] | Step [22195/22538] | Loss: 0.2526 | Accuracy: 0.9306\n","Epoch [2/2] | Step [22196/22538] | Loss: 0.3483 | Accuracy: 0.9071\n","Epoch [2/2] | Step [22197/22538] | Loss: 0.2873 | Accuracy: 0.9236\n","Epoch [2/2] | Step [22198/22538] | Loss: 0.3878 | Accuracy: 0.9097\n","Epoch [2/2] | Step [22199/22538] | Loss: 0.4269 | Accuracy: 0.8904\n","Epoch [2/2] | Step [22200/22538] | Loss: 0.3222 | Accuracy: 0.9068\n","Epoch [2/2] | Step [22201/22538] | Loss: 0.2683 | Accuracy: 0.9225\n","Epoch [2/2] | Step [22202/22538] | Loss: 0.4621 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22203/22538] | Loss: 0.4434 | Accuracy: 0.8867\n","Epoch [2/2] | Step [22204/22538] | Loss: 0.1961 | Accuracy: 0.9549\n","Epoch [2/2] | Step [22205/22538] | Loss: 0.2539 | Accuracy: 0.9277\n","Epoch [2/2] | Step [22206/22538] | Loss: 0.5028 | Accuracy: 0.8512\n","Epoch [2/2] | Step [22207/22538] | Loss: 0.4099 | Accuracy: 0.8803\n","Epoch [2/2] | Step [22208/22538] | Loss: 0.3072 | Accuracy: 0.8965\n","Epoch [2/2] | Step [22209/22538] | Loss: 0.3233 | Accuracy: 0.9139\n","Epoch [2/2] | Step [22210/22538] | Loss: 0.3282 | Accuracy: 0.9089\n","Epoch [2/2] | Step [22211/22538] | Loss: 0.4171 | Accuracy: 0.9025\n","Epoch [2/2] | Step [22212/22538] | Loss: 0.2829 | Accuracy: 0.9298\n","Epoch [2/2] | Step [22213/22538] | Loss: 0.6133 | Accuracy: 0.8309\n","Epoch [2/2] | Step [22214/22538] | Loss: 0.4164 | Accuracy: 0.8898\n","Epoch [2/2] | Step [22215/22538] | Loss: 0.3973 | Accuracy: 0.8828\n","Epoch [2/2] | Step [22216/22538] | Loss: 0.2433 | Accuracy: 0.9308\n","Epoch [2/2] | Step [22217/22538] | Loss: 0.4499 | Accuracy: 0.8810\n","Epoch [2/2] | Step [22218/22538] | Loss: 0.3329 | Accuracy: 0.8946\n","Epoch [2/2] | Step [22219/22538] | Loss: 0.3328 | Accuracy: 0.9036\n","Epoch [2/2] | Step [22220/22538] | Loss: 0.2249 | Accuracy: 0.9304\n","Epoch [2/2] | Step [22221/22538] | Loss: 0.3722 | Accuracy: 0.8955\n","Epoch [2/2] | Step [22222/22538] | Loss: 0.3223 | Accuracy: 0.9025\n","Epoch [2/2] | Step [22223/22538] | Loss: 0.2481 | Accuracy: 0.9245\n","Epoch [2/2] | Step [22224/22538] | Loss: 0.2649 | Accuracy: 0.9181\n","Epoch [2/2] | Step [22225/22538] | Loss: 0.2426 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22226/22538] | Loss: 0.4146 | Accuracy: 0.8795\n","Epoch [2/2] | Step [22227/22538] | Loss: 0.2921 | Accuracy: 0.9271\n","Epoch [2/2] | Step [22228/22538] | Loss: 0.3680 | Accuracy: 0.9068\n","Epoch [2/2] | Step [22229/22538] | Loss: 0.3523 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22230/22538] | Loss: 0.2798 | Accuracy: 0.9199\n","Epoch [2/2] | Step [22231/22538] | Loss: 0.4045 | Accuracy: 0.8920\n","Epoch [2/2] | Step [22232/22538] | Loss: 0.3903 | Accuracy: 0.8965\n","Epoch [2/2] | Step [22233/22538] | Loss: 0.2874 | Accuracy: 0.9257\n","Epoch [2/2] | Step [22234/22538] | Loss: 0.1876 | Accuracy: 0.9472\n","Epoch [2/2] | Step [22235/22538] | Loss: 0.2853 | Accuracy: 0.8975\n","Epoch [2/2] | Step [22236/22538] | Loss: 0.2740 | Accuracy: 0.9152\n","Epoch [2/2] | Step [22237/22538] | Loss: 0.3400 | Accuracy: 0.9037\n","Epoch [2/2] | Step [22238/22538] | Loss: 0.2752 | Accuracy: 0.9273\n","Epoch [2/2] | Step [22239/22538] | Loss: 0.5125 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22240/22538] | Loss: 0.3295 | Accuracy: 0.9209\n","Epoch [2/2] | Step [22241/22538] | Loss: 0.2814 | Accuracy: 0.9146\n","Epoch [2/2] | Step [22242/22538] | Loss: 0.2401 | Accuracy: 0.9301\n","Epoch [2/2] | Step [22243/22538] | Loss: 0.4272 | Accuracy: 0.8719\n","Epoch [2/2] | Step [22244/22538] | Loss: 0.2689 | Accuracy: 0.9351\n","Epoch [2/2] | Step [22245/22538] | Loss: 0.2383 | Accuracy: 0.9280\n","Epoch [2/2] | Step [22246/22538] | Loss: 0.3722 | Accuracy: 0.8944\n","Epoch [2/2] | Step [22247/22538] | Loss: 0.3374 | Accuracy: 0.9271\n","Epoch [2/2] | Step [22248/22538] | Loss: 0.2972 | Accuracy: 0.9115\n","Epoch [2/2] | Step [22249/22538] | Loss: 0.2499 | Accuracy: 0.9225\n","Epoch [2/2] | Step [22250/22538] | Loss: 0.2867 | Accuracy: 0.9181\n","Epoch [2/2] | Step [22251/22538] | Loss: 0.3551 | Accuracy: 0.8989\n","Epoch [2/2] | Step [22252/22538] | Loss: 0.3514 | Accuracy: 0.8975\n","Epoch [2/2] | Step [22253/22538] | Loss: 0.2422 | Accuracy: 0.9324\n","Epoch [2/2] | Step [22254/22538] | Loss: 0.4286 | Accuracy: 0.8693\n","Epoch [2/2] | Step [22255/22538] | Loss: 0.3537 | Accuracy: 0.9063\n","Epoch [2/2] | Step [22256/22538] | Loss: 0.4247 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22257/22538] | Loss: 0.3159 | Accuracy: 0.9301\n","Epoch [2/2] | Step [22258/22538] | Loss: 0.2277 | Accuracy: 0.9360\n","Epoch [2/2] | Step [22259/22538] | Loss: 0.2900 | Accuracy: 0.9093\n","Epoch [2/2] | Step [22260/22538] | Loss: 0.1676 | Accuracy: 0.9590\n","Epoch [2/2] | Step [22261/22538] | Loss: 0.3268 | Accuracy: 0.9207\n","Epoch [2/2] | Step [22262/22538] | Loss: 0.2331 | Accuracy: 0.9295\n","Epoch [2/2] | Step [22263/22538] | Loss: 0.3357 | Accuracy: 0.9050\n","Epoch [2/2] | Step [22264/22538] | Loss: 0.4803 | Accuracy: 0.8668\n","Epoch [2/2] | Step [22265/22538] | Loss: 0.4120 | Accuracy: 0.8929\n","Epoch [2/2] | Step [22266/22538] | Loss: 0.3985 | Accuracy: 0.8889\n","Epoch [2/2] | Step [22267/22538] | Loss: 0.3774 | Accuracy: 0.8778\n","Epoch [2/2] | Step [22268/22538] | Loss: 0.3502 | Accuracy: 0.9014\n","Epoch [2/2] | Step [22269/22538] | Loss: 0.2835 | Accuracy: 0.9133\n","Epoch [2/2] | Step [22270/22538] | Loss: 0.3343 | Accuracy: 0.9016\n","Epoch [2/2] | Step [22271/22538] | Loss: 0.3926 | Accuracy: 0.8900\n","Epoch [2/2] | Step [22272/22538] | Loss: 0.3508 | Accuracy: 0.8971\n","Epoch [2/2] | Step [22273/22538] | Loss: 0.3148 | Accuracy: 0.9250\n","Epoch [2/2] | Step [22274/22538] | Loss: 0.4505 | Accuracy: 0.8868\n","Epoch [2/2] | Step [22275/22538] | Loss: 0.3192 | Accuracy: 0.9067\n","Epoch [2/2] | Step [22276/22538] | Loss: 0.2660 | Accuracy: 0.9196\n","Epoch [2/2] | Step [22277/22538] | Loss: 0.3270 | Accuracy: 0.9059\n","Epoch [2/2] | Step [22278/22538] | Loss: 0.3109 | Accuracy: 0.9191\n","Epoch [2/2] | Step [22279/22538] | Loss: 0.3842 | Accuracy: 0.8958\n","Epoch [2/2] | Step [22280/22538] | Loss: 0.2500 | Accuracy: 0.9267\n","Epoch [2/2] | Step [22281/22538] | Loss: 0.3170 | Accuracy: 0.9074\n","Epoch [2/2] | Step [22282/22538] | Loss: 0.2981 | Accuracy: 0.8796\n","Epoch [2/2] | Step [22283/22538] | Loss: 0.2716 | Accuracy: 0.9199\n","Epoch [2/2] | Step [22284/22538] | Loss: 0.3459 | Accuracy: 0.9036\n","Epoch [2/2] | Step [22285/22538] | Loss: 0.4483 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22286/22538] | Loss: 0.2536 | Accuracy: 0.9223\n","Epoch [2/2] | Step [22287/22538] | Loss: 0.3697 | Accuracy: 0.9006\n","Epoch [2/2] | Step [22288/22538] | Loss: 0.4364 | Accuracy: 0.8828\n","Epoch [2/2] | Step [22289/22538] | Loss: 0.2766 | Accuracy: 0.9146\n","Epoch [2/2] | Step [22290/22538] | Loss: 0.2453 | Accuracy: 0.9490\n","Epoch [2/2] | Step [22291/22538] | Loss: 0.2967 | Accuracy: 0.9018\n","Epoch [2/2] | Step [22292/22538] | Loss: 0.3547 | Accuracy: 0.8946\n","Epoch [2/2] | Step [22293/22538] | Loss: 0.3168 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22294/22538] | Loss: 0.2417 | Accuracy: 0.9288\n","Epoch [2/2] | Step [22295/22538] | Loss: 0.3247 | Accuracy: 0.9201\n","Epoch [2/2] | Step [22296/22538] | Loss: 0.3724 | Accuracy: 0.9083\n","Epoch [2/2] | Step [22297/22538] | Loss: 0.2706 | Accuracy: 0.9118\n","Epoch [2/2] | Step [22298/22538] | Loss: 0.2411 | Accuracy: 0.9333\n","Epoch [2/2] | Step [22299/22538] | Loss: 0.3870 | Accuracy: 0.9045\n","Epoch [2/2] | Step [22300/22538] | Loss: 0.3698 | Accuracy: 0.9193\n","Epoch [2/2] | Step [22301/22538] | Loss: 0.3217 | Accuracy: 0.9211\n","Epoch [2/2] | Step [22302/22538] | Loss: 0.3450 | Accuracy: 0.9012\n","Epoch [2/2] | Step [22303/22538] | Loss: 0.3067 | Accuracy: 0.9125\n","Epoch [2/2] | Step [22304/22538] | Loss: 0.3018 | Accuracy: 0.9267\n","Epoch [2/2] | Step [22305/22538] | Loss: 0.3322 | Accuracy: 0.9091\n","Epoch [2/2] | Step [22306/22538] | Loss: 0.4223 | Accuracy: 0.9006\n","Epoch [2/2] | Step [22307/22538] | Loss: 0.2655 | Accuracy: 0.9186\n","Epoch [2/2] | Step [22308/22538] | Loss: 0.2352 | Accuracy: 0.9329\n","Epoch [2/2] | Step [22309/22538] | Loss: 0.2569 | Accuracy: 0.9347\n","Epoch [2/2] | Step [22310/22538] | Loss: 0.4395 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22311/22538] | Loss: 0.3783 | Accuracy: 0.8846\n","Epoch [2/2] | Step [22312/22538] | Loss: 0.3250 | Accuracy: 0.9211\n","Epoch [2/2] | Step [22313/22538] | Loss: 0.4161 | Accuracy: 0.8990\n","Epoch [2/2] | Step [22314/22538] | Loss: 0.3776 | Accuracy: 0.9050\n","Epoch [2/2] | Step [22315/22538] | Loss: 0.3680 | Accuracy: 0.8886\n","Epoch [2/2] | Step [22316/22538] | Loss: 0.3321 | Accuracy: 0.9291\n","Epoch [2/2] | Step [22317/22538] | Loss: 0.3191 | Accuracy: 0.9078\n","Epoch [2/2] | Step [22318/22538] | Loss: 0.2743 | Accuracy: 0.9259\n","Epoch [2/2] | Step [22319/22538] | Loss: 0.1992 | Accuracy: 0.9521\n","Epoch [2/2] | Step [22320/22538] | Loss: 0.4883 | Accuracy: 0.8639\n","Epoch [2/2] | Step [22321/22538] | Loss: 0.3150 | Accuracy: 0.9012\n","Epoch [2/2] | Step [22322/22538] | Loss: 0.2718 | Accuracy: 0.9173\n","Epoch [2/2] | Step [22323/22538] | Loss: 0.1827 | Accuracy: 0.9457\n","Epoch [2/2] | Step [22324/22538] | Loss: 0.3194 | Accuracy: 0.9028\n","Epoch [2/2] | Step [22325/22538] | Loss: 0.4041 | Accuracy: 0.8903\n","Epoch [2/2] | Step [22326/22538] | Loss: 0.2671 | Accuracy: 0.9262\n","Epoch [2/2] | Step [22327/22538] | Loss: 0.3693 | Accuracy: 0.8917\n","Epoch [2/2] | Step [22328/22538] | Loss: 0.5259 | Accuracy: 0.8726\n","Epoch [2/2] | Step [22329/22538] | Loss: 0.1939 | Accuracy: 0.9500\n","Epoch [2/2] | Step [22330/22538] | Loss: 0.3774 | Accuracy: 0.8929\n","Epoch [2/2] | Step [22331/22538] | Loss: 0.5228 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22332/22538] | Loss: 0.2476 | Accuracy: 0.9414\n","Epoch [2/2] | Step [22333/22538] | Loss: 0.2202 | Accuracy: 0.9382\n","Epoch [2/2] | Step [22334/22538] | Loss: 0.3422 | Accuracy: 0.9004\n","Epoch [2/2] | Step [22335/22538] | Loss: 0.3403 | Accuracy: 0.9186\n","Epoch [2/2] | Step [22336/22538] | Loss: 0.4634 | Accuracy: 0.8839\n","Epoch [2/2] | Step [22337/22538] | Loss: 0.3200 | Accuracy: 0.9107\n","Epoch [2/2] | Step [22338/22538] | Loss: 0.3189 | Accuracy: 0.9139\n","Epoch [2/2] | Step [22339/22538] | Loss: 0.3391 | Accuracy: 0.9123\n","Epoch [2/2] | Step [22340/22538] | Loss: 0.2294 | Accuracy: 0.9398\n","Epoch [2/2] | Step [22341/22538] | Loss: 0.2185 | Accuracy: 0.9432\n","Epoch [2/2] | Step [22342/22538] | Loss: 0.2428 | Accuracy: 0.9303\n","Epoch [2/2] | Step [22343/22538] | Loss: 0.3349 | Accuracy: 0.9051\n","Epoch [2/2] | Step [22344/22538] | Loss: 0.3111 | Accuracy: 0.9231\n","Epoch [2/2] | Step [22345/22538] | Loss: 0.2762 | Accuracy: 0.9331\n","Epoch [2/2] | Step [22346/22538] | Loss: 0.2665 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22347/22538] | Loss: 0.3815 | Accuracy: 0.8846\n","Epoch [2/2] | Step [22348/22538] | Loss: 0.3966 | Accuracy: 0.8984\n","Epoch [2/2] | Step [22349/22538] | Loss: 0.3533 | Accuracy: 0.9006\n","Epoch [2/2] | Step [22350/22538] | Loss: 0.3273 | Accuracy: 0.9036\n","Epoch [2/2] | Step [22351/22538] | Loss: 0.2521 | Accuracy: 0.9228\n","Epoch [2/2] | Step [22352/22538] | Loss: 0.2681 | Accuracy: 0.9327\n","Epoch [2/2] | Step [22353/22538] | Loss: 0.4646 | Accuracy: 0.8542\n","Epoch [2/2] | Step [22354/22538] | Loss: 0.3877 | Accuracy: 0.9012\n","Epoch [2/2] | Step [22355/22538] | Loss: 0.2018 | Accuracy: 0.9414\n","Epoch [2/2] | Step [22356/22538] | Loss: 0.2952 | Accuracy: 0.9009\n","Epoch [2/2] | Step [22357/22538] | Loss: 0.2455 | Accuracy: 0.9129\n","Epoch [2/2] | Step [22358/22538] | Loss: 0.3427 | Accuracy: 0.9013\n","Epoch [2/2] | Step [22359/22538] | Loss: 0.3901 | Accuracy: 0.8992\n","Epoch [2/2] | Step [22360/22538] | Loss: 0.4856 | Accuracy: 0.8603\n","Epoch [2/2] | Step [22361/22538] | Loss: 0.2906 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22362/22538] | Loss: 0.2782 | Accuracy: 0.9151\n","Epoch [2/2] | Step [22363/22538] | Loss: 0.3564 | Accuracy: 0.9269\n","Epoch [2/2] | Step [22364/22538] | Loss: 0.2975 | Accuracy: 0.8929\n","Epoch [2/2] | Step [22365/22538] | Loss: 0.3643 | Accuracy: 0.9014\n","Epoch [2/2] | Step [22366/22538] | Loss: 0.3633 | Accuracy: 0.9009\n","Epoch [2/2] | Step [22367/22538] | Loss: 0.2798 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22368/22538] | Loss: 0.4474 | Accuracy: 0.8562\n","Epoch [2/2] | Step [22369/22538] | Loss: 0.2713 | Accuracy: 0.9077\n","Epoch [2/2] | Step [22370/22538] | Loss: 0.3217 | Accuracy: 0.9077\n","Epoch [2/2] | Step [22371/22538] | Loss: 0.2652 | Accuracy: 0.9313\n","Epoch [2/2] | Step [22372/22538] | Loss: 0.3620 | Accuracy: 0.8942\n","Epoch [2/2] | Step [22373/22538] | Loss: 0.3427 | Accuracy: 0.8910\n","Epoch [2/2] | Step [22374/22538] | Loss: 0.2791 | Accuracy: 0.9139\n","Epoch [2/2] | Step [22375/22538] | Loss: 0.2425 | Accuracy: 0.9291\n","Epoch [2/2] | Step [22376/22538] | Loss: 0.2501 | Accuracy: 0.9309\n","Epoch [2/2] | Step [22377/22538] | Loss: 0.3046 | Accuracy: 0.9103\n","Epoch [2/2] | Step [22378/22538] | Loss: 0.2718 | Accuracy: 0.9225\n","Epoch [2/2] | Step [22379/22538] | Loss: 0.2747 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22380/22538] | Loss: 0.3382 | Accuracy: 0.9035\n","Epoch [2/2] | Step [22381/22538] | Loss: 0.4219 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22382/22538] | Loss: 0.4548 | Accuracy: 0.8663\n","Epoch [2/2] | Step [22383/22538] | Loss: 0.2725 | Accuracy: 0.9174\n","Epoch [2/2] | Step [22384/22538] | Loss: 0.5633 | Accuracy: 0.8500\n","Epoch [2/2] | Step [22385/22538] | Loss: 0.3953 | Accuracy: 0.8856\n","Epoch [2/2] | Step [22386/22538] | Loss: 0.2261 | Accuracy: 0.9413\n","Epoch [2/2] | Step [22387/22538] | Loss: 0.2673 | Accuracy: 0.9271\n","Epoch [2/2] | Step [22388/22538] | Loss: 0.2890 | Accuracy: 0.9228\n","Epoch [2/2] | Step [22389/22538] | Loss: 0.4493 | Accuracy: 0.8792\n","Epoch [2/2] | Step [22390/22538] | Loss: 0.3211 | Accuracy: 0.9095\n","Epoch [2/2] | Step [22391/22538] | Loss: 0.3315 | Accuracy: 0.9062\n","Epoch [2/2] | Step [22392/22538] | Loss: 0.3832 | Accuracy: 0.9110\n","Epoch [2/2] | Step [22393/22538] | Loss: 0.3686 | Accuracy: 0.8819\n","Epoch [2/2] | Step [22394/22538] | Loss: 0.6348 | Accuracy: 0.8438\n","Epoch [2/2] | Step [22395/22538] | Loss: 0.2693 | Accuracy: 0.9271\n","Epoch [2/2] | Step [22396/22538] | Loss: 0.3886 | Accuracy: 0.8983\n","Epoch [2/2] | Step [22397/22538] | Loss: 0.1676 | Accuracy: 0.9441\n","Epoch [2/2] | Step [22398/22538] | Loss: 0.5317 | Accuracy: 0.8646\n","Epoch [2/2] | Step [22399/22538] | Loss: 0.5110 | Accuracy: 0.8615\n","Epoch [2/2] | Step [22400/22538] | Loss: 0.3990 | Accuracy: 0.8705\n","Epoch [2/2] | Step [22401/22538] | Loss: 0.3342 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22402/22538] | Loss: 0.2770 | Accuracy: 0.9207\n","Epoch [2/2] | Step [22403/22538] | Loss: 0.3413 | Accuracy: 0.9135\n","Epoch [2/2] | Step [22404/22538] | Loss: 0.2315 | Accuracy: 0.9306\n","Epoch [2/2] | Step [22405/22538] | Loss: 0.3074 | Accuracy: 0.9137\n","Epoch [2/2] | Step [22406/22538] | Loss: 0.3654 | Accuracy: 0.8880\n","Epoch [2/2] | Step [22407/22538] | Loss: 0.2745 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22408/22538] | Loss: 0.2891 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22409/22538] | Loss: 0.4050 | Accuracy: 0.8932\n","Epoch [2/2] | Step [22410/22538] | Loss: 0.3313 | Accuracy: 0.9107\n","Epoch [2/2] | Step [22411/22538] | Loss: 0.2082 | Accuracy: 0.9400\n","Epoch [2/2] | Step [22412/22538] | Loss: 0.1899 | Accuracy: 0.9470\n","Epoch [2/2] | Step [22413/22538] | Loss: 0.4780 | Accuracy: 0.8698\n","Epoch [2/2] | Step [22414/22538] | Loss: 0.3332 | Accuracy: 0.8991\n","Epoch [2/2] | Step [22415/22538] | Loss: 0.3189 | Accuracy: 0.8955\n","Epoch [2/2] | Step [22416/22538] | Loss: 0.4637 | Accuracy: 0.8659\n","Epoch [2/2] | Step [22417/22538] | Loss: 0.3405 | Accuracy: 0.9025\n","Epoch [2/2] | Step [22418/22538] | Loss: 0.4044 | Accuracy: 0.8750\n","Epoch [2/2] | Step [22419/22538] | Loss: 0.3098 | Accuracy: 0.8981\n","Epoch [2/2] | Step [22420/22538] | Loss: 0.3987 | Accuracy: 0.8902\n","Epoch [2/2] | Step [22421/22538] | Loss: 0.3510 | Accuracy: 0.9113\n","Epoch [2/2] | Step [22422/22538] | Loss: 0.3630 | Accuracy: 0.9070\n","Epoch [2/2] | Step [22423/22538] | Loss: 0.4771 | Accuracy: 0.8615\n","Epoch [2/2] | Step [22424/22538] | Loss: 0.3013 | Accuracy: 0.9180\n","Epoch [2/2] | Step [22425/22538] | Loss: 0.3398 | Accuracy: 0.9012\n","Epoch [2/2] | Step [22426/22538] | Loss: 0.2884 | Accuracy: 0.9092\n","Epoch [2/2] | Step [22427/22538] | Loss: 0.2868 | Accuracy: 0.9206\n","Epoch [2/2] | Step [22428/22538] | Loss: 0.3086 | Accuracy: 0.9259\n","Epoch [2/2] | Step [22429/22538] | Loss: 0.2698 | Accuracy: 0.9216\n","Epoch [2/2] | Step [22430/22538] | Loss: 0.2772 | Accuracy: 0.9174\n","Epoch [2/2] | Step [22431/22538] | Loss: 0.2897 | Accuracy: 0.9282\n","Epoch [2/2] | Step [22432/22538] | Loss: 0.3780 | Accuracy: 0.8868\n","Epoch [2/2] | Step [22433/22538] | Loss: 0.3352 | Accuracy: 0.9057\n","Epoch [2/2] | Step [22434/22538] | Loss: 0.2851 | Accuracy: 0.9153\n","Epoch [2/2] | Step [22435/22538] | Loss: 0.3530 | Accuracy: 0.8925\n","Epoch [2/2] | Step [22436/22538] | Loss: 0.1657 | Accuracy: 0.9567\n","Epoch [2/2] | Step [22437/22538] | Loss: 0.3214 | Accuracy: 0.9148\n","Epoch [2/2] | Step [22438/22538] | Loss: 0.3745 | Accuracy: 0.8730\n","Epoch [2/2] | Step [22439/22538] | Loss: 0.3346 | Accuracy: 0.8940\n","Epoch [2/2] | Step [22440/22538] | Loss: 0.2576 | Accuracy: 0.9294\n","Epoch [2/2] | Step [22441/22538] | Loss: 0.3580 | Accuracy: 0.9032\n","Epoch [2/2] | Step [22442/22538] | Loss: 0.2714 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22443/22538] | Loss: 0.2728 | Accuracy: 0.9159\n","Epoch [2/2] | Step [22444/22538] | Loss: 0.3969 | Accuracy: 0.9028\n","Epoch [2/2] | Step [22445/22538] | Loss: 0.3441 | Accuracy: 0.9093\n","Epoch [2/2] | Step [22446/22538] | Loss: 0.4204 | Accuracy: 0.8946\n","Epoch [2/2] | Step [22447/22538] | Loss: 0.2628 | Accuracy: 0.9254\n","Epoch [2/2] | Step [22448/22538] | Loss: 0.4368 | Accuracy: 0.8869\n","Epoch [2/2] | Step [22449/22538] | Loss: 0.3573 | Accuracy: 0.9079\n","Epoch [2/2] | Step [22450/22538] | Loss: 0.4384 | Accuracy: 0.8558\n","Epoch [2/2] | Step [22451/22538] | Loss: 0.4390 | Accuracy: 0.8906\n","Epoch [2/2] | Step [22452/22538] | Loss: 0.2366 | Accuracy: 0.9182\n","Epoch [2/2] | Step [22453/22538] | Loss: 0.3462 | Accuracy: 0.8949\n","Epoch [2/2] | Step [22454/22538] | Loss: 0.2972 | Accuracy: 0.9216\n","Epoch [2/2] | Step [22455/22538] | Loss: 0.3831 | Accuracy: 0.8924\n","Epoch [2/2] | Step [22456/22538] | Loss: 0.2721 | Accuracy: 0.9149\n","Epoch [2/2] | Step [22457/22538] | Loss: 0.3942 | Accuracy: 0.9077\n","Epoch [2/2] | Step [22458/22538] | Loss: 0.3090 | Accuracy: 0.9056\n","Epoch [2/2] | Step [22459/22538] | Loss: 0.4669 | Accuracy: 0.8830\n","Epoch [2/2] | Step [22460/22538] | Loss: 0.3059 | Accuracy: 0.8962\n","Epoch [2/2] | Step [22461/22538] | Loss: 0.2700 | Accuracy: 0.9219\n","Epoch [2/2] | Step [22462/22538] | Loss: 0.3706 | Accuracy: 0.9107\n","Epoch [2/2] | Step [22463/22538] | Loss: 0.3250 | Accuracy: 0.9018\n","Epoch [2/2] | Step [22464/22538] | Loss: 0.2072 | Accuracy: 0.9459\n","Epoch [2/2] | Step [22465/22538] | Loss: 0.3311 | Accuracy: 0.8980\n","Epoch [2/2] | Step [22466/22538] | Loss: 0.3751 | Accuracy: 0.8973\n","Epoch [2/2] | Step [22467/22538] | Loss: 0.2640 | Accuracy: 0.9250\n","Epoch [2/2] | Step [22468/22538] | Loss: 0.3296 | Accuracy: 0.9042\n","Epoch [2/2] | Step [22469/22538] | Loss: 0.3844 | Accuracy: 0.8859\n","Epoch [2/2] | Step [22470/22538] | Loss: 0.4540 | Accuracy: 0.8983\n","Epoch [2/2] | Step [22471/22538] | Loss: 0.3766 | Accuracy: 0.9136\n","Epoch [2/2] | Step [22472/22538] | Loss: 0.2454 | Accuracy: 0.9367\n","Epoch [2/2] | Step [22473/22538] | Loss: 0.2173 | Accuracy: 0.9418\n","Epoch [2/2] | Step [22474/22538] | Loss: 0.2580 | Accuracy: 0.9286\n","Epoch [2/2] | Step [22475/22538] | Loss: 0.4578 | Accuracy: 0.8817\n","Epoch [2/2] | Step [22476/22538] | Loss: 0.3853 | Accuracy: 0.8906\n","Epoch [2/2] | Step [22477/22538] | Loss: 0.4360 | Accuracy: 0.8883\n","Epoch [2/2] | Step [22478/22538] | Loss: 0.3602 | Accuracy: 0.8995\n","Epoch [2/2] | Step [22479/22538] | Loss: 0.3545 | Accuracy: 0.8843\n","Epoch [2/2] | Step [22480/22538] | Loss: 0.2702 | Accuracy: 0.9335\n","Epoch [2/2] | Step [22481/22538] | Loss: 0.4689 | Accuracy: 0.8634\n","Epoch [2/2] | Step [22482/22538] | Loss: 0.3758 | Accuracy: 0.8816\n","Epoch [2/2] | Step [22483/22538] | Loss: 0.1745 | Accuracy: 0.9491\n","Epoch [2/2] | Step [22484/22538] | Loss: 0.1929 | Accuracy: 0.9432\n","Epoch [2/2] | Step [22485/22538] | Loss: 0.3257 | Accuracy: 0.9158\n","Epoch [2/2] | Step [22486/22538] | Loss: 0.3653 | Accuracy: 0.8981\n","Epoch [2/2] | Step [22487/22538] | Loss: 0.2415 | Accuracy: 0.9321\n","Epoch [2/2] | Step [22488/22538] | Loss: 0.3259 | Accuracy: 0.9049\n","Epoch [2/2] | Step [22489/22538] | Loss: 0.4133 | Accuracy: 0.8724\n","Epoch [2/2] | Step [22490/22538] | Loss: 0.2744 | Accuracy: 0.9239\n","Epoch [2/2] | Step [22491/22538] | Loss: 0.3660 | Accuracy: 0.9000\n","Epoch [2/2] | Step [22492/22538] | Loss: 0.3421 | Accuracy: 0.8990\n","Epoch [2/2] | Step [22493/22538] | Loss: 0.3445 | Accuracy: 0.8977\n","Epoch [2/2] | Step [22494/22538] | Loss: 0.3326 | Accuracy: 0.9131\n","Epoch [2/2] | Step [22495/22538] | Loss: 0.2757 | Accuracy: 0.9229\n","Epoch [2/2] | Step [22496/22538] | Loss: 0.2716 | Accuracy: 0.9294\n","Epoch [2/2] | Step [22497/22538] | Loss: 0.2873 | Accuracy: 0.9224\n","Epoch [2/2] | Step [22498/22538] | Loss: 0.2663 | Accuracy: 0.9232\n","Epoch [2/2] | Step [22499/22538] | Loss: 0.2261 | Accuracy: 0.9418\n","Epoch [2/2] | Step [22500/22538] | Loss: 0.2792 | Accuracy: 0.9348\n","Epoch [2/2] | Step [22501/22538] | Loss: 0.2770 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22502/22538] | Loss: 0.2797 | Accuracy: 0.9344\n","Epoch [2/2] | Step [22503/22538] | Loss: 0.2766 | Accuracy: 0.9040\n","Epoch [2/2] | Step [22504/22538] | Loss: 0.2316 | Accuracy: 0.9241\n","Epoch [2/2] | Step [22505/22538] | Loss: 0.2404 | Accuracy: 0.9451\n","Epoch [2/2] | Step [22506/22538] | Loss: 0.2773 | Accuracy: 0.9219\n","Epoch [2/2] | Step [22507/22538] | Loss: 0.3226 | Accuracy: 0.9114\n","Epoch [2/2] | Step [22508/22538] | Loss: 0.3255 | Accuracy: 0.9250\n","Epoch [2/2] | Step [22509/22538] | Loss: 0.3211 | Accuracy: 0.9107\n","Epoch [2/2] | Step [22510/22538] | Loss: 0.4550 | Accuracy: 0.8880\n","Epoch [2/2] | Step [22511/22538] | Loss: 0.1983 | Accuracy: 0.9366\n","Epoch [2/2] | Step [22512/22538] | Loss: 0.2564 | Accuracy: 0.9216\n","Epoch [2/2] | Step [22513/22538] | Loss: 0.2523 | Accuracy: 0.9321\n","Epoch [2/2] | Step [22514/22538] | Loss: 0.2950 | Accuracy: 0.9247\n","Epoch [2/2] | Step [22515/22538] | Loss: 0.3770 | Accuracy: 0.9037\n","Epoch [2/2] | Step [22516/22538] | Loss: 0.2873 | Accuracy: 0.9167\n","Epoch [2/2] | Step [22517/22538] | Loss: 0.2966 | Accuracy: 0.9313\n","Epoch [2/2] | Step [22518/22538] | Loss: 0.3935 | Accuracy: 0.9049\n","Epoch [2/2] | Step [22519/22538] | Loss: 0.3778 | Accuracy: 0.8902\n","Epoch [2/2] | Step [22520/22538] | Loss: 0.2275 | Accuracy: 0.9462\n","Epoch [2/2] | Step [22521/22538] | Loss: 0.3549 | Accuracy: 0.9174\n","Epoch [2/2] | Step [22522/22538] | Loss: 0.2432 | Accuracy: 0.9321\n","Epoch [2/2] | Step [22523/22538] | Loss: 0.2036 | Accuracy: 0.9420\n","Epoch [2/2] | Step [22524/22538] | Loss: 0.2251 | Accuracy: 0.9427\n","Epoch [2/2] | Step [22525/22538] | Loss: 0.3584 | Accuracy: 0.8848\n","Epoch [2/2] | Step [22526/22538] | Loss: 0.3333 | Accuracy: 0.9299\n","Epoch [2/2] | Step [22527/22538] | Loss: 0.4543 | Accuracy: 0.8566\n","Epoch [2/2] | Step [22528/22538] | Loss: 0.1923 | Accuracy: 0.9418\n","Epoch [2/2] | Step [22529/22538] | Loss: 0.2299 | Accuracy: 0.9325\n","Epoch [2/2] | Step [22530/22538] | Loss: 0.3060 | Accuracy: 0.9242\n","Epoch [2/2] | Step [22531/22538] | Loss: 0.4019 | Accuracy: 0.8990\n","Epoch [2/2] | Step [22532/22538] | Loss: 0.2090 | Accuracy: 0.9366\n","Epoch [2/2] | Step [22533/22538] | Loss: 0.4101 | Accuracy: 0.8922\n","Epoch [2/2] | Step [22534/22538] | Loss: 0.1781 | Accuracy: 0.9543\n","Epoch [2/2] | Step [22535/22538] | Loss: 0.3635 | Accuracy: 0.8951\n","Epoch [2/2] | Step [22536/22538] | Loss: 0.3171 | Accuracy: 0.9096\n","Epoch [2/2] | Step [22537/22538] | Loss: 0.2202 | Accuracy: 0.9505\n","Epoch [2/2] | Step [22538/22538] | Loss: 0.4708 | Accuracy: 0.8706\n","Epoch 2 Loss: 0.3426732263549381 | Accuracy: 0.906581536908743\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/T5model_225376data/tokenizer_config.json',\n"," '/content/drive/MyDrive/T5model_225376data/special_tokens_map.json',\n"," '/content/drive/MyDrive/T5model_225376data/tokenizer.json')"]},"metadata":{},"execution_count":8}],"source":["# 추가 학습 실행\n","for epoch in range(num_epochs):\n","    epoch_loss = 0.0\n","    epoch_acc = 0.0\n","\n","    for i, data in enumerate(trainDataLoader):\n","        optimizer.zero_grad()\n","        input_ids, attention_masks, target_ids = (data.values())\n","        outputs = model(input_ids= input_ids.to(device),attention_mask = attention_masks.to(device),labels=target_ids.to(device))\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        preds = logits.argmax(dim=-1)\n","\n","        accuracy = 0\n","        for j in range(len(input_ids)):\n","            acc_score = accuracy_score(target_ids[j].cpu(), preds[j].cpu())\n","            accuracy += acc_score\n","        accuracy /= len(input_ids)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        epoch_acc += accuracy\n","\n","        # 학습 상황 출력\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] | Step [{i+1}/{(pairs.values.shape[0] - test_val_split_idx)//Batch_Size+1}] | Loss: {loss.item():.4f} | Accuracy: {accuracy:.4f}\")\n","\n","    scheduler.step()\n","    epoch_loss /= (pairs.values.shape[0] - test_val_split_idx)//Batch_Size + 1\n","    epoch_acc /= (pairs.values.shape[0] - test_val_split_idx)//Batch_Size + 1\n","    print(f\"Epoch {epoch+1} Loss: {epoch_loss} | Accuracy: {epoch_acc}\")\n","\n","# 추가 학습된 모델 저장\n","model.save_pretrained(f\"/content/drive/MyDrive/T5model_{pairs.values.shape[0]}data\")\n","tokenizer.save_pretrained(f\"/content/drive/MyDrive/T5model_{pairs.values.shape[0]}data\")"]},{"cell_type":"code","source":["def getParaphrased(s):\n","    encoded = tokenizer(\"Paraphrase: \"+s, padding=True, truncation = True, return_tensors = 'pt')\n","    output = model.generate(\n","        input_ids=encoded[\"input_ids\"].to(device), attention_mask=encoded[\"attention_mask\"].to(device), # input_ids = 인코딩된 입력 문장의 인덱스 텐서 / attention_mask = 인코딩된 입력 문장의 어텐션 마스크 텐서(0=패딩토큰, 1=실제토큰)\n","        max_length=256, # 생성되는 문장의 최대 출력 길이\n","        do_sample=True, # 샘플링 여부 파라미터(True=다양한 토큰을 샘플링하여 출력 생성 / False=모델이 가장 확률적으로 높은 토큰을 선택하여 출력 생성)\n","        top_k=50, # 상위 k개의 확률 분포에서만 토큰을 샘플링하는데 사용되는 파라미터. 값을 높이면 생성 다양성 증가. 낮추면 생성 정확성 증가.\n","        top_p=0.9, # 누적 확률 분포의 상위 p%에 해당하는 토큰만을 고려하여 샘플링하는데 사용되는 파라미터. 값을 높이면 생성 정확성이 증가, 낮추면 생성 다양성이 증가.\n","        early_stopping=False, # 조기 중단 여부 결정 파라미터(True=모델이 '<eos>' 토큰을 만났을 때 생성 중단 / False=max_length까지 계속해서 토큰 생성)\n","        num_return_sequences=5 # 생성할 문장 개수 지정 파라미터. 출력 시퀀스 1개로 설정\n","    )\n","    result = []\n","    for o in output:\n","        line = tokenizer.decode(o.to(device), skip_special_tokens=True,clean_up_tokenization_spaces=True) # tokenizer.decode(): 토큰 인덱스를 실제 텍스트로 디코딩\n","        #print(line)\n","        result.append(line)\n","    return result"],"metadata":{"id":"vYmNY4jDpqJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pairs.head()"],"metadata":{"id":"aL53WfCK3AGs","executionInfo":{"status":"ok","timestamp":1685383393984,"user_tz":-540,"elapsed":3,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/","height":250},"outputId":"f283e10f-57bb-40b2-dd60-51b36040911b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                    texts                       pairs\n","0           0            비행기가 이륙하고 있다.               비행기가 이륙하고 있다.\n","1           9     사람이 고양이를 천장에 던지고 있다.           사람이 고양이를 천장에 던진다.\n","2          11  한 여성이 아기를 안아서 캥거루를 안는다.  한 여성이 아기를 안아서 팔에 캥거루를 안는다.\n","3          13       사람이 종이 한 장을 접고 있다.             누군가가 종이를 접고 있다.\n","4          16     북극곰이 눈 위에서 미끄러지고 있다.       북극곰이 눈 위로 미끄러져 가고 있다."],"text/html":["\n","  <div id=\"df-6f9d6a3b-1999-432f-92e4-07604774e15e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>texts</th>\n","      <th>pairs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>비행기가 이륙하고 있다.</td>\n","      <td>비행기가 이륙하고 있다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>사람이 고양이를 천장에 던지고 있다.</td>\n","      <td>사람이 고양이를 천장에 던진다.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>한 여성이 아기를 안아서 캥거루를 안는다.</td>\n","      <td>한 여성이 아기를 안아서 팔에 캥거루를 안는다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13</td>\n","      <td>사람이 종이 한 장을 접고 있다.</td>\n","      <td>누군가가 종이를 접고 있다.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16</td>\n","      <td>북극곰이 눈 위에서 미끄러지고 있다.</td>\n","      <td>북극곰이 눈 위로 미끄러져 가고 있다.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f9d6a3b-1999-432f-92e4-07604774e15e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f9d6a3b-1999-432f-92e4-07604774e15e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f9d6a3b-1999-432f-92e4-07604774e15e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["for i in pairs[500:520].iterrows():\n","    text = i[1][\"pairs\"]\n","    print(f\"{text} => {getParaphrased(text)[3]}\")"],"metadata":{"id":"F18M5EwC2R3h","executionInfo":{"status":"ok","timestamp":1685383413958,"user_tz":-540,"elapsed":19976,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec3df3d7-8c25-4ed3-a58c-405470cd0baa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["망명을 위해 스노우든의 안타 => 스노우던의 망명은 안타리에게 결정을 내린다.\n","노벨 도리스 레딩 94세 사망 => 노벨 도리스 레딩 94세에 죽다 \n","보스턴 경찰은 마라톤 폭탄테러로 3명이 구금되었다고 밝혔다. => 3명의 부상자가 보스턴 경찰에 의해 체포되었다.\n","뉴욕디의 트위터 캠페인 역효과 => 뉴욕디는 트위터 광고에 대해 좋은 반응을 보이지 않는다.\n","터키 검색은 마지막으로 사라진 광부들이 발견한 것으로 끝납니다 => 터키는 결국 실종된 광부들에 의해 이루어졌으나 그들은 실종된 상태입니다.\n","앙키트 차반은 결혼하기 위해 보석금을 내주었다. => 결혼을 약속한 앙키트 차반은 귀한 선물로 현금으로 주었다.\n","베이루트 : 레바논 총리는 어제 취임한 지 10개월이 넘은 내각을 구성했는데, 이들 중 심각한 분열을 대부분 넘어선 후 광범위한 정치 단체를 포함했다 => 베이루트 대통령 (사진)은 어제 10개월 이상의 임기를 가진 레바논 총리 중 심각한 분지를 모두 삭제한 뒤 범야권의 정치 집단 진출과 안보를 위한 폭넓은 지역외교를 진행하는 일을 하고 있다.\n","세계 최고령의 남자가 116세에 사망 => 116년 전 세계 최고령 남성의 생이 사망했다.\n","그리스 극우 지도자 투옥 재판 중 => 그리스 극우파 지도자 체포 재판 중\n","넬슨 만델라는 95세에 사망한다. => 95세에 그는 세상을 하직하고 만다.\n","유대인 관례에 묻힌 나치 족장 => 나치 국적자인 호이자 씨는 유태인 관습 속에 새겨\n","스위스는 세계 최고 최저임금에 투표용지를 던졌다. => 세계에서 제일 낮은 최저 임금에도 스위스는 투표용지를 던졌다.\n","러드는 호주의 새 총리로 취임했다 => 새 총리에 러시가는 호주의 총리에 임명되었다.\n","강력한 삼촌을 해고한 배후에 있는 북한의 김모씨 => 김정은 체제 하에 있는 김동원(북한 출신) 총잡이 김모씨가 북한에서 김정일 위원장의 아들인 김모씨를 해고했다.\n","전 영국 PM 마가렛 대처가 87세에 사망 => 영국 PM 소속 인물인 영국의 쇼핑몰 쇼핑몰 직원인 영국의 마가렛 대처는 올해 87세가 되었다.\n","UN, 남부 수단에서 인종 살해 비난 => UN은 미국 내의 수단에서 인종을 죽이는 수단을 비난했다.\n","시리아 육군, 역사적인 십자군 성 재탈환 => 시리아 군단장, 역사적인 십자군 성을 다시 찾았다\n","사우디 아라비아, 레바논 군대에 30억 달러를 지원 => 사우디아라비아와 레바논 주둔 군대에 30억 달러를 지원하였다.\n","프라하에서 폭발로 사망한 팔레스타인 외교관 => 팔레스타인의 외무장관 자결 파도는 폭렬 후 사망했으며 방글라데시로 망명한 팔레스타인 외교관 사\n","해크니 촬영 : 10대 셰레카 마시 '목에 총을 맞은 후 출혈로 사망' => 해크니 동영상 촬영 : 10대 여자 셰레티 '목에 총 맞은 후 출혈로 사망'\n"]}]},{"cell_type":"code","source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/T5model_225376data\")\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/T5model_225376data\")"],"metadata":{"id":"ffSPd1zO2NRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getParaphrased(s):\n","    encoded = tokenizer(s, padding=True, truncation = True, return_tensors = 'pt')\n","    output = model.generate(\n","        input_ids=encoded[\"input_ids\"].to(device), attention_mask=encoded[\"attention_mask\"].to(device), # input_ids = 인코딩된 입력 문장의 인덱스 텐서 / attention_mask = 인코딩된 입력 문장의 어텐션 마스크 텐서(0=패딩토큰, 1=실제토큰)\n","        max_length=len(s)*2, # 생성되는 문장의 최대 출력 길이\n","        do_sample=True, # 샘플링 여부 파라미터(True=다양한 토큰을 샘플링하여 출력 생성 / False=모델이 가장 확률적으로 높은 토큰을 선택하여 출력 생성)\n","        top_k=30, # 상위 k개의 확률 분포에서만 토큰을 샘플링하는데 사용되는 파라미터. 값을 높이면 생성 다양성 증가. 낮추면 생성 정확성 증가.\n","        top_p=0.5, # 누적 확률 분포의 상위 p%에 해당하는 토큰만을 고려하여 샘플링하는데 사용되는 파라미터. 값을 높이면 생성 정확성이 증가, 낮추면 생성 다양성이 증가.\n","        early_stopping=False, # 조기 중단 여부 결정 파라미터(True=모델이 '<eos>' 토큰을 만났을 때 생성 중단 / False=max_length까지 계속해서 토큰 생성)\n","        num_return_sequences=5 # 생성할 문장 개수 지정 파라미터. 출력 시퀀스 1개로 설정\n","    )\n","    result = []\n","    for o in output:\n","        line = tokenizer.decode(o.to(device), skip_special_tokens=True,clean_up_tokenization_spaces=True) # tokenizer.decode(): 토큰 인덱스를 실제 텍스트로 디코딩\n","        #print(line)\n","        result.append(line)\n","    return result"],"metadata":{"id":"VKqTRWGxxROo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27Hi90bBYczf","executionInfo":{"status":"ok","timestamp":1688017634842,"user_tz":-540,"elapsed":3,"user":{"displayName":"jdk829355 55","userId":"13264177773458165149"}},"outputId":"00e38242-e5e3-4a4e-df8c-d5d7b291e274"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(50358, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(50358, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50358, bias=False)\n",")"]},"metadata":{},"execution_count":48}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"435e0f8d1220415a86e1d9769f6da653":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72b35df8644a43838aea9b2d10e8eec4","IPY_MODEL_0fa2c4c58a3847bda7c18ece1b364bdd","IPY_MODEL_285afea32cb4411e848bdfc48b914285"],"layout":"IPY_MODEL_9dd8547294884c3a904b6b06b9825b28"}},"72b35df8644a43838aea9b2d10e8eec4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4615a56f3add47b0b29d96b21612f2bf","placeholder":"​","style":"IPY_MODEL_b377338964e4456b93734b0a36d83d86","value":"Downloading (…)okenizer_config.json: 100%"}},"0fa2c4c58a3847bda7c18ece1b364bdd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bc58d2c4aa24f3eb59e3acaf5091914","max":2403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18e42b920d2d4527a8bd83a1c1189c37","value":2403}},"285afea32cb4411e848bdfc48b914285":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ccb46c3633e490ba8575aca475c0534","placeholder":"​","style":"IPY_MODEL_f795354defae41fcb02ca073863cf6ed","value":" 2.40k/2.40k [00:00&lt;00:00, 216kB/s]"}},"9dd8547294884c3a904b6b06b9825b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4615a56f3add47b0b29d96b21612f2bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b377338964e4456b93734b0a36d83d86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bc58d2c4aa24f3eb59e3acaf5091914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18e42b920d2d4527a8bd83a1c1189c37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ccb46c3633e490ba8575aca475c0534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f795354defae41fcb02ca073863cf6ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"050e04f847b1440f8ad708a77ce86cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce8afbf770874ab2a099db443fb36a33","IPY_MODEL_2ebabf666fb64eee9a383d46115d513d","IPY_MODEL_1bc71665ce754a1f9f2bca20755e7179"],"layout":"IPY_MODEL_9c5faf0be4bf4b60afb12dc571861f37"}},"ce8afbf770874ab2a099db443fb36a33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd49743843274e10aac4a3426559ab16","placeholder":"​","style":"IPY_MODEL_5edbff18355f4410943a36b1bda462b3","value":"Downloading (…)/main/tokenizer.json: 100%"}},"2ebabf666fb64eee9a383d46115d513d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad1ca0f5217949668683e16cfee5544f","max":2919674,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5ccb81de2344819a8c4b98d58847413","value":2919674}},"1bc71665ce754a1f9f2bca20755e7179":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_000980d82635463a9070d46b89226337","placeholder":"​","style":"IPY_MODEL_e0b763ad3a064531ad2150e4747059f1","value":" 2.92M/2.92M [00:00&lt;00:00, 13.1MB/s]"}},"9c5faf0be4bf4b60afb12dc571861f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd49743843274e10aac4a3426559ab16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5edbff18355f4410943a36b1bda462b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad1ca0f5217949668683e16cfee5544f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5ccb81de2344819a8c4b98d58847413":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"000980d82635463a9070d46b89226337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b763ad3a064531ad2150e4747059f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e772f4cc9074e80b8a8163c5b77fcb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f79f6cc82f5443688e75b858d8969ef","IPY_MODEL_ed8ddbeb04f345d593d2290f1e645945","IPY_MODEL_1c491ad22e6d473eb717dc9bd991a6ab"],"layout":"IPY_MODEL_905afbe8184641778c6e94409a6b6e23"}},"2f79f6cc82f5443688e75b858d8969ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_011bc38e1e094d87a7703401ad4a0f64","placeholder":"​","style":"IPY_MODEL_9152307d90694799853824ee3ff647c4","value":"Downloading (…)cial_tokens_map.json: 100%"}},"ed8ddbeb04f345d593d2290f1e645945":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4489727369e4f52a0c9f1e35e3dfe20","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99f64c5897a542b28b40a79425729203","value":2201}},"1c491ad22e6d473eb717dc9bd991a6ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0589921a4b534cc2b0f154ff901230cf","placeholder":"​","style":"IPY_MODEL_ebcf6046e53341a5934ca138f2c34d7d","value":" 2.20k/2.20k [00:00&lt;00:00, 134kB/s]"}},"905afbe8184641778c6e94409a6b6e23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"011bc38e1e094d87a7703401ad4a0f64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9152307d90694799853824ee3ff647c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4489727369e4f52a0c9f1e35e3dfe20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f64c5897a542b28b40a79425729203":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0589921a4b534cc2b0f154ff901230cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebcf6046e53341a5934ca138f2c34d7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8779d228f13642ad91e3950666731737":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe74fec9198543f48adedb8119a6af26","IPY_MODEL_0e183db0f08c4554bc8992bd8ec3101b","IPY_MODEL_71666fc31b804c408fd9dc506f93967b"],"layout":"IPY_MODEL_8535458e206241b1a3c2b36426168c71"}},"fe74fec9198543f48adedb8119a6af26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec7e8512f48848409ca5bd5b9c0707c4","placeholder":"​","style":"IPY_MODEL_1c372e8bb2714e9a8f645086083fab74","value":"Downloading (…)lve/main/config.json: 100%"}},"0e183db0f08c4554bc8992bd8ec3101b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_793e15f7269249aa96f55cf43ee3907f","max":790,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ebc9bc301834a98988dc088b7318f00","value":790}},"71666fc31b804c408fd9dc506f93967b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59eee7a4aabc4d7e927bc99c2319ab75","placeholder":"​","style":"IPY_MODEL_8da4593649a6474aa8d5d461fd641316","value":" 790/790 [00:00&lt;00:00, 65.6kB/s]"}},"8535458e206241b1a3c2b36426168c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec7e8512f48848409ca5bd5b9c0707c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c372e8bb2714e9a8f645086083fab74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"793e15f7269249aa96f55cf43ee3907f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebc9bc301834a98988dc088b7318f00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59eee7a4aabc4d7e927bc99c2319ab75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8da4593649a6474aa8d5d461fd641316":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9300aef687a3411da2c7a7a6e6e819d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74614b411ac44c3cbb4603936452a5a7","IPY_MODEL_f555967191ca4361a3c2bde2de98a13a","IPY_MODEL_e5ba67456b5a4570bcc22bb5b511c330"],"layout":"IPY_MODEL_78f620a3fef14e3aa670accd1ac627bf"}},"74614b411ac44c3cbb4603936452a5a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4cc2cd4f0d345da817f497b6d3e114c","placeholder":"​","style":"IPY_MODEL_0142023ec86244cea6ad6b5a08f6eec3","value":"Downloading pytorch_model.bin: 100%"}},"f555967191ca4361a3c2bde2de98a13a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f12def0a08534fbeb2da210d13c4b89b","max":1102407757,"min":0,"orientation":"horizontal","style":"IPY_MODEL_948fc7ab4dcd49b2a8b00b11ebee83f3","value":1102407757}},"e5ba67456b5a4570bcc22bb5b511c330":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4276af31427f45b8aa448800a82318df","placeholder":"​","style":"IPY_MODEL_55e5313d12c64bb697b02d78a4c1fc43","value":" 1.10G/1.10G [00:08&lt;00:00, 129MB/s]"}},"78f620a3fef14e3aa670accd1ac627bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4cc2cd4f0d345da817f497b6d3e114c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0142023ec86244cea6ad6b5a08f6eec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f12def0a08534fbeb2da210d13c4b89b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"948fc7ab4dcd49b2a8b00b11ebee83f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4276af31427f45b8aa448800a82318df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55e5313d12c64bb697b02d78a4c1fc43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}